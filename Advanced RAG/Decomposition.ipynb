{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6c95ee1d-9783-42b3-8b1b-77fe89d7a7ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "0fGL1UIE6FW1"
   },
   "source": [
    "# Step-by-step implementation\n",
    "The following are the steps to implement the decomposition technique:\n",
    "1. Import necessary libraries\n",
    "2. Set up the LangSmith and OpenAI API keys\n",
    "3. Load document\n",
    "4. Split text\n",
    "5. Index documents\n",
    "6. Create sub-questions: Decompose the main question\n",
    "7. Generate answers for sub-questions\n",
    "8. Merge sub-questions and answers\n",
    "9. Generate the final answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0cbcf80d-7ce3-436a-9287-aa6820307d55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Zn8VTYab6i87"
   },
   "source": [
    "## 1. Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08dd77a5-1f63-4374-872c-be6154bfd612",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "O5EpuMcAoGVr"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain import hub\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6461ab53-91b2-4c65-8cef-4fc1c0243588",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "-Nu9BWmo6kEa"
   },
   "source": [
    "## 2. Set up the LangSmith and OpenAI API keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32e2c7ea-991d-490c-8beb-d3616e796e8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "xtUZIcrdlB1n"
   },
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"] = \"\"  # Add your OpenAI API key\n",
    "if OPENAI_API_KEY == \"\":\n",
    "    raise ValueError(\"Please set the OPENAI_API_KEY environment variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b85f2bad-8772-4492-af3f-b1f29fad2e22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "HsZ75jxGoafh"
   },
   "outputs": [],
   "source": [
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = '' # Add your LangSmith LangChain API key\n",
    "os.environ['LANGCHAIN_PROJECT']='Decomposition'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bd11fd99-40c1-413c-a5bf-b42767916f2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "64sKm_Pp6z6d"
   },
   "source": [
    "## 3. Load document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "744238f5-4149-4004-bea9-a4e333c1b30b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "leJg9GS-otWk"
   },
   "outputs": [],
   "source": [
    "# provide you document\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://blog.langchain.dev/announcing-langsmith\",),\n",
    ")\n",
    "\n",
    "blog_docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "61f06071-cdb7-494b-9a85-eacd1ebcd44a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "FKNIN5Ze62UW"
   },
   "source": [
    "## 4. Split text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5cddc05e-f13b-4877-8923-250c9d4ae6dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "26Z32k_YotYt"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=20)\n",
    "\n",
    "splits = text_splitter.split_documents(blog_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "af2801e9-7c67-487d-b35c-da52827fc489",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "WeTnN8VV65HA"
   },
   "source": [
    "## 5. Index documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c5acea33-5dd6-455f-bc5f-2844bb07cacf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "_92nqzj8pNlR"
   },
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc4d5a1b-0eff-42b1-890c-dc7c497d1117",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "JeKdaFjPpshM"
   },
   "source": [
    "## 6. Create sub-questions: Decompose the main question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8534db30-8a9e-4906-946f-f2dd69779755",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "3seCHbnapoGX"
   },
   "outputs": [],
   "source": [
    "template = \"\"\"You are an AI language model assistant that generates multiple sub-questions related to an input question. \\n\n",
    "Your task is to break down the input into three sub-problems / sub-questions that can be answers in isolation. \\n\n",
    "Generate multiple search queries related to: {question} \\n\n",
    "Original question: {question}\"\"\"\n",
    "prompt_decomposition = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "generate_queries_decomposition = ( prompt_decomposition | llm | StrOutputParser() | (lambda x: x.split(\"\\n\")))\n",
    "\n",
    "question = \"What is LangSmith, and why do we need it?\"\n",
    "\n",
    "generate_queries_decomposition.invoke({\"question\":question})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba804e6e-f0d8-4f8e-8a09-7354e36469be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "veaOBEBe6_NF"
   },
   "source": [
    "## 7. Generate answers for sub-questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "071dc9a2-525a-4509-a25f-8942c8509a20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "YjVpAJEDpNoG"
   },
   "outputs": [],
   "source": [
    "prompt_rag = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "sub_questions = generate_queries_decomposition.invoke({\"question\":question})\n",
    "rag_results = []\n",
    "for sub_question in sub_questions:\n",
    "  retrieved_docs = retriever.invoke(sub_question)\n",
    "  answer = (prompt_rag | llm | StrOutputParser()).invoke({\"context\": retrieved_docs,\n",
    "                                                                \"question\": sub_question})\n",
    "  rag_results.append(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11e2b3f7-3012-43ae-9b50-3e5147325150",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "DDb_OIfz7Ef4"
   },
   "source": [
    "## 8. Merge sub-questions and answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "98e2cb54-3f8b-4382-992c-a0dc8777b4d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "IhkASPFqpNsE"
   },
   "outputs": [],
   "source": [
    "def format(questions, answers):\n",
    "    \"\"\"Format Q and A\"\"\"\n",
    "\n",
    "    formatted_string = \"\"\n",
    "    for i, (question, answer) in enumerate(zip(questions, answers), start=1):\n",
    "        formatted_string += f\"Question {i}: {question}\\nAnswer {i}: {answer}\\n\\n\"\n",
    "    return formatted_string.strip()\n",
    "\n",
    "context = format(sub_questions, rag_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ddf8e289-d180-4614-9b75-3b52b32ebe68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "5tkT1DCW7Fgy"
   },
   "source": [
    "## 9. Generate the final answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dba3b97d-722e-4bc2-b3ac-b733152496d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "zezRKkBlpNva"
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Here is a set of Q and A:\n",
    "\n",
    "{context}\n",
    "\n",
    "Use these to synthesize an answer to the question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"context\":context,\"question\":question})"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "Decomposition",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
