{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b798f7f",
   "metadata": {},
   "source": [
    "# Build a RAG System with Source Citations Agentic Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4632e840",
   "metadata": {},
   "source": [
    "For this the section till `rag_prompt_template` would be same like previous `2. Build a Contextual Retrieval based RAG System` Notebook.\n",
    "\n",
    "So we call that notebook and later customize the RAG_Pipeline to get the source context along with answer from RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962969a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pages: ../../docs/vision_transformer.pdf\n",
      "Chunking pages: ../../docs/vision_transformer.pdf\n",
      "Generating contextual chunks: ../../docs/vision_transformer.pdf\n",
      "Finished processing: ../../docs/vision_transformer.pdf\n",
      "\n",
      "Loading pages: ../../docs/attention_paper.pdf\n",
      "Chunking pages: ../../docs/attention_paper.pdf\n",
      "Generating contextual chunks: ../../docs/attention_paper.pdf\n",
      "Finished processing: ../../docs/attention_paper.pdf\n",
      "\n",
      "Metadata: {'id': '564928', 'page': 1, 'source': 'Wikipedia', 'title': 'Machine learning'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Machine learning gives computers the ability to learn without being explicitly programmed (Arthur Samuel, 1959). It is a subfield of computer science. The idea came from work in artificial intelligence. Machine learning explores the study and construction of algorithms which can learn and make predictions on data. Such algorithms follow programmed instructions, but can also make predictions or decisions based on data. They build a model from sample inputs. Machine learning is done where designing and programming explicit algorithms cannot be done. Examples include spam filtering, detection of network intruders or malicious insiders working towards a data breach, optical character recognition (OCR), search engines and computer vision."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': '564928', 'page': 1, 'source': 'Wikipedia', 'title': 'Machine learning'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Machine learning gives computers the ability to learn without being explicitly programmed (Arthur Samuel, 1959). It is a subfield of computer science. The idea came from work in artificial intelligence. Machine learning explores the study and construction of algorithms which can learn and make predictions on data. Such algorithms follow programmed instructions, but can also make predictions or decisions based on data. They build a model from sample inputs. Machine learning is done where designing and programming explicit algorithms cannot be done. Examples include spam filtering, detection of network intruders or malicious insiders working towards a data breach, optical character recognition (OCR), search engines and computer vision."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': '564928', 'page': 1, 'source': 'Wikipedia', 'title': 'Machine learning'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Machine learning gives computers the ability to learn without being explicitly programmed (Arthur Samuel, 1959). It is a subfield of computer science. The idea came from work in artificial intelligence. Machine learning explores the study and construction of algorithms which can learn and make predictions on data. Such algorithms follow programmed instructions, but can also make predictions or decisions based on data. They build a model from sample inputs. Machine learning is done where designing and programming explicit algorithms cannot be done. Examples include spam filtering, detection of network intruders or malicious insiders working towards a data breach, optical character recognition (OCR), search engines and computer vision."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': '359370', 'page': 1, 'source': 'Wikipedia', 'title': 'Supervised learning'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "In machine learning, supervised learning is the task of inferring a function from labelled training data. The results of the training are known beforehand, the system simply learns how to get to these results correctly. Usually, such systems work with vectors. They get the training data and the result of the training as two vectors and produce a \"classifier\". Usually, the system uses inductive reasoning to generalize the training data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': '359370', 'page': 1, 'source': 'Wikipedia', 'title': 'Supervised learning'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "In machine learning, supervised learning is the task of inferring a function from labelled training data. The results of the training are known beforehand, the system simply learns how to get to these results correctly. Usually, such systems work with vectors. They get the training data and the result of the training as two vectors and produce a \"classifier\". Usually, the system uses inductive reasoning to generalize the training data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': '3f8c6a36-622e-412f-bc43-af267c37e949', 'page': 7, 'source': '../../docs/vision_transformer.pdf', 'title': 'vision_transformer.pdf'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Focuses on a controlled scaling study of various models, including Vision Transformers and ResNets, evaluating their transfer performance from the JFT-300M dataset. It highlights the performance versus pre-training cost, revealing that Vision Transformers generally outperform ResNets in terms of efficiency and scalability. Additionally, it discusses the implications of hybrid models and the potential for further scaling of Vision Transformers.\n",
       "Published as a conference paper at ICLR 2021\n",
       "4.4\n",
       "SCALING STUDY\n",
       "We perform a controlled scaling study of different models by evaluating transfer performance from\n",
       "JFT-300M. In this setting data size does not bottleneck the models’ performances, and we assess\n",
       "performance versus pre-training cost of each model. The model set includes: 7 ResNets, R50x1,\n",
       "R50x2 R101x1, R152x1, R152x2, pre-trained for 7 epochs, plus R152x2 and R200x3 pre-trained\n",
       "for 14 epochs; 6 Vision Transformers, ViT-B/32, B/16, L/32, L/16, pre-trained for 7 epochs, plus\n",
       "L/16 and H/14"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': '5b62f899-a41f-4452-8c51-82407866b9b5', 'page': 7, 'source': '../../docs/vision_transformer.pdf', 'title': 'vision_transformer.pdf'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Focuses on a controlled scaling study of various models, including Vision Transformers and ResNets, to evaluate their transfer performance from the JFT-300M dataset. It highlights the performance versus pre-training cost, revealing that Vision Transformers generally outperform ResNets in terms of efficiency and scalability. Additionally, it discusses the implications of hybrid models and the potential for further scaling of Vision Transformers.\n",
       "Published as a conference paper at ICLR 2021\n",
       "4.4\n",
       "SCALING STUDY\n",
       "We perform a controlled scaling study of different models by evaluating transfer performance from\n",
       "JFT-300M. In this setting data size does not bottleneck the models’ performances, and we assess\n",
       "performance versus pre-training cost of each model. The model set includes: 7 ResNets, R50x1,\n",
       "R50x2 R101x1, R152x1, R152x2, pre-trained for 7 epochs, plus R152x2 and R200x3 pre-trained\n",
       "for 14 epochs; 6 Vision Transformers, ViT-B/32, B/16, L/32, L/16, pre-trained for 7 epochs, plus\n",
       "L/16 and H/1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': '403e6109-282a-439f-a0b5-c282dde29509', 'page': 0, 'source': '../../docs/vision_transformer.pdf', 'title': 'vision_transformer.pdf'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Focuses on the introduction of the Vision Transformer (ViT) model, which applies a pure Transformer architecture to image classification tasks by treating image patches as tokens, challenging the dominance of convolutional neural networks (CNNs) in computer vision. It highlights the model's performance on various benchmarks when pre-trained on large datasets, demonstrating its efficiency and effectiveness compared to state-of-the-art CNNs.\n",
       "Published as a conference paper at ICLR 2021\n",
       "AN IMAGE IS WORTH 16X16 WORDS:\n",
       "TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE\n",
       "Alexey Dosovitskiy∗,†, Lucas Beyer∗, Alexander Kolesnikov∗, Dirk Weissenborn∗,\n",
       "Xiaohua Zhai∗, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer,\n",
       "Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby∗,†\n",
       "∗equal technical contribution, †equal advising\n",
       "Google Research, Brain Team\n",
       "{adosovitskiy, neilhoulsby}@google.com\n",
       "ABSTRACT\n",
       "While the Transformer architecture has become the de-facto standard for natural\n",
       "language processing"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': 'f67497d2-411f-465b-84c4-c686183e95fd', 'page': 0, 'source': '../../docs/vision_transformer.pdf', 'title': 'vision_transformer.pdf'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Focuses on the introduction of the Vision Transformer (ViT) model, which applies a standard Transformer architecture directly to image classification tasks by treating image patches as tokens. It highlights the limitations of traditional convolutional neural networks (CNNs) in computer vision and presents evidence that ViT can achieve competitive performance on various benchmarks with fewer computational resources when pre-trained on large datasets.\n",
       "Published as a conference paper at ICLR 2021\n",
       "AN IMAGE IS WORTH 16X16 WORDS:\n",
       "TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE\n",
       "Alexey Dosovitskiy∗,†, Lucas Beyer∗, Alexander Kolesnikov∗, Dirk Weissenborn∗,\n",
       "Xiaohua Zhai∗, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer,\n",
       "Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby∗,†\n",
       "∗equal technical contribution, †equal advising\n",
       "Google Research, Brain Team\n",
       "{adosovitskiy, neilhoulsby}@google.com\n",
       "ABSTRACT\n",
       "While the Transformer architecture has become the de-facto standard for natural\n",
       "language "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': 'd2790ead-3861-48ff-88be-ffa027116619', 'page': 7, 'source': '../../docs/vision_transformer.pdf', 'title': 'vision_transformer.pdf'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Focuses on a controlled scaling study of various models, including Vision Transformers and ResNets, evaluating their transfer performance from the JFT-300M dataset. It highlights the performance versus pre-training cost, revealing that Vision Transformers generally outperform ResNets in terms of efficiency and scalability. Additionally, it discusses the implications of these findings for future scaling efforts in model architecture.\n",
       "Published as a conference paper at ICLR 2021\n",
       "4.4\n",
       "SCALING STUDY\n",
       "We perform a controlled scaling study of different models by evaluating transfer performance from\n",
       "JFT-300M. In this setting data size does not bottleneck the models’ performances, and we assess\n",
       "performance versus pre-training cost of each model. The model set includes: 7 ResNets, R50x1,\n",
       "R50x2 R101x1, R152x1, R152x2, pre-trained for 7 epochs, plus R152x2 and R200x3 pre-trained\n",
       "for 14 epochs; 6 Vision Transformers, ViT-B/32, B/16, L/32, L/16, pre-trained for 7 epochs, plus\n",
       "L/16 and H/14 pre-traine"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Machine learning is a subfield of computer science that provides computers with the ability to learn without being explicitly programmed, a concept first articulated by Arthur Samuel in 1959. It originated from research in artificial intelligence and focuses on the study and construction of algorithms that can learn from and make predictions based on data.\n",
       "\n",
       "Key aspects of machine learning include:\n",
       "\n",
       "- **Learning from Data**: Machine learning algorithms build models from sample inputs, allowing them to make predictions or decisions based on new data.\n",
       "- **Algorithmic Flexibility**: While these algorithms follow programmed instructions, they can also adapt and improve their performance based on the data they process.\n",
       "- **Applications**: Machine learning is particularly useful in scenarios where designing and programming explicit algorithms is impractical. Common applications include:\n",
       "  - Spam filtering\n",
       "  - Detection of network intruders or malicious insiders\n",
       "  - Optical character recognition (OCR)\n",
       "  - Search engines\n",
       "  - Computer vision\n",
       "\n",
       "Additionally, machine learning encompasses various learning paradigms, such as supervised learning, where the system infers a function from labeled training data. In supervised learning, the results of the training are known in advance, and the system learns to achieve these results correctly, often using inductive reasoning to generalize from the training data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The term \"CNN\" can refer to two different concepts based on the context provided:\n",
       "\n",
       "1. **Cable News Network (CNN)**: This is an American cable news television channel founded in 1980 by Ted Turner. CNN first aired on June 1, 1980, and its inaugural newscast was anchored by David Walker and Lois Hart. The network is known for its 24-hour news coverage and has been a significant player in the media landscape, broadcasting from various locations including Atlanta, New York City, Washington, D.C., and Los Angeles. CNN has been criticized for perceived biases, including claims of left-wing bias and pro-American bias.\n",
       "\n",
       "2. **Convolutional Neural Network (CNN)**: Although not explicitly mentioned in the provided context, a CNN in the field of artificial intelligence refers to a type of neural network particularly effective for processing structured grid data such as images. It is a specialized form of artificial neural network designed to recognize patterns and features in visual data.\n",
       "\n",
       "If you are looking for information specifically about Convolutional Neural Networks, that information is not present in the provided context."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The provided context does not contain specific information comparing ResNet and CNNs directly, nor does it explicitly state how ResNet is better than CNNs. Instead, it discusses the Vision Transformer (ViT) and its differences from CNNs, particularly in terms of inductive bias and architecture.\n",
       "\n",
       "However, it can be inferred that ResNet, as a type of CNN, incorporates certain advantages over traditional CNN architectures, such as:\n",
       "\n",
       "1. **Residual Connections**: ResNet introduces skip connections that allow gradients to flow through the network more effectively during training, which helps in training deeper networks without suffering from the vanishing gradient problem.\n",
       "\n",
       "2. **Performance**: The context mentions that ResNet models have been evaluated for their representation learning capabilities and have shown competitive performance on various benchmark tasks.\n",
       "\n",
       "3. **Scalability**: ResNet architectures can be scaled up (e.g., ResNet50, ResNet101, ResNet152) to improve performance on complex tasks, which is a common practice in deep learning.\n",
       "\n",
       "4. **Inductive Bias**: While the context emphasizes that CNNs (including ResNet) have strong inductive biases related to locality and translation equivariance, it also notes that ViT has less image-specific inductive bias. This suggests that ResNet's architectural choices are beneficial for image processing tasks.\n",
       "\n",
       "In summary, while the context does not provide a direct comparison of ResNet to CNNs, it implies that ResNet's architectural innovations, such as residual connections and scalability, contribute to its effectiveness in image classification tasks. \n",
       "\n",
       "If you are looking for a more detailed comparison or specific advantages of ResNet over other CNN architectures, that information is not available in the provided context."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run '2. Build a Contextual Retrieval based RAG System.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6656e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "rag_prompt = \"\"\"You are an assistant who is an expert in question-answering tasks.\n",
    "                Answer the following question using only the following pieces of retrieved context.\n",
    "                If the answer is not in the context, do not make up answers, just say that you don't know.\n",
    "                Keep the answer detailed and well formatted based on the information from the context.\n",
    "\n",
    "                Question:\n",
    "                {question}\n",
    "\n",
    "                Context:\n",
    "                {context}\n",
    "\n",
    "                Answer:\n",
    "            \"\"\"\n",
    "\n",
    "rag_prompt_template = ChatPromptTemplate.from_template(rag_prompt)\n",
    "rag_prompt_template.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36eafca",
   "metadata": {},
   "outputs": [],
   "source": [
    "citations_prompt = \"\"\"You are an assistant who is an expert in analyzing answers to questions\n",
    "                      and finding out referenced citations from context articles.\n",
    "\n",
    "                      Given the following question, context and generated answer,\n",
    "                      analyze the generated answer and quote citations from context articles\n",
    "                      that can be used to justify the generated answer.\n",
    "\n",
    "                      Question:\n",
    "                      {question}\n",
    "\n",
    "                      Context Articles:\n",
    "                      {context}\n",
    "\n",
    "                      Answer:\n",
    "                      {answer}\n",
    "                  \"\"\"\n",
    "\n",
    "cite_prompt_template = ChatPromptTemplate.from_template(citations_prompt)\n",
    "cite_prompt_template.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9271f70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class Citation(BaseModel):\n",
    "    id: str = Field(description=\"\"\"The string ID of a SPECIFIC context article\n",
    "                                   which justifies the answer.\"\"\")\n",
    "    source: str = Field(description=\"\"\"The source of the SPECIFIC context article\n",
    "                                       which justifies the answer.\"\"\")\n",
    "    title: str = Field(description=\"\"\"The title of the SPECIFIC context article\n",
    "                                      which justifies the answer.\"\"\")\n",
    "    page: int = Field(description=\"\"\"The page number of the SPECIFIC context article\n",
    "                                     which justifies the answer.\"\"\")\n",
    "    quotes: str = Field(description=\"\"\"The VERBATIM sentences from the SPECIFIC context article\n",
    "                                      that are used to generate the answer.\n",
    "                                      Should be exact sentences from context article without missing words.\"\"\")\n",
    "\n",
    "\n",
    "class QuotedCitations(BaseModel):\n",
    "    \"\"\"Quote citations from given context articles\n",
    "       that can be used to justify the generated answer. Can be multiple articles.\"\"\"\n",
    "    citations: List[Citation] = Field(description=\"\"\"Citations (can be multiple) from the given\n",
    "                                                     context articles that justify the answer.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5fa8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "structured_chatgpt = chatgpt.with_structured_output(QuotedCitations)\n",
    "\n",
    "\n",
    "def format_docs_with_metadata(docs: List[Document]) -> str:\n",
    "    formatted_docs = [\n",
    "        f\"\"\"Context Article ID: {doc.metadata['id']}\n",
    "            Context Article Source: {doc.metadata['source']}\n",
    "            Context Article Title: {doc.metadata['title']}\n",
    "            Context Article Page: {doc.metadata['page']}\n",
    "            Context Article Details: {doc.page_content}\n",
    "         \"\"\"\n",
    "            for i, doc in enumerate(docs)\n",
    "    ]\n",
    "    return \"\\n\\n\" + \"\\n\\n\".join(formatted_docs)\n",
    "\n",
    "rag_response_chain = (\n",
    "    {\n",
    "        \"context\": (itemgetter('context')\n",
    "                        |\n",
    "                    RunnableLambda(format_docs_with_metadata)),\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    }\n",
    "        |\n",
    "    rag_prompt_template\n",
    "        |\n",
    "    chatgpt\n",
    "        |\n",
    "    StrOutputParser()\n",
    ")\n",
    "\n",
    "cite_response_chain = (\n",
    "    {\n",
    "        \"context\": itemgetter('context'),\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "        \"answer\": itemgetter(\"answer\")\n",
    "    }\n",
    "        |\n",
    "    cite_prompt_template\n",
    "        |\n",
    "    structured_chatgpt\n",
    ")\n",
    "\n",
    "rag_chain_w_citations = (\n",
    "    {\n",
    "        \"context\": similarity_retriever,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "        |\n",
    "    RunnablePassthrough.assign(answer=rag_response_chain)\n",
    "        |\n",
    "    RunnablePassthrough.assign(citations=cite_response_chain)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b373a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is machine learning\"\n",
    "result = rag_chain_w_citations.invoke(query)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62a5f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['citations'].dict()['citations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccbf7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# used mostly for nice display formatting, ignore if not needed\n",
    "def get_cited_context(result_obj):\n",
    "    # Dictionary to hold separate citation information for each unique source and title combination\n",
    "    source_with_citations = {}\n",
    "\n",
    "    def highlight_text(context, quote):\n",
    "        # Normalize whitespace and remove unnecessary punctuation\n",
    "        quote = re.sub(r'\\s+', ' ', quote).strip()\n",
    "        context = re.sub(r'\\s+', ' ', context).strip()\n",
    "\n",
    "        # Split quote into phrases, being careful with punctuation\n",
    "        phrases = [phrase.strip() for phrase in re.split(r'[.!?]', quote) if phrase.strip()]\n",
    "\n",
    "        highlighted_context = context\n",
    "\n",
    "        for phrase in phrases: # for each quoted phrase\n",
    "\n",
    "            # Create regex pattern to match cited phrases\n",
    "            # Escape special regex characters, but preserve word boundaries\n",
    "            escaped_phrase = re.escape(phrase)\n",
    "            # Create regex pattern that allows for slight variations\n",
    "            pattern = re.compile(r'\\b' + escaped_phrase + r'\\b', re.IGNORECASE)\n",
    "\n",
    "            # Replace all matched phrases with bolded version\n",
    "            highlighted_context = pattern.sub(lambda m: f\"**{m.group(0)}**\", highlighted_context)\n",
    "\n",
    "        return highlighted_context\n",
    "\n",
    "    # Process the citation data\n",
    "    for cite in result_obj['citations'].dict()['citations']:\n",
    "        cite_id = cite['id']\n",
    "        title = cite['title']\n",
    "        source = cite['source']\n",
    "        page = cite['page']\n",
    "        quote = cite['quotes']\n",
    "\n",
    "        # Check if the (source, title) key exists, and initialize if it doesn't\n",
    "        if (source, title) not in source_with_citations:\n",
    "            source_with_citations[(source, title)] = {\n",
    "                'title': title,\n",
    "                'source': source,\n",
    "                'citations': []\n",
    "            }\n",
    "\n",
    "        # Find or create the citation entry for this unique (id, page) combination\n",
    "        citation_entry = next(\n",
    "            (c for c in source_with_citations[(source, title)]['citations'] if c['id'] == cite_id and c['page'] == page),\n",
    "            None\n",
    "        )\n",
    "        if citation_entry is None:\n",
    "            citation_entry = {'id': cite_id, 'page': page, 'quote': [quote], 'context': None}\n",
    "            source_with_citations[(source, title)]['citations'].append(citation_entry)\n",
    "        else:\n",
    "            citation_entry['quote'].append(quote)\n",
    "\n",
    "    # Process context data\n",
    "    for context in result_obj['context']:\n",
    "        context_id = context.metadata['id']\n",
    "        context_page = context.metadata['page']\n",
    "        source = context.metadata['source']\n",
    "        title = context.metadata['title']\n",
    "        page_content = context.page_content\n",
    "\n",
    "        # Match the context to the correct citation entry by source, title, id, and page\n",
    "        if (source, title) in source_with_citations:\n",
    "            for citation in source_with_citations[(source, title)]['citations']:\n",
    "                if citation['id'] == context_id and citation['page'] == context_page:\n",
    "                    # Apply highlighting for each quote in the citation's quote list\n",
    "                    highlighted_content = page_content\n",
    "                    for quote in citation['quote']:\n",
    "                        highlighted_content = highlight_text(highlighted_content, quote)\n",
    "                    citation['context'] = highlighted_content\n",
    "\n",
    "    # Convert the dictionary to a list of dictionaries for separate entries\n",
    "    final_result_list = [\n",
    "        {\n",
    "            'title': details['title'],\n",
    "            'source': details['source'],\n",
    "            'citations': details['citations']\n",
    "        }\n",
    "        for details in source_with_citations.values()\n",
    "    ]\n",
    "\n",
    "    return final_result_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a7dd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_cited_context(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2dd898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def display_results(result_obj):\n",
    "    print('Query:')\n",
    "    display(Markdown(result_obj['question']))\n",
    "    print()\n",
    "    print('Response:')\n",
    "    display(Markdown(result_obj['answer']))\n",
    "    print('='*50)\n",
    "    print('Sources:')\n",
    "    cited_context = get_cited_context(result_obj)\n",
    "    for source in cited_context:\n",
    "        print('Title:', source['title'], ' ', 'Source:', source['source'])\n",
    "        print('Citations:')\n",
    "        for citation in source['citations']:\n",
    "            print('ID:', citation['id'], ' ', 'Page:', citation['page'])\n",
    "            print('Cited Quotes:')\n",
    "            display(Markdown('*'+' '.join(citation['quote'])+'*'))\n",
    "            print('Cited Context:')\n",
    "            display(Markdown(citation['context']))\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7c0d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9259c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is AI, ML and DL?\"\n",
    "result = rag_chain_w_citations.invoke(query)\n",
    "display_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0600e1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How is Machine learning related to supervised learning and clustering?\"\n",
    "result = rag_chain_w_citations.invoke(query)\n",
    "display_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb44ee37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
