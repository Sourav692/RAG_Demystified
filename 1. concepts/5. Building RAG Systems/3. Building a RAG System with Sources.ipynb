{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df4dbd87",
   "metadata": {},
   "source": [
    "# Build a RAG System with Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8578a03d",
   "metadata": {},
   "source": [
    "For this the section till `rag_prompt_template` would be same like previous `2. Build a Contextual Retrieval based RAG System` Notebook.\n",
    "\n",
    "So we call that notebook and later customize the RAG_Pipeline to get the source context along with answer from RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaef2726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pages: ../../docs/vision_transformer.pdf\n",
      "Chunking pages: ../../docs/vision_transformer.pdf\n",
      "Generating contextual chunks: ../../docs/vision_transformer.pdf\n",
      "Finished processing: ../../docs/vision_transformer.pdf\n",
      "\n",
      "Loading pages: ../../docs/attention_paper.pdf\n",
      "Chunking pages: ../../docs/attention_paper.pdf\n",
      "Generating contextual chunks: ../../docs/attention_paper.pdf\n",
      "Finished processing: ../../docs/attention_paper.pdf\n",
      "\n",
      "Metadata: {'id': '564928', 'page': 1, 'source': 'Wikipedia', 'title': 'Machine learning'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Machine learning gives computers the ability to learn without being explicitly programmed (Arthur Samuel, 1959). It is a subfield of computer science. The idea came from work in artificial intelligence. Machine learning explores the study and construction of algorithms which can learn and make predictions on data. Such algorithms follow programmed instructions, but can also make predictions or decisions based on data. They build a model from sample inputs. Machine learning is done where designing and programming explicit algorithms cannot be done. Examples include spam filtering, detection of network intruders or malicious insiders working towards a data breach, optical character recognition (OCR), search engines and computer vision."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': '564928', 'page': 1, 'source': 'Wikipedia', 'title': 'Machine learning'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Machine learning gives computers the ability to learn without being explicitly programmed (Arthur Samuel, 1959). It is a subfield of computer science. The idea came from work in artificial intelligence. Machine learning explores the study and construction of algorithms which can learn and make predictions on data. Such algorithms follow programmed instructions, but can also make predictions or decisions based on data. They build a model from sample inputs. Machine learning is done where designing and programming explicit algorithms cannot be done. Examples include spam filtering, detection of network intruders or malicious insiders working towards a data breach, optical character recognition (OCR), search engines and computer vision."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': '359370', 'page': 1, 'source': 'Wikipedia', 'title': 'Supervised learning'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "In machine learning, supervised learning is the task of inferring a function from labelled training data. The results of the training are known beforehand, the system simply learns how to get to these results correctly. Usually, such systems work with vectors. They get the training data and the result of the training as two vectors and produce a \"classifier\". Usually, the system uses inductive reasoning to generalize the training data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': '359370', 'page': 1, 'source': 'Wikipedia', 'title': 'Supervised learning'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "In machine learning, supervised learning is the task of inferring a function from labelled training data. The results of the training are known beforehand, the system simply learns how to get to these results correctly. Usually, such systems work with vectors. They get the training data and the result of the training as two vectors and produce a \"classifier\". Usually, the system uses inductive reasoning to generalize the training data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': '663523', 'page': 1, 'source': 'Wikipedia', 'title': 'Deep learning'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Deep learning (also called deep structured learning or hierarchical learning) is a kind of machine learning, which is mostly used with certain kinds of neural networks. As with other kinds of machine-learning, learning sessions can be unsupervised, semi-supervised, or supervised. In many cases, structures are organised so that there is at least one intermediate layer (or hidden layer), between the input layer and the output layer. Certain tasks, such as as recognizing and understanding speech, images or handwriting, is easy to do for humans. However, for a computer, these tasks are very difficult to do. In a multi-layer neural network (having more than two layers), the information processed will become more abstract with each added layer. Deep learning models are inspired by information processing and communication patterns in biological nervous systems; they are different from the structural and functional properties of biological brains (especially the human brain) in many ways, whic"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': '5b62f899-a41f-4452-8c51-82407866b9b5', 'page': 7, 'source': '../../docs/vision_transformer.pdf', 'title': 'vision_transformer.pdf'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Focuses on a controlled scaling study of various models, including Vision Transformers and ResNets, to evaluate their transfer performance from the JFT-300M dataset. It highlights the performance versus pre-training cost, revealing that Vision Transformers generally outperform ResNets in terms of efficiency and scalability. Additionally, it discusses the implications of hybrid models and the potential for further scaling of Vision Transformers.\n",
       "Published as a conference paper at ICLR 2021\n",
       "4.4\n",
       "SCALING STUDY\n",
       "We perform a controlled scaling study of different models by evaluating transfer performance from\n",
       "JFT-300M. In this setting data size does not bottleneck the models’ performances, and we assess\n",
       "performance versus pre-training cost of each model. The model set includes: 7 ResNets, R50x1,\n",
       "R50x2 R101x1, R152x1, R152x2, pre-trained for 7 epochs, plus R152x2 and R200x3 pre-trained\n",
       "for 14 epochs; 6 Vision Transformers, ViT-B/32, B/16, L/32, L/16, pre-trained for 7 epochs, plus\n",
       "L/16 and H/1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': 'f67497d2-411f-465b-84c4-c686183e95fd', 'page': 0, 'source': '../../docs/vision_transformer.pdf', 'title': 'vision_transformer.pdf'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Focuses on the introduction of the Vision Transformer (ViT) model, which applies a standard Transformer architecture directly to image classification tasks by treating image patches as tokens. It highlights the limitations of traditional convolutional neural networks (CNNs) in computer vision and presents evidence that ViT can achieve competitive performance on various benchmarks with fewer computational resources when pre-trained on large datasets.\n",
       "Published as a conference paper at ICLR 2021\n",
       "AN IMAGE IS WORTH 16X16 WORDS:\n",
       "TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE\n",
       "Alexey Dosovitskiy∗,†, Lucas Beyer∗, Alexander Kolesnikov∗, Dirk Weissenborn∗,\n",
       "Xiaohua Zhai∗, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer,\n",
       "Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby∗,†\n",
       "∗equal technical contribution, †equal advising\n",
       "Google Research, Brain Team\n",
       "{adosovitskiy, neilhoulsby}@google.com\n",
       "ABSTRACT\n",
       "While the Transformer architecture has become the de-facto standard for natural\n",
       "language "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': 'd2790ead-3861-48ff-88be-ffa027116619', 'page': 7, 'source': '../../docs/vision_transformer.pdf', 'title': 'vision_transformer.pdf'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Focuses on a controlled scaling study of various models, including Vision Transformers and ResNets, evaluating their transfer performance from the JFT-300M dataset. It highlights the performance versus pre-training cost, revealing that Vision Transformers generally outperform ResNets in terms of efficiency and scalability. Additionally, it discusses the implications of these findings for future scaling efforts in model architecture.\n",
       "Published as a conference paper at ICLR 2021\n",
       "4.4\n",
       "SCALING STUDY\n",
       "We perform a controlled scaling study of different models by evaluating transfer performance from\n",
       "JFT-300M. In this setting data size does not bottleneck the models’ performances, and we assess\n",
       "performance versus pre-training cost of each model. The model set includes: 7 ResNets, R50x1,\n",
       "R50x2 R101x1, R152x1, R152x2, pre-trained for 7 epochs, plus R152x2 and R200x3 pre-trained\n",
       "for 14 epochs; 6 Vision Transformers, ViT-B/32, B/16, L/32, L/16, pre-trained for 7 epochs, plus\n",
       "L/16 and H/14 pre-traine"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': '5633ed0f-6c0b-4e4c-b425-8744e88f3510', 'page': 0, 'source': '../../docs/vision_transformer.pdf', 'title': 'vision_transformer.pdf'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Focuses on introducing the Vision Transformer (ViT) as a novel approach for image recognition, highlighting its ability to perform well on classification tasks by applying a standard Transformer architecture directly to sequences of image patches. It contrasts the reliance on convolutional neural networks (CNNs) in computer vision and emphasizes the advantages of using Transformers, particularly when pre-trained on large datasets.\n",
       "Published as a conference paper at ICLR 2021\n",
       "AN IMAGE IS WORTH 16X16 WORDS:\n",
       "TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE\n",
       "Alexey Dosovitskiy∗,†, Lucas Beyer∗, Alexander Kolesnikov∗, Dirk Weissenborn∗,\n",
       "Xiaohua Zhai∗, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer,\n",
       "Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby∗,†\n",
       "∗equal technical contribution, †equal advising\n",
       "Google Research, Brain Team\n",
       "{adosovitskiy, neilhoulsby}@google.com\n",
       "ABSTRACT\n",
       "While the Transformer architecture has become the de-facto standard for natural\n",
       "language processing tasks, i"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': '70f0e7bc-ac29-485f-9b36-d5196619fa29', 'page': 2, 'source': '../../docs/vision_transformer.pdf', 'title': 'vision_transformer.pdf'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Focuses on the architecture and methodology of the Vision Transformer (ViT), detailing how images are processed by splitting them into patches, embedding them, and utilizing a standard Transformer encoder for image classification tasks. It describes the model's design principles, including the use of position embeddings and the classification head, while referencing foundational work in Transformer architecture.\n",
       "Published as a conference paper at ICLR 2021\n",
       "Transformer Encoder\n",
       "MLP \n",
       "Head\n",
       "Vision Transformer (ViT)\n",
       "*\n",
       "Linear Projection of Flattened Patches\n",
       "* Extra learnable\n",
       "     [ cl ass]  embedding\n",
       "1\n",
       "2\n",
       "3\n",
       "4\n",
       "5\n",
       "6\n",
       "7\n",
       "8\n",
       "9\n",
       "0\n",
       "Patch + Position \n",
       "Embedding\n",
       "Class\n",
       "Bird\n",
       "Ball\n",
       "Car\n",
       "...\n",
       "Embedded \n",
       "Patches\n",
       "Multi-Head \n",
       "Attention\n",
       "Norm\n",
       "MLP\n",
       "Norm\n",
       "+\n",
       "L x\n",
       "+\n",
       "Transformer Encoder\n",
       "Figure 1: Model overview. We split an image into ﬁxed-size patches, linearly embed each of them,\n",
       "add position embeddings, and feed the resulting sequence of vectors to a standard Transformer\n",
       "encoder. In order to perform classiﬁcation, we use the"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Machine learning is a subfield of computer science that provides computers the ability to learn without being explicitly programmed, a concept first articulated by Arthur Samuel in 1959. It originated from research in artificial intelligence and focuses on the study and construction of algorithms that can learn from and make predictions based on data. \n",
       "\n",
       "These algorithms operate by following programmed instructions while also being capable of making predictions or decisions based on the data they process. They build models from sample inputs, which allows them to function in scenarios where explicit algorithm design and programming are not feasible. \n",
       "\n",
       "Examples of machine learning applications include:\n",
       "- Spam filtering\n",
       "- Detection of network intruders or malicious insiders\n",
       "- Optical character recognition (OCR)\n",
       "- Search engines\n",
       "- Computer vision\n",
       "\n",
       "Within machine learning, there are various approaches, including supervised learning, which involves inferring a function from labeled training data. In supervised learning, the outcomes of the training are known in advance, and the system learns to achieve these results correctly, often using vectors to represent training data and outcomes.\n",
       "\n",
       "Additionally, deep learning is a specialized area of machine learning that utilizes neural networks, often with multiple layers (known as deep structured learning). This approach is particularly effective for complex tasks such as speech recognition, image understanding, and handwriting recognition, which are challenging for computers but relatively easy for humans. Deep learning models are inspired by the information processing patterns of biological nervous systems, although they differ significantly from the structural and functional properties of biological brains."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The term \"CNN\" can refer to two different concepts based on the context provided:\n",
       "\n",
       "1. **Cable News Network (CNN)**: This is an American cable news television channel founded in 1980 by Ted Turner. CNN first aired on June 1, 1980, and its inaugural newscast was anchored by David Walker and Lois Hart. It was notable for being the first 24-hour news channel and has since become a significant player in the news broadcasting industry. CNN broadcasts from various locations, including its headquarters in Atlanta, the Time Warner Center in New York City, and studios in Washington, D.C., and Los Angeles. The network has been both praised and criticized for its perceived political biases.\n",
       "\n",
       "2. **Convolutional Neural Network (CNN)**: Although not explicitly mentioned in the provided context, a CNN in the field of artificial intelligence typically refers to a type of deep learning model used primarily for processing structured grid data such as images. Convolutional Neural Networks are designed to automatically and adaptively learn spatial hierarchies of features from images, making them highly effective for tasks like image recognition and classification.\n",
       "\n",
       "If you are looking for information specifically about Convolutional Neural Networks, I don't have that information in the provided context."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The provided context does not contain specific information comparing ResNet and CNNs directly. However, it does mention the Vision Transformer (ViT) and its differences from CNNs, particularly in terms of inductive bias and architecture. \n",
       "\n",
       "Here are some key points regarding how ResNet (a type of CNN) might be considered better or different from traditional CNNs based on the context:\n",
       "\n",
       "1. **Inductive Bias**: The context highlights that CNNs, including ResNet, have a strong inductive bias due to their architecture, which incorporates locality, two-dimensional neighborhood structure, and translation equivariance. This means that CNNs are designed to take advantage of the spatial structure of images, which can lead to better performance on image-related tasks.\n",
       "\n",
       "2. **Performance Metrics**: The context provides performance metrics for various models, including ResNet and ViT, across multiple datasets. It indicates that ResNet models achieve high accuracy on tasks like image classification, which suggests that they are effective in their domain.\n",
       "\n",
       "3. **Computational Cost**: The context mentions that ViT performs favorably in terms of computational cost compared to ResNet when pre-training on large datasets. This implies that while ResNet is effective, ViT may offer advantages in certain scenarios, particularly in terms of resource efficiency.\n",
       "\n",
       "4. **Hybrid Models**: The context discusses hybrid architectures that combine CNN feature maps with ViT, suggesting that there are ways to leverage the strengths of both architectures. This indicates that ResNet can be part of a more complex system that may outperform traditional CNNs alone.\n",
       "\n",
       "In summary, while the context does not provide a direct comparison of ResNet to CNNs in terms of superiority, it does imply that ResNet benefits from its architectural design and inductive biases, which are crucial for image processing tasks. For a more detailed comparison, additional specific information would be needed."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "I don't know."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "I don't know."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The context provided does not contain specific information about an \"Agentic AI System.\" Therefore, I don't know what an Agentic AI System is."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "I don't know."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run '2. Build a Contextual Retrieval based RAG System.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7128c313",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from operator import itemgetter\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# src_rag_response_chain is a chain that:\n",
    "# 1. Takes a dictionary with 'context' and 'question' keys.\n",
    "# 2. Formats the 'context' (list of docs) into a single string using format_docs.\n",
    "# 3. Passes the formatted context and question into the rag_prompt_template.\n",
    "# 4. Sends the prompt to the chatgpt LLM.\n",
    "# 5. Parses the LLM output into a string.\n",
    "src_rag_response_chain = (\n",
    "    {\n",
    "        \"context\": (itemgetter('context') | RunnableLambda(format_docs)),\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    }\n",
    "    | rag_prompt_template\n",
    "    | chatgpt\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# rag_chain_w_sources is a higher-level chain that:\n",
    "# 1. Retrieves relevant documents using similarity_retriever for the 'context'.\n",
    "# 2. Passes the original question through unchanged.\n",
    "# 3. Runs src_rag_response_chain to generate the answer, and assigns the result to a new 'response' key.\n",
    "# This allows you to get both the answer and the source context used for the answer.\n",
    "rag_chain_w_sources = (\n",
    "    {\n",
    "        \"context\": similarity_retriever,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "    | RunnablePassthrough.assign(response=src_rag_response_chain)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ff79460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(metadata={'id': '564928', 'page': 1, 'source': 'Wikipedia', 'title': 'Machine learning'}, page_content='Machine learning gives computers the ability to learn without being explicitly programmed (Arthur Samuel, 1959). It is a subfield of computer science. The idea came from work in artificial intelligence. Machine learning explores the study and construction of algorithms which can learn and make predictions on data. Such algorithms follow programmed instructions, but can also make predictions or decisions based on data. They build a model from sample inputs. Machine learning is done where designing and programming explicit algorithms cannot be done. Examples include spam filtering, detection of network intruders or malicious insiders working towards a data breach, optical character recognition (OCR), search engines and computer vision.'),\n",
       "  Document(metadata={'id': '564928', 'page': 1, 'source': 'Wikipedia', 'title': 'Machine learning'}, page_content='Machine learning gives computers the ability to learn without being explicitly programmed (Arthur Samuel, 1959). It is a subfield of computer science. The idea came from work in artificial intelligence. Machine learning explores the study and construction of algorithms which can learn and make predictions on data. Such algorithms follow programmed instructions, but can also make predictions or decisions based on data. They build a model from sample inputs. Machine learning is done where designing and programming explicit algorithms cannot be done. Examples include spam filtering, detection of network intruders or malicious insiders working towards a data breach, optical character recognition (OCR), search engines and computer vision.'),\n",
       "  Document(metadata={'id': '359370', 'page': 1, 'source': 'Wikipedia', 'title': 'Supervised learning'}, page_content='In machine learning, supervised learning is the task of inferring a function from labelled training data. The results of the training are known beforehand, the system simply learns how to get to these results correctly. Usually, such systems work with vectors. They get the training data and the result of the training as two vectors and produce a \"classifier\". Usually, the system uses inductive reasoning to generalize the training data.'),\n",
       "  Document(metadata={'id': '359370', 'page': 1, 'source': 'Wikipedia', 'title': 'Supervised learning'}, page_content='In machine learning, supervised learning is the task of inferring a function from labelled training data. The results of the training are known beforehand, the system simply learns how to get to these results correctly. Usually, such systems work with vectors. They get the training data and the result of the training as two vectors and produce a \"classifier\". Usually, the system uses inductive reasoning to generalize the training data.'),\n",
       "  Document(metadata={'id': '663523', 'page': 1, 'source': 'Wikipedia', 'title': 'Deep learning'}, page_content='Deep learning (also called deep structured learning or hierarchical learning) is a kind of machine learning, which is mostly used with certain kinds of neural networks. As with other kinds of machine-learning, learning sessions can be unsupervised, semi-supervised, or supervised. In many cases, structures are organised so that there is at least one intermediate layer (or hidden layer), between the input layer and the output layer. Certain tasks, such as as recognizing and understanding speech, images or handwriting, is easy to do for humans. However, for a computer, these tasks are very difficult to do. In a multi-layer neural network (having more than two layers), the information processed will become more abstract with each added layer. Deep learning models are inspired by information processing and communication patterns in biological nervous systems; they are different from the structural and functional properties of biological brains (especially the human brain) in many ways, which make them incompatible with neuroscience evidences.')],\n",
       " 'question': 'What is machine learning?',\n",
       " 'response': 'Machine learning is a subfield of computer science that provides computers with the ability to learn without being explicitly programmed, a concept first articulated by Arthur Samuel in 1959. It originated from research in artificial intelligence and focuses on the study and construction of algorithms that can learn from and make predictions based on data.\\n\\nKey aspects of machine learning include:\\n\\n- **Learning from Data**: Machine learning algorithms build models from sample inputs, allowing them to make predictions or decisions based on new data. This is particularly useful in scenarios where designing and programming explicit algorithms is impractical.\\n\\n- **Types of Learning**: \\n  - **Supervised Learning**: This involves inferring a function from labeled training data, where the results are known beforehand. The system learns to reach these results correctly, typically using vectors to represent training data and outcomes, and produces a \"classifier\" through inductive reasoning.\\n  - **Deep Learning**: A specialized form of machine learning that utilizes neural networks with multiple layers (deep structured learning). It is particularly effective for complex tasks such as speech recognition, image understanding, and handwriting recognition. Deep learning models process information in a hierarchical manner, becoming more abstract with each additional layer.\\n\\n- **Applications**: Machine learning is applied in various domains, including spam filtering, network intrusion detection, optical character recognition (OCR), search engines, and computer vision.\\n\\nOverall, machine learning enables systems to improve their performance on tasks through experience, making it a powerful tool in modern computing.'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is machine learning?\"\n",
    "result = rag_chain_w_sources.invoke(query)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0c1b735",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def display_results(result_obj):\n",
    "    print('Query:')\n",
    "    display(Markdown(result_obj['question']))\n",
    "    print()\n",
    "    print('Response:')\n",
    "    display(Markdown(result_obj['response']))\n",
    "    print('='*50)\n",
    "    print('Sources:')\n",
    "    for source in result_obj['context']:\n",
    "        print('Metadata:', source.metadata)\n",
    "        print('Content Brief:')\n",
    "        display(Markdown(source.page_content))\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8192c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "What is machine learning?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Machine learning is a subfield of computer science that provides computers the ability to learn without being explicitly programmed, a concept first articulated by Arthur Samuel in 1959. It originated from research in artificial intelligence and focuses on the study and construction of algorithms that can learn from and make predictions based on data. \n",
       "\n",
       "These algorithms operate by following programmed instructions while also being capable of making predictions or decisions based on the data they process. They build a model from sample inputs, which allows them to function in scenarios where designing and programming explicit algorithms is not feasible. \n",
       "\n",
       "Examples of machine learning applications include:\n",
       "- Spam filtering\n",
       "- Detection of network intruders or malicious insiders\n",
       "- Optical character recognition (OCR)\n",
       "- Search engines\n",
       "- Computer vision\n",
       "\n",
       "Within machine learning, there are various approaches, including supervised learning, which involves inferring a function from labeled training data. In supervised learning, the outcomes of the training are known in advance, and the system learns to achieve these results correctly, typically using vectors to process the training data and outcomes.\n",
       "\n",
       "Additionally, deep learning is a specialized area of machine learning that utilizes neural networks, often with multiple layers (known as deep structured learning). This approach is particularly effective for complex tasks such as speech recognition, image understanding, and handwriting recognition, which are challenging for computers but relatively easy for humans. Deep learning models are inspired by the information processing patterns of biological nervous systems, although they differ significantly from the structural and functional properties of biological brains."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Sources:\n",
      "Metadata: {'id': '564928', 'page': 1, 'source': 'Wikipedia', 'title': 'Machine learning'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Machine learning gives computers the ability to learn without being explicitly programmed (Arthur Samuel, 1959). It is a subfield of computer science. The idea came from work in artificial intelligence. Machine learning explores the study and construction of algorithms which can learn and make predictions on data. Such algorithms follow programmed instructions, but can also make predictions or decisions based on data. They build a model from sample inputs. Machine learning is done where designing and programming explicit algorithms cannot be done. Examples include spam filtering, detection of network intruders or malicious insiders working towards a data breach, optical character recognition (OCR), search engines and computer vision."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': '564928', 'page': 1, 'source': 'Wikipedia', 'title': 'Machine learning'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Machine learning gives computers the ability to learn without being explicitly programmed (Arthur Samuel, 1959). It is a subfield of computer science. The idea came from work in artificial intelligence. Machine learning explores the study and construction of algorithms which can learn and make predictions on data. Such algorithms follow programmed instructions, but can also make predictions or decisions based on data. They build a model from sample inputs. Machine learning is done where designing and programming explicit algorithms cannot be done. Examples include spam filtering, detection of network intruders or malicious insiders working towards a data breach, optical character recognition (OCR), search engines and computer vision."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': '359370', 'page': 1, 'source': 'Wikipedia', 'title': 'Supervised learning'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "In machine learning, supervised learning is the task of inferring a function from labelled training data. The results of the training are known beforehand, the system simply learns how to get to these results correctly. Usually, such systems work with vectors. They get the training data and the result of the training as two vectors and produce a \"classifier\". Usually, the system uses inductive reasoning to generalize the training data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': '359370', 'page': 1, 'source': 'Wikipedia', 'title': 'Supervised learning'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "In machine learning, supervised learning is the task of inferring a function from labelled training data. The results of the training are known beforehand, the system simply learns how to get to these results correctly. Usually, such systems work with vectors. They get the training data and the result of the training as two vectors and produce a \"classifier\". Usually, the system uses inductive reasoning to generalize the training data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': '663523', 'page': 1, 'source': 'Wikipedia', 'title': 'Deep learning'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Deep learning (also called deep structured learning or hierarchical learning) is a kind of machine learning, which is mostly used with certain kinds of neural networks. As with other kinds of machine-learning, learning sessions can be unsupervised, semi-supervised, or supervised. In many cases, structures are organised so that there is at least one intermediate layer (or hidden layer), between the input layer and the output layer. Certain tasks, such as as recognizing and understanding speech, images or handwriting, is easy to do for humans. However, for a computer, these tasks are very difficult to do. In a multi-layer neural network (having more than two layers), the information processed will become more abstract with each added layer. Deep learning models are inspired by information processing and communication patterns in biological nervous systems; they are different from the structural and functional properties of biological brains (especially the human brain) in many ways, which make them incompatible with neuroscience evidences."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is machine learning?\"\n",
    "result = rag_chain_w_sources.invoke(query)\n",
    "display_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20e63ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "What is the difference between AI, ML and DL?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The differences between Artificial Intelligence (AI), Machine Learning (ML), and Deep Learning (DL) can be summarized as follows:\n",
       "\n",
       "### 1. Artificial Intelligence (AI)\n",
       "- **Definition**: AI refers to the ability of a computer program or machine to think and learn, mimicking human cognition. It encompasses a broad range of technologies and applications aimed at making machines \"smart.\"\n",
       "- **Origin**: The term \"Artificial Intelligence\" was coined by John McCarthy in 1955.\n",
       "- **Functionality**: AI systems can interpret external data, learn from it, and adapt to achieve specific goals. They can perform tasks that typically require human intelligence, such as learning and problem-solving.\n",
       "- **Examples**: AI includes various applications, but as machines become more capable, some tasks (like optical character recognition) are no longer classified as AI.\n",
       "\n",
       "### 2. Machine Learning (ML)\n",
       "- **Definition**: ML is a subfield of AI that focuses on the study and construction of algorithms that allow computers to learn from data without being explicitly programmed.\n",
       "- **Functionality**: ML algorithms build models from sample inputs and can make predictions or decisions based on data. They are particularly useful in scenarios where traditional programming is impractical.\n",
       "- **Examples**: Applications of ML include spam filtering, network intrusion detection, optical character recognition (OCR), search engines, and computer vision.\n",
       "\n",
       "### 3. Deep Learning (DL)\n",
       "- **Definition**: DL is a specialized subset of ML that primarily uses neural networks with multiple layers (multi-layer neural networks) to process data.\n",
       "- **Functionality**: In DL, information is processed through several layers, with each layer transforming the data into more abstract representations. This approach is particularly effective for complex tasks such as speech and image recognition.\n",
       "- **Characteristics**: DL models are inspired by the information processing patterns of biological nervous systems, although they differ significantly from the structural and functional properties of human brains.\n",
       "\n",
       "### Summary\n",
       "- **AI** is the overarching field that includes any technique enabling machines to mimic human intelligence.\n",
       "- **ML** is a subset of AI that focuses on algorithms that learn from data.\n",
       "- **DL** is a further specialization within ML that utilizes deep neural networks to handle complex data processing tasks. \n",
       "\n",
       "In essence, while all three terms are interconnected, they represent different levels of complexity and specialization in the field of computer science."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Sources:\n",
      "Metadata: {'id': '663523', 'page': 1, 'source': 'Wikipedia', 'title': 'Deep learning'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Deep learning (also called deep structured learning or hierarchical learning) is a kind of machine learning, which is mostly used with certain kinds of neural networks. As with other kinds of machine-learning, learning sessions can be unsupervised, semi-supervised, or supervised. In many cases, structures are organised so that there is at least one intermediate layer (or hidden layer), between the input layer and the output layer. Certain tasks, such as as recognizing and understanding speech, images or handwriting, is easy to do for humans. However, for a computer, these tasks are very difficult to do. In a multi-layer neural network (having more than two layers), the information processed will become more abstract with each added layer. Deep learning models are inspired by information processing and communication patterns in biological nervous systems; they are different from the structural and functional properties of biological brains (especially the human brain) in many ways, which make them incompatible with neuroscience evidences."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': '663523', 'page': 1, 'source': 'Wikipedia', 'title': 'Deep learning'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Deep learning (also called deep structured learning or hierarchical learning) is a kind of machine learning, which is mostly used with certain kinds of neural networks. As with other kinds of machine-learning, learning sessions can be unsupervised, semi-supervised, or supervised. In many cases, structures are organised so that there is at least one intermediate layer (or hidden layer), between the input layer and the output layer. Certain tasks, such as as recognizing and understanding speech, images or handwriting, is easy to do for humans. However, for a computer, these tasks are very difficult to do. In a multi-layer neural network (having more than two layers), the information processed will become more abstract with each added layer. Deep learning models are inspired by information processing and communication patterns in biological nervous systems; they are different from the structural and functional properties of biological brains (especially the human brain) in many ways, which make them incompatible with neuroscience evidences."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': '564928', 'page': 1, 'source': 'Wikipedia', 'title': 'Machine learning'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Machine learning gives computers the ability to learn without being explicitly programmed (Arthur Samuel, 1959). It is a subfield of computer science. The idea came from work in artificial intelligence. Machine learning explores the study and construction of algorithms which can learn and make predictions on data. Such algorithms follow programmed instructions, but can also make predictions or decisions based on data. They build a model from sample inputs. Machine learning is done where designing and programming explicit algorithms cannot be done. Examples include spam filtering, detection of network intruders or malicious insiders working towards a data breach, optical character recognition (OCR), search engines and computer vision."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': '564928', 'page': 1, 'source': 'Wikipedia', 'title': 'Machine learning'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Machine learning gives computers the ability to learn without being explicitly programmed (Arthur Samuel, 1959). It is a subfield of computer science. The idea came from work in artificial intelligence. Machine learning explores the study and construction of algorithms which can learn and make predictions on data. Such algorithms follow programmed instructions, but can also make predictions or decisions based on data. They build a model from sample inputs. Machine learning is done where designing and programming explicit algorithms cannot be done. Examples include spam filtering, detection of network intruders or malicious insiders working towards a data breach, optical character recognition (OCR), search engines and computer vision."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': '6360', 'page': 1, 'source': 'Wikipedia', 'title': 'Artificial intelligence'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Artificial intelligence (AI) is the ability of a computer program or a machine to think and learn. It is also a field of study which tries to make computers \"smart\". They work on their own without being encoded with commands. John McCarthy came up with the name \"Artificial Intelligence\" in 1955. In general use, the term \"artificial intelligence\" means a programme which mimics human cognition. At least some of the things we associate with other minds, such as learning and problem solving can be done by computers, though not in the same way as we do. Andreas Kaplan and Michael Haenlein define AI as a system’s ability to correctly interpret external data, to learn from such data, and to use those learnings to achieve specific goals and tasks through flexible adaptation. An ideal (perfect) intelligent machine is a flexible agent which perceives its environment and takes actions to maximize its chance of success at some goal or objective. As machines become increasingly capable, mental faculties once thought to require intelligence are removed from the definition. For example, optical character recognition is no longer perceived as an example of \"artificial intelligence\": it is just a routine technology."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the difference between AI, ML and DL?\"\n",
    "result = rag_chain_w_sources.invoke(query)\n",
    "display_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ffba63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "What is the difference between transformers and vision transformers?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The difference between transformers and vision transformers (ViTs) primarily lies in their application and the way they process input data.\n",
       "\n",
       "1. **Architecture and Input Handling**:\n",
       "   - **Transformers**: Originally designed for natural language processing (NLP), transformers operate on sequences of tokens (words) and utilize self-attention mechanisms to capture relationships between these tokens. The input is typically a sequence of word embeddings derived from a text corpus.\n",
       "   - **Vision Transformers (ViTs)**: ViTs adapt the transformer architecture for image classification tasks by treating image patches as tokens. An image is divided into fixed-size patches, which are then flattened and linearly embedded into a sequence of vectors. This sequence is fed into a standard transformer encoder, allowing the model to process the image as a sequence of patch embeddings.\n",
       "\n",
       "2. **Positional Information**:\n",
       "   - In traditional transformers, positional embeddings are used to maintain the order of tokens in a sequence. \n",
       "   - ViTs also incorporate positional embeddings to retain spatial information about the image patches, ensuring that the model understands the relative positions of these patches within the image.\n",
       "\n",
       "3. **Performance and Efficiency**:\n",
       "   - The context indicates that ViTs generally outperform traditional convolutional neural networks (CNNs) like ResNets in terms of efficiency and scalability when pre-trained on large datasets. ViTs can achieve competitive performance with fewer computational resources compared to CNNs, which have been the dominant architecture in computer vision.\n",
       "\n",
       "4. **Integration of Information**:\n",
       "   - ViTs leverage self-attention to integrate information across the entire image, even in the early layers of the model. This capability allows them to capture global context effectively, which is a significant advantage over traditional CNNs that typically focus on local features.\n",
       "\n",
       "In summary, while both transformers and vision transformers share a foundational architecture based on self-attention, they differ in their input types, the way they handle spatial information, and their applications in NLP versus computer vision tasks."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Sources:\n",
      "Metadata: {'id': '5b62f899-a41f-4452-8c51-82407866b9b5', 'page': 7, 'source': '../../docs/vision_transformer.pdf', 'title': 'vision_transformer.pdf'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Focuses on a controlled scaling study of various models, including Vision Transformers and ResNets, to evaluate their transfer performance from the JFT-300M dataset. It highlights the performance versus pre-training cost, revealing that Vision Transformers generally outperform ResNets in terms of efficiency and scalability. Additionally, it discusses the implications of hybrid models and the potential for further scaling of Vision Transformers.\n",
       "Published as a conference paper at ICLR 2021\n",
       "4.4\n",
       "SCALING STUDY\n",
       "We perform a controlled scaling study of different models by evaluating transfer performance from\n",
       "JFT-300M. In this setting data size does not bottleneck the models’ performances, and we assess\n",
       "performance versus pre-training cost of each model. The model set includes: 7 ResNets, R50x1,\n",
       "R50x2 R101x1, R152x1, R152x2, pre-trained for 7 epochs, plus R152x2 and R200x3 pre-trained\n",
       "for 14 epochs; 6 Vision Transformers, ViT-B/32, B/16, L/32, L/16, pre-trained for 7 epochs, plus\n",
       "L/16 and H/14 pre-trained for 14 epochs; and 5 hybrids, R50+ViT-B/32, B/16, L/32, L/16 pre-\n",
       "trained for 7 epochs, plus R50+ViT-L/16 pre-trained for 14 epochs (for hybrids, the number at the\n",
       "end of the model name stands not for the patch size, but for the total dowsampling ratio in the ResNet\n",
       "backbone).\n",
       "Figure 5 contains the transfer performance versus total pre-training compute (see Appendix D.5\n",
       "for details on computational costs). Detailed results per model are provided in Table 6 in the Ap-\n",
       "pendix. A few patterns can be observed. First, Vision Transformers dominate ResNets on the\n",
       "performance/compute trade-off. ViT uses approximately 2 −4× less compute to attain the same\n",
       "performance (average over 5 datasets). Second, hybrids slightly outperform ViT at small compu-\n",
       "tational budgets, but the difference vanishes for larger models. This result is somewhat surprising,\n",
       "since one might expect convolutional local feature processing to assist ViT at any size. Third, Vision\n",
       "Transformers appear not to saturate within the range tried, motivating future scaling efforts.\n",
       "4.5\n",
       "INSPECTING VISION TRANSFORMER\n",
       "Input\n",
       "Attention\n",
       "Figure 6: Representative ex-\n",
       "amples of attention from the\n",
       "output token to the input\n",
       "space. See Appendix D.7 for\n",
       "details.\n",
       "To begin to understand how the Vision Transformer processes im-\n",
       "age data, we analyze its internal representations. The ﬁrst layer of\n",
       "the Vision Transformer linearly projects the ﬂattened patches into a\n",
       "lower-dimensional space (Eq. 1). Figure 7 (left) shows the top prin-\n",
       "cipal components of the the learned embedding ﬁlters. The com-\n",
       "ponents resemble plausible basis functions for a low-dimensional\n",
       "representation of the ﬁne structure within each patch.\n",
       "After the projection, a learned position embedding is added to the\n",
       "patch representations. Figure 7 (center) shows that the model learns\n",
       "to encode distance within the image in the similarity of position em-\n",
       "beddings, i.e. closer patches tend to have more similar position em-\n",
       "beddings. Further, the row-column structure appears; patches in the\n",
       "same row/column have similar embeddings. Finally, a sinusoidal\n",
       "structure is sometimes apparent for larger grids (Appendix D). That\n",
       "the position embeddings learn to represent 2D image topology ex-\n",
       "plains why hand-crafted 2D-aware embedding variants do not yield\n",
       "improvements (Appendix D.4).\n",
       "Self-attention allows ViT to integrate information across the entire\n",
       "image even in the lowest layers. We investigate to what degree\n",
       "the network makes use of this capability. Speciﬁcally, we compute\n",
       "the average distance in image space across which information is\n",
       "integrated, based on the attention weights (Figure 7, right). This\n",
       "“attention distance” is analogous to receptive ﬁeld size in CNNs.\n",
       "We ﬁnd that some heads attend to most of the image already in the lowest layers, showing that\n",
       "the ability to integrate information globally is indeed used by the model. Other attention heads"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': 'f67497d2-411f-465b-84c4-c686183e95fd', 'page': 0, 'source': '../../docs/vision_transformer.pdf', 'title': 'vision_transformer.pdf'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Focuses on the introduction of the Vision Transformer (ViT) model, which applies a standard Transformer architecture directly to image classification tasks by treating image patches as tokens. It highlights the limitations of traditional convolutional neural networks (CNNs) in computer vision and presents evidence that ViT can achieve competitive performance on various benchmarks with fewer computational resources when pre-trained on large datasets.\n",
       "Published as a conference paper at ICLR 2021\n",
       "AN IMAGE IS WORTH 16X16 WORDS:\n",
       "TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE\n",
       "Alexey Dosovitskiy∗,†, Lucas Beyer∗, Alexander Kolesnikov∗, Dirk Weissenborn∗,\n",
       "Xiaohua Zhai∗, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer,\n",
       "Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby∗,†\n",
       "∗equal technical contribution, †equal advising\n",
       "Google Research, Brain Team\n",
       "{adosovitskiy, neilhoulsby}@google.com\n",
       "ABSTRACT\n",
       "While the Transformer architecture has become the de-facto standard for natural\n",
       "language processing tasks, its applications to computer vision remain limited. In\n",
       "vision, attention is either applied in conjunction with convolutional networks, or\n",
       "used to replace certain components of convolutional networks while keeping their\n",
       "overall structure in place. We show that this reliance on CNNs is not necessary\n",
       "and a pure transformer applied directly to sequences of image patches can perform\n",
       "very well on image classiﬁcation tasks. When pre-trained on large amounts of\n",
       "data and transferred to multiple mid-sized or small image recognition benchmarks\n",
       "(ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent\n",
       "results compared to state-of-the-art convolutional networks while requiring sub-\n",
       "stantially fewer computational resources to train.1\n",
       "1\n",
       "INTRODUCTION\n",
       "Self-attention-based architectures, in particular Transformers (Vaswani et al., 2017), have become\n",
       "the model of choice in natural language processing (NLP). The dominant approach is to pre-train on\n",
       "a large text corpus and then ﬁne-tune on a smaller task-speciﬁc dataset (Devlin et al., 2019). Thanks\n",
       "to Transformers’ computational efﬁciency and scalability, it has become possible to train models of\n",
       "unprecedented size, with over 100B parameters (Brown et al., 2020; Lepikhin et al., 2020). With the\n",
       "models and datasets growing, there is still no sign of saturating performance.\n",
       "In computer vision, however, convolutional architectures remain dominant (LeCun et al., 1989;\n",
       "Krizhevsky et al., 2012; He et al., 2016). Inspired by NLP successes, multiple works try combining\n",
       "CNN-like architectures with self-attention (Wang et al., 2018; Carion et al., 2020), some replacing\n",
       "the convolutions entirely (Ramachandran et al., 2019; Wang et al., 2020a). The latter models, while\n",
       "theoretically efﬁcient, have not yet been scaled effectively on modern hardware accelerators due to\n",
       "the use of specialized attention patterns. Therefore, in large-scale image recognition, classic ResNet-\n",
       "like architectures are still state of the art (Mahajan et al., 2018; Xie et al., 2020; Kolesnikov et al.,\n",
       "2020).\n",
       "Inspired by the Transformer scaling successes in NLP, we experiment with applying a standard\n",
       "Transformer directly to images, with the fewest possible modiﬁcations. To do so, we split an image\n",
       "into patches and provide the sequence of linear embeddings of these patches as an input to a Trans-\n",
       "former. Image patches are treated the same way as tokens (words) in an NLP application. We train\n",
       "the model on image classiﬁcation in supervised fashion.\n",
       "When trained on mid-sized datasets such as ImageNet without strong regularization, these mod-\n",
       "els yield modest accuracies of a few percentage points below ResNets of comparable size. This\n",
       "seemingly discouraging outcome may be expected: Transformers lack some of the inductive biases\n",
       "1Fine-tuning\n",
       "code\n",
       "and\n",
       "pre-trained\n",
       "models\n",
       "are\n",
       "available\n",
       "at\n",
       "https://github.com/\n",
       "google-research/vision_transformer\n",
       "1\n",
       "arXiv:2010.11929v2  [cs.CV]  3 Jun 2021"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': '5633ed0f-6c0b-4e4c-b425-8744e88f3510', 'page': 0, 'source': '../../docs/vision_transformer.pdf', 'title': 'vision_transformer.pdf'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Focuses on introducing the Vision Transformer (ViT) as a novel approach for image recognition, highlighting its ability to perform well on classification tasks by applying a standard Transformer architecture directly to sequences of image patches. It contrasts the reliance on convolutional neural networks (CNNs) in computer vision and emphasizes the advantages of using Transformers, particularly when pre-trained on large datasets.\n",
       "Published as a conference paper at ICLR 2021\n",
       "AN IMAGE IS WORTH 16X16 WORDS:\n",
       "TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE\n",
       "Alexey Dosovitskiy∗,†, Lucas Beyer∗, Alexander Kolesnikov∗, Dirk Weissenborn∗,\n",
       "Xiaohua Zhai∗, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer,\n",
       "Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby∗,†\n",
       "∗equal technical contribution, †equal advising\n",
       "Google Research, Brain Team\n",
       "{adosovitskiy, neilhoulsby}@google.com\n",
       "ABSTRACT\n",
       "While the Transformer architecture has become the de-facto standard for natural\n",
       "language processing tasks, its applications to computer vision remain limited. In\n",
       "vision, attention is either applied in conjunction with convolutional networks, or\n",
       "used to replace certain components of convolutional networks while keeping their\n",
       "overall structure in place. We show that this reliance on CNNs is not necessary\n",
       "and a pure transformer applied directly to sequences of image patches can perform\n",
       "very well on image classiﬁcation tasks. When pre-trained on large amounts of\n",
       "data and transferred to multiple mid-sized or small image recognition benchmarks\n",
       "(ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent\n",
       "results compared to state-of-the-art convolutional networks while requiring sub-\n",
       "stantially fewer computational resources to train.1\n",
       "1\n",
       "INTRODUCTION\n",
       "Self-attention-based architectures, in particular Transformers (Vaswani et al., 2017), have become\n",
       "the model of choice in natural language processing (NLP). The dominant approach is to pre-train on\n",
       "a large text corpus and then ﬁne-tune on a smaller task-speciﬁc dataset (Devlin et al., 2019). Thanks\n",
       "to Transformers’ computational efﬁciency and scalability, it has become possible to train models of\n",
       "unprecedented size, with over 100B parameters (Brown et al., 2020; Lepikhin et al., 2020). With the\n",
       "models and datasets growing, there is still no sign of saturating performance.\n",
       "In computer vision, however, convolutional architectures remain dominant (LeCun et al., 1989;\n",
       "Krizhevsky et al., 2012; He et al., 2016). Inspired by NLP successes, multiple works try combining\n",
       "CNN-like architectures with self-attention (Wang et al., 2018; Carion et al., 2020), some replacing\n",
       "the convolutions entirely (Ramachandran et al., 2019; Wang et al., 2020a). The latter models, while\n",
       "theoretically efﬁcient, have not yet been scaled effectively on modern hardware accelerators due to\n",
       "the use of specialized attention patterns. Therefore, in large-scale image recognition, classic ResNet-\n",
       "like architectures are still state of the art (Mahajan et al., 2018; Xie et al., 2020; Kolesnikov et al.,\n",
       "2020).\n",
       "Inspired by the Transformer scaling successes in NLP, we experiment with applying a standard\n",
       "Transformer directly to images, with the fewest possible modiﬁcations. To do so, we split an image\n",
       "into patches and provide the sequence of linear embeddings of these patches as an input to a Trans-\n",
       "former. Image patches are treated the same way as tokens (words) in an NLP application. We train\n",
       "the model on image classiﬁcation in supervised fashion.\n",
       "When trained on mid-sized datasets such as ImageNet without strong regularization, these mod-\n",
       "els yield modest accuracies of a few percentage points below ResNets of comparable size. This\n",
       "seemingly discouraging outcome may be expected: Transformers lack some of the inductive biases\n",
       "1Fine-tuning\n",
       "code\n",
       "and\n",
       "pre-trained\n",
       "models\n",
       "are\n",
       "available\n",
       "at\n",
       "https://github.com/\n",
       "google-research/vision_transformer\n",
       "1\n",
       "arXiv:2010.11929v2  [cs.CV]  3 Jun 2021"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': 'd2790ead-3861-48ff-88be-ffa027116619', 'page': 7, 'source': '../../docs/vision_transformer.pdf', 'title': 'vision_transformer.pdf'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Focuses on a controlled scaling study of various models, including Vision Transformers and ResNets, evaluating their transfer performance from the JFT-300M dataset. It highlights the performance versus pre-training cost, revealing that Vision Transformers generally outperform ResNets in terms of efficiency and scalability. Additionally, it discusses the implications of these findings for future scaling efforts in model architecture.\n",
       "Published as a conference paper at ICLR 2021\n",
       "4.4\n",
       "SCALING STUDY\n",
       "We perform a controlled scaling study of different models by evaluating transfer performance from\n",
       "JFT-300M. In this setting data size does not bottleneck the models’ performances, and we assess\n",
       "performance versus pre-training cost of each model. The model set includes: 7 ResNets, R50x1,\n",
       "R50x2 R101x1, R152x1, R152x2, pre-trained for 7 epochs, plus R152x2 and R200x3 pre-trained\n",
       "for 14 epochs; 6 Vision Transformers, ViT-B/32, B/16, L/32, L/16, pre-trained for 7 epochs, plus\n",
       "L/16 and H/14 pre-trained for 14 epochs; and 5 hybrids, R50+ViT-B/32, B/16, L/32, L/16 pre-\n",
       "trained for 7 epochs, plus R50+ViT-L/16 pre-trained for 14 epochs (for hybrids, the number at the\n",
       "end of the model name stands not for the patch size, but for the total dowsampling ratio in the ResNet\n",
       "backbone).\n",
       "Figure 5 contains the transfer performance versus total pre-training compute (see Appendix D.5\n",
       "for details on computational costs). Detailed results per model are provided in Table 6 in the Ap-\n",
       "pendix. A few patterns can be observed. First, Vision Transformers dominate ResNets on the\n",
       "performance/compute trade-off. ViT uses approximately 2 −4× less compute to attain the same\n",
       "performance (average over 5 datasets). Second, hybrids slightly outperform ViT at small compu-\n",
       "tational budgets, but the difference vanishes for larger models. This result is somewhat surprising,\n",
       "since one might expect convolutional local feature processing to assist ViT at any size. Third, Vision\n",
       "Transformers appear not to saturate within the range tried, motivating future scaling efforts.\n",
       "4.5\n",
       "INSPECTING VISION TRANSFORMER\n",
       "Input\n",
       "Attention\n",
       "Figure 6: Representative ex-\n",
       "amples of attention from the\n",
       "output token to the input\n",
       "space. See Appendix D.7 for\n",
       "details.\n",
       "To begin to understand how the Vision Transformer processes im-\n",
       "age data, we analyze its internal representations. The ﬁrst layer of\n",
       "the Vision Transformer linearly projects the ﬂattened patches into a\n",
       "lower-dimensional space (Eq. 1). Figure 7 (left) shows the top prin-\n",
       "cipal components of the the learned embedding ﬁlters. The com-\n",
       "ponents resemble plausible basis functions for a low-dimensional\n",
       "representation of the ﬁne structure within each patch.\n",
       "After the projection, a learned position embedding is added to the\n",
       "patch representations. Figure 7 (center) shows that the model learns\n",
       "to encode distance within the image in the similarity of position em-\n",
       "beddings, i.e. closer patches tend to have more similar position em-\n",
       "beddings. Further, the row-column structure appears; patches in the\n",
       "same row/column have similar embeddings. Finally, a sinusoidal\n",
       "structure is sometimes apparent for larger grids (Appendix D). That\n",
       "the position embeddings learn to represent 2D image topology ex-\n",
       "plains why hand-crafted 2D-aware embedding variants do not yield\n",
       "improvements (Appendix D.4).\n",
       "Self-attention allows ViT to integrate information across the entire\n",
       "image even in the lowest layers. We investigate to what degree\n",
       "the network makes use of this capability. Speciﬁcally, we compute\n",
       "the average distance in image space across which information is\n",
       "integrated, based on the attention weights (Figure 7, right). This\n",
       "“attention distance” is analogous to receptive ﬁeld size in CNNs.\n",
       "We ﬁnd that some heads attend to most of the image already in the lowest layers, showing that\n",
       "the ability to integrate information globally is indeed used by the model. Other attention heads"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': '70f0e7bc-ac29-485f-9b36-d5196619fa29', 'page': 2, 'source': '../../docs/vision_transformer.pdf', 'title': 'vision_transformer.pdf'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Focuses on the architecture and methodology of the Vision Transformer (ViT), detailing how images are processed by splitting them into patches, embedding them, and utilizing a standard Transformer encoder for image classification tasks. It describes the model's design principles, including the use of position embeddings and the classification head, while referencing foundational work in Transformer architecture.\n",
       "Published as a conference paper at ICLR 2021\n",
       "Transformer Encoder\n",
       "MLP \n",
       "Head\n",
       "Vision Transformer (ViT)\n",
       "*\n",
       "Linear Projection of Flattened Patches\n",
       "* Extra learnable\n",
       "     [ cl ass]  embedding\n",
       "1\n",
       "2\n",
       "3\n",
       "4\n",
       "5\n",
       "6\n",
       "7\n",
       "8\n",
       "9\n",
       "0\n",
       "Patch + Position \n",
       "Embedding\n",
       "Class\n",
       "Bird\n",
       "Ball\n",
       "Car\n",
       "...\n",
       "Embedded \n",
       "Patches\n",
       "Multi-Head \n",
       "Attention\n",
       "Norm\n",
       "MLP\n",
       "Norm\n",
       "+\n",
       "L x\n",
       "+\n",
       "Transformer Encoder\n",
       "Figure 1: Model overview. We split an image into ﬁxed-size patches, linearly embed each of them,\n",
       "add position embeddings, and feed the resulting sequence of vectors to a standard Transformer\n",
       "encoder. In order to perform classiﬁcation, we use the standard approach of adding an extra learnable\n",
       "“classiﬁcation token” to the sequence. The illustration of the Transformer encoder was inspired by\n",
       "Vaswani et al. (2017).\n",
       "3\n",
       "METHOD\n",
       "In model design we follow the original Transformer (Vaswani et al., 2017) as closely as possible.\n",
       "An advantage of this intentionally simple setup is that scalable NLP Transformer architectures – and\n",
       "their efﬁcient implementations – can be used almost out of the box.\n",
       "3.1\n",
       "VISION TRANSFORMER (VIT)\n",
       "An overview of the model is depicted in Figure 1. The standard Transformer receives as input a 1D\n",
       "sequence of token embeddings. To handle 2D images, we reshape the image x ∈RH×W ×C into a\n",
       "sequence of ﬂattened 2D patches xp ∈RN×(P 2·C), where (H, W) is the resolution of the original\n",
       "image, C is the number of channels, (P, P) is the resolution of each image patch, and N = HW/P 2\n",
       "is the resulting number of patches, which also serves as the effective input sequence length for the\n",
       "Transformer. The Transformer uses constant latent vector size D through all of its layers, so we\n",
       "ﬂatten the patches and map to D dimensions with a trainable linear projection (Eq. 1). We refer to\n",
       "the output of this projection as the patch embeddings.\n",
       "Similar to BERT’s [class] token, we prepend a learnable embedding to the sequence of embed-\n",
       "ded patches (z0\n",
       "0 = xclass), whose state at the output of the Transformer encoder (z0\n",
       "L) serves as the\n",
       "image representation y (Eq. 4). Both during pre-training and ﬁne-tuning, a classiﬁcation head is at-\n",
       "tached to z0\n",
       "L. The classiﬁcation head is implemented by a MLP with one hidden layer at pre-training\n",
       "time and by a single linear layer at ﬁne-tuning time.\n",
       "Position embeddings are added to the patch embeddings to retain positional information. We use\n",
       "standard learnable 1D position embeddings, since we have not observed signiﬁcant performance\n",
       "gains from using more advanced 2D-aware position embeddings (Appendix D.4). The resulting\n",
       "sequence of embedding vectors serves as input to the encoder.\n",
       "The Transformer encoder (Vaswani et al., 2017) consists of alternating layers of multiheaded self-\n",
       "attention (MSA, see Appendix A) and MLP blocks (Eq. 2, 3). Layernorm (LN) is applied before\n",
       "every block, and residual connections after every block (Wang et al., 2019; Baevski & Auli, 2019).\n",
       "3"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the difference between transformers and vision transformers?\"\n",
    "result = rag_chain_w_sources.invoke(query)\n",
    "display_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c1651f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "What is an Agentic AI System?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The context provided does not contain specific information about an \"Agentic AI System.\" Therefore, I don't know what an Agentic AI System is."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Sources:\n",
      "Metadata: {'id': '6360', 'page': 1, 'source': 'Wikipedia', 'title': 'Artificial intelligence'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Artificial intelligence (AI) is the ability of a computer program or a machine to think and learn. It is also a field of study which tries to make computers \"smart\". They work on their own without being encoded with commands. John McCarthy came up with the name \"Artificial Intelligence\" in 1955. In general use, the term \"artificial intelligence\" means a programme which mimics human cognition. At least some of the things we associate with other minds, such as learning and problem solving can be done by computers, though not in the same way as we do. Andreas Kaplan and Michael Haenlein define AI as a system’s ability to correctly interpret external data, to learn from such data, and to use those learnings to achieve specific goals and tasks through flexible adaptation. An ideal (perfect) intelligent machine is a flexible agent which perceives its environment and takes actions to maximize its chance of success at some goal or objective. As machines become increasingly capable, mental faculties once thought to require intelligence are removed from the definition. For example, optical character recognition is no longer perceived as an example of \"artificial intelligence\": it is just a routine technology."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': '6360', 'page': 1, 'source': 'Wikipedia', 'title': 'Artificial intelligence'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Artificial intelligence (AI) is the ability of a computer program or a machine to think and learn. It is also a field of study which tries to make computers \"smart\". They work on their own without being encoded with commands. John McCarthy came up with the name \"Artificial Intelligence\" in 1955. In general use, the term \"artificial intelligence\" means a programme which mimics human cognition. At least some of the things we associate with other minds, such as learning and problem solving can be done by computers, though not in the same way as we do. Andreas Kaplan and Michael Haenlein define AI as a system’s ability to correctly interpret external data, to learn from such data, and to use those learnings to achieve specific goals and tasks through flexible adaptation. An ideal (perfect) intelligent machine is a flexible agent which perceives its environment and takes actions to maximize its chance of success at some goal or objective. As machines become increasingly capable, mental faculties once thought to require intelligence are removed from the definition. For example, optical character recognition is no longer perceived as an example of \"artificial intelligence\": it is just a routine technology."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': '674015', 'page': 1, 'source': 'Wikipedia', 'title': 'A.I. Artificial Intelligence'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "A.I. Artificial Intelligence, or A.I., is a 2001 American science fiction drama movie directed by Steven Spielberg. The screenplay was by Spielberg based on the 1969 short story \"Supertoys Last All Summer Long\" by Brian Aldiss. The movie was produced by Kathleen Kennedy, Spielberg and Bonnie Curtis. It stars Haley Joel Osment, Jude Law, Frances O'Connor, Brendan Gleeson and William Hurt. It is set in a futuristic post-climate change society. \"A.I.\" tells the story of David (Osment), a childlike android uniquely programmed with the ability to love."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': '674015', 'page': 1, 'source': 'Wikipedia', 'title': 'A.I. Artificial Intelligence'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "A.I. Artificial Intelligence, or A.I., is a 2001 American science fiction drama movie directed by Steven Spielberg. The screenplay was by Spielberg based on the 1969 short story \"Supertoys Last All Summer Long\" by Brian Aldiss. The movie was produced by Kathleen Kennedy, Spielberg and Bonnie Curtis. It stars Haley Joel Osment, Jude Law, Frances O'Connor, Brendan Gleeson and William Hurt. It is set in a futuristic post-climate change society. \"A.I.\" tells the story of David (Osment), a childlike android uniquely programmed with the ability to love."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': '112634', 'page': 1, 'source': 'Wikipedia', 'title': 'Swarm intelligence'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Swarm Intelligence is a field of Computer science. It is a form of Artificial intelligence. Some animals, mostly insects like ants, or bees form large colonies. These colonies are made of many animals that communicate with each other. Each animal is relatively simple, but by working together with other animals it is able to solve complex tasks. Swarm intelligence wants to obtain similar behaviour than that observed with these animals. Instead of the animals, so called \"agents\" are used."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is an Agentic AI System?\"\n",
    "result = rag_chain_w_sources.invoke(query)\n",
    "display_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc68d5da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
