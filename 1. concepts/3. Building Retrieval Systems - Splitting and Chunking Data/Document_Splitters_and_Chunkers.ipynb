{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f829c934",
   "metadata": {},
   "source": [
    "**Reference Link:** [RAG Systems Essentials (Analytics Vidhya)](https://courses.analyticsvidhya.com/courses/take/rag-systems-essentials/lessons/60148017-hands-on-deep-dive-into-rag-evaluation-metrics-generator-metrics-i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bfe05e",
   "metadata": {},
   "source": [
    "# Exploring Document Splitters and Chunkers in LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac5db54",
   "metadata": {},
   "source": [
    "## Install OpenAI, HuggingFace and LangChain dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbcd8c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run setup.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b9a7ea",
   "metadata": {},
   "source": [
    "## Document Splitting and Chunking\n",
    "\n",
    "After loading documents into LangChain, you might need to transform them for optimal use in your application. One common transformation is splitting a long document into smaller segments to fit within your model's context window. LangChain provides several built-in document transformers to facilitate the splitting, combining, filtering, and manipulating of documents.\n",
    "\n",
    "#### Process of Document Splitting:\n",
    "1. **Splitting into Chunks:**\n",
    "   - Break down the text into small, semantically meaningful units (typically sentences).\n",
    "   \n",
    "2. **Combining Chunks:**\n",
    "   - Assemble these smaller units into larger chunks until they reach a predefined size. This size is determined by a specific measurement function.\n",
    "\n",
    "3. **Creating Overlapping Chunks:**\n",
    "   - Once the maximum size is reached, finalize the chunk as an independent text piece.\n",
    "   - Begin a new chunk, incorporating some overlap with the previous chunk to maintain textual context.\n",
    "\n",
    "This approach ensures that semantically related text pieces are kept together, which is crucial for maintaining the meaning and continuity of the document.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cc7282",
   "metadata": {},
   "source": [
    "### Fixed Length Chunking\n",
    "\n",
    "Fixed-length chunking is a straightforward approach where text is divided into **predefined chunk sizes**, typically based on tokens or characters.\n",
    "\n",
    "**Mechanism**\n",
    "\n",
    "•\tSplits text into **fixed-size chunks** without considering meaning.\n",
    "\n",
    "•\tChunks are defined by **a set number of tokens or characters**.\n",
    "\n",
    "**Ideal Use Cases**\n",
    "\n",
    "•\tSuitable for **structured documents**, FAQs, or cases where **processing speed** is a priority.\n",
    "\n",
    "**Pros**\n",
    "\n",
    "•\t**Simplicity:** Easy to implement without complex algorithms.\n",
    "\n",
    "•\t**Uniformity:** Consistent chunk sizes simplify indexing and retrieval.\n",
    "\n",
    "**Cons**\n",
    "\n",
    "•\t**Context Loss:** May split sentences or ideas, leading to incomplete information.\n",
    "\n",
    "•\t**Relevance Issues:** Important details may span multiple chunks, reducing retrieval effectiveness.\n",
    "\n",
    "**Implementation Strategies**\n",
    "\n",
    "•\tSelect a **chunk size** that balances **context retention and efficiency**.\n",
    "\n",
    "•\tUse **overlapping windows** to preserve continuity and reduce context loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0553d2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\"\n",
    "Introduction\n",
    "\n",
    "Data Science is an interdisciplinary field that uses scientific methods, processes,\n",
    " algorithms, and systems to extract knowledge and insights from structured and \n",
    " unstructured data. It draws from statistics, computer science, machine learning, \n",
    " and various data analysis techniques to discover patterns, make predictions, and \n",
    " derive actionable insights.\n",
    "\n",
    "Data Science can be applied across many industries, including healthcare, finance,\n",
    " marketing, and education, where it helps organizations make data-driven decisions,\n",
    "  optimize processes, and understand customer behaviors.\n",
    "\n",
    "Overview of Big Data\n",
    "\n",
    "Big data refers to large, diverse sets of information that grow at ever-increasing \n",
    "rates. It encompasses the volume of information, the velocity or speed at which it \n",
    "is created and collected, and the variety or scope of the data points being \n",
    "covered.\n",
    "\n",
    "Data Science Methods\n",
    "\n",
    "There are several important methods used in Data Science:\n",
    "\n",
    "1. Regression Analysis\n",
    "2. Classification\n",
    "3. Clustering\n",
    "4. Neural Networks\n",
    "\n",
    "Challenges in Data Science\n",
    "\n",
    "- Data Quality: Poor data quality can lead to incorrect conclusions.\n",
    "- Data Privacy: Ensuring the privacy of sensitive information.\n",
    "- Scalability: Handling massive datasets efficiently.\n",
    "\n",
    "Conclusion\n",
    "\n",
    "Data Science continues to be a driving force in many industries, offering insights \n",
    "that can lead to better decisions and optimized outcomes. It remains an evolving \n",
    "field that incorporates the latest technological advancements.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0713ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 1\n",
      "Introduction Data Science is an interdisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data. It draws from statistics, computer science, machine learning, and various data analysis techniques to discover patterns, make predictions, and derive actionable insights. Data Science can be applied across many industries, including healthcare, finance, marketing, and education, where it helps organizations make data-driven decisions, optimize processes, and understand customer behaviors. Overview of Big Data Big data refers to large, diverse sets of information that grow at ever-increasing rates. It encompasses the volume of information, the velocity \n",
      "---\n",
      "\n",
      "chunk 2\n",
      "or speed at which it is created and collected, and the variety or scope of the data points being covered. Data Science Methods There are several important methods used in Data Science: 1. Regression Analysis 2. Classification 3. Clustering 4. Neural Networks Challenges in Data Science - Data Quality: Poor data quality can lead to incorrect conclusions. - Data Privacy: Ensuring the privacy of sensitive information. - Scalability: Handling massive datasets efficiently. Conclusion Data Science continues to be a driving force in many industries, offering insights that can lead to better decisions and optimized outcomes. It remains an evolving field \n",
      "---\n",
      "\n",
      "chunk 3\n",
      "that incorporates the latest technological advancements. \n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def fixed_size_chunk(text, max_words=100):\n",
    "    words = text.split()\n",
    "    return [' '.join(words[i:i + max_words]) for i in range(0, len(words), \n",
    "    max_words)]\n",
    "\n",
    "# Applying Fixed-Size Chunking\n",
    "fixed_chunks = fixed_size_chunk(sample_text)\n",
    "i = 0\n",
    "for chunk in fixed_chunks:\n",
    "  print(f\"chunk {i+1}\")\n",
    "  print(chunk, '\\n---\\n')\n",
    "  i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e15efc",
   "metadata": {},
   "source": [
    "### Sentence Based Chunking\n",
    "\n",
    "Sentence-based chunking ensures that each chunk represents a **complete thought** by splitting text at **sentence boundaries**.\n",
    "\n",
    "**Mechanism**\n",
    "\n",
    "•\tSplits text at **sentence boundaries** to maintain logical structure.\n",
    "\n",
    "•\tEach chunk contains a **full sentence** rather than an arbitrary length of text.\n",
    "\n",
    "**Ideal Use Cases**\n",
    "\n",
    "•\tWorks best for **short, direct responses** such as **customer queries or conversational AI** applications.\n",
    "\n",
    "**Pros**\n",
    "\n",
    "•\t**Context Preservation:** Maintains the integrity of individual sentences.\n",
    "\n",
    "•\t**Ease of Implementation:** Utilizes NLP tools for accurate sentence detection.\n",
    "\n",
    "**Cons**\n",
    "\n",
    "•\t**Limited Context:** Single sentences may lack sufficient context for complex queries.\n",
    "\n",
    "•\t**Variable Length:** Sentence lengths can vary, leading to inconsistent chunk sizes.\n",
    "\n",
    "**Implementation Strategies**\n",
    "\n",
    "•\tUse **NLP libraries** for accurate sentence boundary detection.\n",
    "\n",
    "•\t**Combine multiple short sentences** into a single chunk to provide more context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "219d328a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.8.7-cp311-cp311-macosx_11_0_arm64.whl.metadata (27 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.13-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.11-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.5 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.10-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.4 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.6-cp311-cp311-macosx_11_0_arm64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Downloading wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Downloading weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Using cached typer-0.16.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/sourav.banerjee/Documents/My Codebases/GenerativAI_Demystified/venv/lib/python3.11/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/sourav.banerjee/Documents/My Codebases/GenerativAI_Demystified/venv/lib/python3.11/site-packages (from spacy) (2.2.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/sourav.banerjee/Documents/My Codebases/GenerativAI_Demystified/venv/lib/python3.11/site-packages (from spacy) (2.32.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/sourav.banerjee/Documents/My Codebases/GenerativAI_Demystified/venv/lib/python3.11/site-packages (from spacy) (2.11.7)\n",
      "Requirement already satisfied: jinja2 in /Users/sourav.banerjee/Documents/My Codebases/GenerativAI_Demystified/venv/lib/python3.11/site-packages (from spacy) (3.1.6)\n",
      "Requirement already satisfied: setuptools in /Users/sourav.banerjee/Documents/My Codebases/GenerativAI_Demystified/venv/lib/python3.11/site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sourav.banerjee/Documents/My Codebases/GenerativAI_Demystified/venv/lib/python3.11/site-packages (from spacy) (24.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/sourav.banerjee/Documents/My Codebases/GenerativAI_Demystified/venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/sourav.banerjee/Documents/My Codebases/GenerativAI_Demystified/venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/sourav.banerjee/Documents/My Codebases/GenerativAI_Demystified/venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.14.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/sourav.banerjee/Documents/My Codebases/GenerativAI_Demystified/venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/sourav.banerjee/Documents/My Codebases/GenerativAI_Demystified/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sourav.banerjee/Documents/My Codebases/GenerativAI_Demystified/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sourav.banerjee/Documents/My Codebases/GenerativAI_Demystified/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sourav.banerjee/Documents/My Codebases/GenerativAI_Demystified/venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2025.7.9)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.3.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.4 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/sourav.banerjee/Documents/My Codebases/GenerativAI_Demystified/venv/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.2.1)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading cloudpathlib-0.21.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting smart-open<8.0.0,>=5.2.1 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Downloading smart_open-7.3.0.post1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: wrapt in /Users/sourav.banerjee/Documents/My Codebases/GenerativAI_Demystified/venv/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.2.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (9.0 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/sourav.banerjee/Documents/My Codebases/GenerativAI_Demystified/venv/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sourav.banerjee/Documents/My Codebases/GenerativAI_Demystified/venv/lib/python3.11/site-packages (from jinja2->spacy) (3.0.2)\n",
      "Downloading spacy-3.8.7-cp311-cp311-macosx_11_0_arm64.whl (6.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/6.4 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp311-cp311-macosx_11_0_arm64.whl (41 kB)\n",
      "Downloading langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.13-cp311-cp311-macosx_11_0_arm64.whl (26 kB)\n",
      "Downloading preshed-3.0.10-cp311-cp311-macosx_11_0_arm64.whl (127 kB)\n",
      "Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp311-cp311-macosx_11_0_arm64.whl (634 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m634.4/634.4 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading thinc-8.3.6-cp311-cp311-macosx_11_0_arm64.whl (845 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m845.3/845.3 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading blis-1.3.0-cp311-cp311-macosx_11_0_arm64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Using cached typer-0.16.0-py3-none-any.whl (46 kB)\n",
      "Downloading wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Downloading cloudpathlib-0.21.1-py3-none-any.whl (52 kB)\n",
      "Downloading smart_open-7.3.0.post1-py3-none-any.whl (61 kB)\n",
      "Downloading language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading marisa_trie-1.2.1-cp311-cp311-macosx_11_0_arm64.whl (174 kB)\n",
      "Using cached rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, smart-open, shellingham, murmurhash, mdurl, marisa-trie, cloudpathlib, catalogue, blis, srsly, preshed, markdown-it-py, language-data, rich, langcodes, confection, typer, thinc, weasel, spacy\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23/23\u001b[0m [spacy]m22/23\u001b[0m [spacy]]e-data]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed blis-1.3.0 catalogue-2.0.10 cloudpathlib-0.21.1 confection-0.1.5 cymem-2.0.11 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.2.1 markdown-it-py-3.0.0 mdurl-0.1.2 murmurhash-1.0.13 preshed-3.0.10 rich-14.0.0 shellingham-1.5.4 smart-open-7.3.0.post1 spacy-3.8.7 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.6 typer-0.16.0 wasabi-1.1.3 weasel-0.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "# Install the en_core_web_sm model\n",
    "%pip install spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "653ff1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 1\n",
      "\n",
      "Introduction\n",
      "\n",
      "Data Science is an interdisciplinary field that uses scientific methods, processes,\n",
      " algorithms, and systems to extract knowledge and insights from structured and \n",
      " unstructured data. \n",
      "---\n",
      "\n",
      "chunk 2\n",
      "It draws from statistics, computer science, machine learning, \n",
      " and various data analysis techniques to discover patterns, make predictions, and \n",
      " derive actionable insights.\n",
      "\n",
      " \n",
      "---\n",
      "\n",
      "chunk 3\n",
      "Data Science can be applied across many industries, including healthcare, finance,\n",
      " marketing, and education, where it helps organizations make data-driven decisions,\n",
      "  optimize processes, and understand customer behaviors.\n",
      "\n",
      " \n",
      "---\n",
      "\n",
      "chunk 4\n",
      "Overview of Big Data\n",
      "\n",
      "Big data refers to large, diverse sets of information that grow at ever-increasing \n",
      "rates. \n",
      "---\n",
      "\n",
      "chunk 5\n",
      "It encompasses the volume of information, the velocity or speed at which it \n",
      "is created and collected, and the variety or scope of the data points being \n",
      "covered.\n",
      "\n",
      " \n",
      "---\n",
      "\n",
      "chunk 6\n",
      "Data Science Methods\n",
      "\n",
      "There are several important methods used in Data Science:\n",
      "\n",
      "1. \n",
      "---\n",
      "\n",
      "chunk 7\n",
      "Regression Analysis\n",
      "2. \n",
      "---\n",
      "\n",
      "chunk 8\n",
      "Classification\n",
      "3. \n",
      "---\n",
      "\n",
      "chunk 9\n",
      "Clustering\n",
      "4. \n",
      "---\n",
      "\n",
      "chunk 10\n",
      "Neural Networks\n",
      "\n",
      "Challenges in Data Science\n",
      "\n",
      "- Data Quality: Poor data quality can lead to incorrect conclusions.\n",
      "- Data Privacy: \n",
      "---\n",
      "\n",
      "chunk 11\n",
      "Ensuring the privacy of sensitive information.\n",
      "- Scalability: Handling massive datasets efficiently.\n",
      "\n",
      " \n",
      "---\n",
      "\n",
      "chunk 12\n",
      "Conclusion\n",
      "\n",
      "Data Science continues to be a driving force in many industries, offering insights \n",
      "that can lead to better decisions and optimized outcomes. \n",
      "---\n",
      "\n",
      "chunk 13\n",
      "It remains an evolving \n",
      "field that incorporates the latest technological advancements.\n",
      " \n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy  # Import the spaCy library for NLP tasks\n",
    "\n",
    "# Load the small English model for spaCy (used for sentence segmentation)\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def sentence_chunk(text):\n",
    "    \"\"\"\n",
    "    Splits the input text into sentences using spaCy's sentence boundary detection.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to be chunked into sentences.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: A list of sentences extracted from the text.\n",
    "    \"\"\"\n",
    "    doc = nlp(text)  # Process the text with spaCy to create a Doc object\n",
    "    return [sent.text for sent in doc.sents]  # Extract and return sentences as strings\n",
    "\n",
    "# Applying Sentence-Based Chunking\n",
    "sentence_chunks = sentence_chunk(sample_text)  # Split the sample_text into sentence chunks\n",
    "\n",
    "i = 0  # Initialize chunk counter\n",
    "for chunk in sentence_chunks:\n",
    "    print(f\"chunk {i+1}\")  # Print the chunk number (1-based index)\n",
    "    print(chunk, '\\n---\\n')  # Print the chunk content followed by a separator\n",
    "    i += 1  # Increment the chunk counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e541bb17",
   "metadata": {},
   "source": [
    "### Paragraph Based Chunking\n",
    "\n",
    "**Paragraph-Based Chunking**\n",
    "\n",
    "Paragraph-based chunking divides documents into **paragraphs**, ensuring each chunk encapsulates a **complete idea or topic**.\n",
    "\n",
    "**Mechanism**\n",
    "\n",
    "•\tSplits text at **paragraph boundaries**, preserving logical flow.\n",
    "\n",
    "•\tEach chunk typically represents a **self-contained idea** or section.\n",
    "\n",
    "**Ideal Use Cases**\n",
    "\n",
    "•\tSuitable for **structured documents** such as **articles, reports, or essays**.\n",
    "\n",
    "**Pros**\n",
    "\n",
    "•\t**Richer Context:** Provides more information than sentence-based chunks.\n",
    "\n",
    "•\t**Logical Division:** Aligns with the natural structure of the text.\n",
    "\n",
    "**Cons**\n",
    "\n",
    "•\t**Inconsistent Sizes:** Paragraph lengths can vary widely.\n",
    "\n",
    "•\t**Token Limits:** Large paragraphs may exceed the model’s token constraints.\n",
    "\n",
    "**Implementation Strategies**\n",
    "\n",
    "•\tMonitor chunk sizes to ensure they stay within acceptable **token limits**.\n",
    "\n",
    "•\tIf necessary, **split large paragraphs** further while preserving context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5daf2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Introduction \n",
      "---\n",
      "\n",
      "Data Science is an interdisciplinary field that uses scientific methods, processes,\n",
      " algorithms, and systems to extract knowledge and insights from structured and \n",
      " unstructured data. It draws from statistics, computer science, machine learning, \n",
      " and various data analysis techniques to discover patterns, make predictions, and \n",
      " derive actionable insights. \n",
      "---\n",
      "\n",
      "Data Science can be applied across many industries, including healthcare, finance,\n",
      " marketing, and education, where it helps organizations make data-driven decisions,\n",
      "  optimize processes, and understand customer behaviors. \n",
      "---\n",
      "\n",
      "Overview of Big Data \n",
      "---\n",
      "\n",
      "Big data refers to large, diverse sets of information that grow at ever-increasing \n",
      "rates. It encompasses the volume of information, the velocity or speed at which it \n",
      "is created and collected, and the variety or scope of the data points being \n",
      "covered. \n",
      "---\n",
      "\n",
      "Data Science Methods \n",
      "---\n",
      "\n",
      "There are several important methods used in Data Science: \n",
      "---\n",
      "\n",
      "1. Regression Analysis\n",
      "2. Classification\n",
      "3. Clustering\n",
      "4. Neural Networks \n",
      "---\n",
      "\n",
      "Challenges in Data Science \n",
      "---\n",
      "\n",
      "- Data Quality: Poor data quality can lead to incorrect conclusions.\n",
      "- Data Privacy: Ensuring the privacy of sensitive information.\n",
      "- Scalability: Handling massive datasets efficiently. \n",
      "---\n",
      "\n",
      "Conclusion \n",
      "---\n",
      "\n",
      "Data Science continues to be a driving force in many industries, offering insights \n",
      "that can lead to better decisions and optimized outcomes. It remains an evolving \n",
      "field that incorporates the latest technological advancements.\n",
      " \n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def paragraph_chunk(text):\n",
    "    paragraphs = text.split('\\n\\n')\n",
    "    return paragraphs\n",
    "\n",
    "# Applying Paragraph-Based Chunking\n",
    "paragraph_chunks = paragraph_chunk(sample_text)\n",
    "for chunk in paragraph_chunks:\n",
    "    print(chunk, '\\n---\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234762ae",
   "metadata": {},
   "source": [
    "### Sliding Window Chunking\n",
    "\n",
    "Sliding window chunking creates **overlapping chunks** by shifting a window over the text, ensuring adjacent chunks share content for better context retention.\n",
    "\n",
    "**Mechanism**\n",
    "\n",
    "•\tUses a **moving window** to generate chunks with overlapping content.\n",
    "\n",
    "•\tHelps maintain continuity by ensuring **important details appear in multiple chunks**.\n",
    "\n",
    "**Ideal Use Cases**\n",
    "\n",
    "•\tBest suited for **documents where maintaining context across sections is critical**, such as **legal or medical texts**.\n",
    "\n",
    "**Pros**\n",
    "\n",
    "•\t**Context Continuity:** Overlaps help preserve the flow of information.\n",
    "\n",
    "•\t**Improved Retrieval:** Increases the chances that relevant information is included in the retrieved chunks.\n",
    "\n",
    "**Cons**\n",
    "\n",
    "•\t**Redundancy:** Overlapping content can lead to duplicate information.\n",
    "\n",
    "•\t**Computational Cost:** More chunks require additional processing and storage.\n",
    "\n",
    "**Implementation Strategies**\n",
    "\n",
    "•\tOptimize **window size and overlap** based on the document’s nature.\n",
    "\n",
    "•\tUse **deduplication techniques** during retrieval to handle redundancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "629d7f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Introduction Data Science is an interdisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data. It draws from statistics, computer science, machine learning, and various data analysis techniques to discover patterns, make predictions, and derive actionable insights. Data Science can be applied across many industries, including healthcare, finance, marketing, and education, where it helps organizations make data-driven decisions, optimize processes, and understand customer behaviors. Overview of Big Data Big data refers to large, diverse sets of information that grow at ever-increasing rates. It encompasses the volume of information, the velocity \n",
      "---\n",
      "\n",
      "refers to large, diverse sets of information that grow at ever-increasing rates. It encompasses the volume of information, the velocity or speed at which it is created and collected, and the variety or scope of the data points being covered. Data Science Methods There are several important methods used in Data Science: 1. Regression Analysis 2. Classification 3. Clustering 4. Neural Networks Challenges in Data Science - Data Quality: Poor data quality can lead to incorrect conclusions. - Data Privacy: Ensuring the privacy of sensitive information. - Scalability: Handling massive datasets efficiently. Conclusion Data Science continues to be a driving \n",
      "---\n",
      "\n",
      "Ensuring the privacy of sensitive information. - Scalability: Handling massive datasets efficiently. Conclusion Data Science continues to be a driving force in many industries, offering insights that can lead to better decisions and optimized outcomes. It remains an evolving field that incorporates the latest technological advancements. \n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def sliding_window_chunk(text, chunk_size=100, overlap=20):\n",
    "    \"\"\"\n",
    "    Splits the input text into overlapping chunks using a sliding window approach.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to be chunked.\n",
    "        chunk_size (int): The number of tokens in each chunk.\n",
    "        overlap (int): The number of tokens that overlap between consecutive chunks.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of overlapping text chunks.\n",
    "    \"\"\"\n",
    "    tokens = text.split()  # Split the text into tokens (words)\n",
    "    chunks = []  # List to store the resulting chunks\n",
    "    # Iterate over the tokens with a step size of (chunk_size - overlap)\n",
    "    for i in range(0, len(tokens), chunk_size - overlap):\n",
    "        # Create a chunk by joining the tokens from i to i + chunk_size\n",
    "        chunk = ' '.join(tokens[i:i + chunk_size])\n",
    "        chunks.append(chunk)  # Add the chunk to the list\n",
    "    return chunks\n",
    "\n",
    "# Applying Sliding Window Chunking\n",
    "sliding_chunks = sliding_window_chunk(sample_text)\n",
    "# Print each chunk followed by a separator for clarity\n",
    "for chunk in sliding_chunks:\n",
    "    print(chunk, '\\n---\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730c7223",
   "metadata": {},
   "source": [
    "Introduction Data Science is an interdisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data. It draws from statistics, computer science, machine learning, and various data analysis techniques to discover patterns, make predictions, and derive actionable insights. Data Science can be applied across many industries, including healthcare, finance, marketing, and education, where it helps organizations make data-driven decisions, optimize processes, and understand customer behaviors. Overview of Big Data Big data `refers to large, diverse sets of information that grow at ever-increasing rates. It encompasses the volume of information, the velocity`\n",
    "\n",
    "`refers to large, diverse sets of information that grow at ever-increasing rates. It encompasses the volume of information, the velocity` or speed at which it is created and collected, and the variety or scope of the data points being covered. Data Science Methods There are several important methods used in Data Science: 1. Regression Analysis 2. Classification 3. Clustering 4. Neural Networks Challenges in Data Science - Data Quality: Poor data quality can lead to incorrect conclusions. - Data Privacy: `Ensuring the privacy of sensitive information. - Scalability: Handling massive datasets efficiently. Conclusion Data Science continues to be a driving` \n",
    "\n",
    "`Ensuring the privacy of sensitive information. - Scalability: Handling massive datasets efficiently. Conclusion Data Science continues to be a driving` force in many industries, offering insights that can lead to better decisions and optimized outcomes. It remains an evolving field that incorporates the latest technological advancements. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281f442f",
   "metadata": {},
   "source": [
    "### Semantic Based Chunking\n",
    "\n",
    "Semantic-based chunking leverages **embeddings or machine learning models** to split text based on **semantic meaning**, ensuring each chunk remains **cohesive in topic or idea**.\n",
    "\n",
    "**Mechanism**\n",
    "\n",
    "•\tUses **NLP models** to detect and segment text based on **meaning rather than fixed sizes**.\n",
    "\n",
    "•\tEnsures that **each chunk represents a complete thought or concept**.\n",
    "\n",
    "**Ideal Use Cases**\n",
    "\n",
    "•\tBest for **complex queries requiring deep understanding**, such as **technical manuals or academic papers**.\n",
    "\n",
    "**Pros**\n",
    "\n",
    "•\t**Contextual Relevance:** Chunks are meaningfully grouped, improving retrieval accuracy.\n",
    "\n",
    "•\t**Flexibility:** Adapts to the text’s inherent structure and content.\n",
    "\n",
    "**Cons**\n",
    "\n",
    "•\t**Complexity:** Requires advanced NLP models and significant computational resources.\n",
    "\n",
    "•\t**Processing Time:** Semantic analysis can be time-consuming.\n",
    "\n",
    "**Implementation Strategies**\n",
    "\n",
    "•\tUse **pre-trained models** for **semantic segmentation**.\n",
    "\n",
    "•\tBalance between **computational cost and granularity** to optimize efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bad4cd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Introduction\n",
      "\n",
      "Data Science is an interdisciplinary field that uses scientific methods, processes,\n",
      " algorithms, and systems to extract knowledge and insights from structured and \n",
      " unstructured data. It draws from statistics, computer science, machine learning, \n",
      " and various data analysis techniques to discover patterns, make predictions, and \n",
      " derive actionable insights.\n",
      "\n",
      " \n",
      "---\n",
      "\n",
      "Data Science can be applied across many industries, including healthcare, finance,\n",
      " marketing, and education, where it helps organizations make data-driven decisions,\n",
      "  optimize processes, and understand customer behaviors.\n",
      "\n",
      " \n",
      "---\n",
      "\n",
      "Overview of Big Data\n",
      "\n",
      "Big data refers to large, diverse sets of information that grow at ever-increasing \n",
      "rates. It encompasses the volume of information, the velocity or speed at which it \n",
      "is created and collected, and the variety or scope of the data points being \n",
      "covered.\n",
      "\n",
      " \n",
      "---\n",
      "\n",
      "Data Science Methods\n",
      "\n",
      "There are several important methods used in Data Science:\n",
      "\n",
      "1. Regression Analysis\n",
      "2. Classification\n",
      "3. Clustering\n",
      "4. Neural Networks\n",
      "\n",
      "Challenges in Data Science\n",
      "\n",
      "- Data Quality: Poor data quality can lead to incorrect conclusions.\n",
      "- Data Privacy: \n",
      "---\n",
      "\n",
      "Ensuring the privacy of sensitive information.\n",
      "- Scalability: Handling massive datasets efficiently.\n",
      "\n",
      " Conclusion\n",
      "\n",
      "Data Science continues to be a driving force in many industries, offering insights \n",
      "that can lead to better decisions and optimized outcomes. \n",
      "---\n",
      "\n",
      "It remains an evolving \n",
      "field that incorporates the latest technological advancements.\n",
      " \n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def semantic_chunk(text, max_len=200):\n",
    "    # Process the input text using the NLP model to obtain a Doc object\n",
    "    doc = nlp(text)\n",
    "    chunks = []         # List to store the resulting text chunks\n",
    "    current_chunk = []  # Temporary list to accumulate sentences for the current chunk\n",
    "\n",
    "    # Iterate over each sentence detected by the NLP model\n",
    "    for sent in doc.sents:\n",
    "        current_chunk.append(sent.text)  # Add the sentence text to the current chunk\n",
    "\n",
    "        # If the combined length of the current chunk exceeds the maximum length\n",
    "        if len(' '.join(current_chunk)) > max_len:\n",
    "            # Join the sentences to form a chunk and add to the list of chunks\n",
    "            chunks.append(' '.join(current_chunk))\n",
    "            current_chunk = []  # Reset the current chunk for the next set of sentences\n",
    "\n",
    "    # After the loop, if there are any remaining sentences, add them as the last chunk\n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "\n",
    "    return chunks  # Return the list of semantically-chunked text segments\n",
    "\n",
    "# Applying Semantic-Based Chunking\n",
    "# Use the semantic_chunk function to split the sample_text into semantically meaningful chunks\n",
    "semantic_chunks = semantic_chunk(sample_text)\n",
    "\n",
    "# Print each chunk, separated by a visual divider for clarity\n",
    "for chunk in semantic_chunks:\n",
    "    print(chunk, '\\n---\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2fc448",
   "metadata": {},
   "source": [
    "### RecursiveCharacterTextSplitter\n",
    "\n",
    "The `RecursiveCharacterTextSplitter` is a versatile tool within LangChain for splitting text based on a list of characters. This splitter is designed to handle various requirements through adjustable parameters.\n",
    "\n",
    "This text splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough. The default list is [\"\\n\\n\", \"\\n\", \" \", \"\"]. This has the effect of trying to keep all paragraphs (and then sentences, and then words) together as long as possible, as those would generically seem to be the strongest semantically related pieces of text.\n",
    "\n",
    "#### Features and Parameters:\n",
    "\n",
    "- **Character List:** Utilizes a specified list of characters to determine where splits should occur.\n",
    "- **Chunk Size:** Allows you to set the size of each chunk, helping ensure that chunks are manageable and suit the context window of your model.\n",
    "- **Overlap:** Configurable overlap between consecutive chunks to maintain context continuity across chunks.\n",
    "\n",
    "This splitter is particularly useful for texts where precise control over the splitting criteria is needed, allowing for customized chunking strategies based on specific characters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c8c3be0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c0ff75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "doc = \"\"\"Welcome to Green Valley, a small town nestled in the heart of the mountains. With its picturesque landscapes and vibrant community life, Green Valley has been a hidden gem for years. The main street is lined with an array of shops and cafes, each offering a unique taste of local flavor and culture.\n",
    "On a typical afternoon, the town square comes alive with the bustling sounds of locals and visitors mingling. Children play near the fountain, artists display their crafts, and an old man tells stories of days gone by. The aroma of freshly baked bread wafts from the bakery, drawing a steady stream of customers.\n",
    "Green Valley is not only known for its scenic beauty but also for its annual festivals. The most anticipated event is the Harvest Festival, celebrated with great enthusiasm. Locals prepare months in advance, cultivating crops and crafting goods for the occasion. The festival features a parade, various competitions, and a night market that lights up the town with vibrant colors and joyous energy.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cbaacc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Welcome to Green Valley, a small town nestled in the heart of the mountains. '\n",
      " 'With its picturesque landscapes and vibrant community life, Green Valley has '\n",
      " 'been a hidden gem for years. The main street is lined with an array of shops '\n",
      " 'and cafes, each offering a unique taste of local flavor and culture.\\n'\n",
      " 'On a typical afternoon, the town square comes alive with the bustling sounds '\n",
      " 'of locals and visitors mingling. Children play near the fountain, artists '\n",
      " 'display their crafts, and an old man tells stories of days gone by. The '\n",
      " 'aroma of freshly baked bread wafts from the bakery, drawing a steady stream '\n",
      " 'of customers.\\n'\n",
      " 'Green Valley is not only known for its scenic beauty but also for its annual '\n",
      " 'festivals. The most anticipated event is the Harvest Festival, celebrated '\n",
      " 'with great enthusiasm. Locals prepare months in advance, cultivating crops '\n",
      " 'and crafting goods for the occasion. The festival features a parade, various '\n",
      " 'competitions, and a night market that lights up the town with vibrant colors '\n",
      " 'and joyous energy.\\n')\n"
     ]
    }
   ],
   "source": [
    "pprint(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bb16e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators= [\"\\n\\n\", \"\\n\", \" \", \"\"], #First by Paragraph, then by lines, then by Words and then empty string character split\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5466987d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='Welcome to Green Valley, a small town nestled in the heart of the mountains. With its picturesque landscapes and vibrant community life, Green Valley has been a hidden gem for years. The main street is lined with an array of shops and cafes, each offering a unique taste of local flavor and culture.'),\n",
       " Document(metadata={}, page_content='On a typical afternoon, the town square comes alive with the bustling sounds of locals and visitors mingling. Children play near the fountain, artists display their crafts, and an old man tells stories of days gone by. The aroma of freshly baked bread wafts from the bakery, drawing a steady stream'),\n",
       " Document(metadata={}, page_content='of customers.'),\n",
       " Document(metadata={}, page_content='Green Valley is not only known for its scenic beauty but also for its annual festivals. The most anticipated event is the Harvest Festival, celebrated with great enthusiasm. Locals prepare months in advance, cultivating crops and crafting goods for the occasion. The festival features a parade,'),\n",
       " Document(metadata={}, page_content='various competitions, and a night market that lights up the town with vibrant colors and joyous energy.')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter.create_documents([doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f1c357a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "texts = text_splitter.split_text(doc)\n",
    "print(len(texts)) # 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbd43429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Welcome to Green Valley, a small town nestled in the heart of the mountains. With its picturesque landscapes and vibrant community life, Green Valley has been a hidden gem for years. The main street is lined with an array of shops and cafes, each offering a unique taste of local flavor and culture.', 'On a typical afternoon, the town square comes alive with the bustling sounds of locals and visitors mingling. Children play near the fountain, artists display their crafts, and an old man tells stories of days gone by. The aroma of freshly baked bread wafts from the bakery, drawing a steady stream', 'of customers.', 'Green Valley is not only known for its scenic beauty but also for its annual festivals. The most anticipated event is the Harvest Festival, celebrated with great enthusiasm. Locals prepare months in advance, cultivating crops and crafting goods for the occasion. The festival features a parade,', 'various competitions, and a night market that lights up the town with vibrant colors and joyous energy.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "174b9fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Green Valley, a small town nestled in the heart of the mountains. With its picturesque landscapes and vibrant community life, Green Valley has been a hidden gem for years. The main street is lined with an array of shops and cafes, each offering a unique taste of local flavor and culture.\n",
      "299\n",
      "\n",
      "On a typical afternoon, the town square comes alive with the bustling sounds of locals and visitors mingling. Children play near the fountain, artists display their crafts, and an old man tells stories of days gone by. The aroma of freshly baked bread wafts from the bakery, drawing a steady stream\n",
      "298\n",
      "\n",
      "of customers.\n",
      "13\n",
      "\n",
      "Green Valley is not only known for its scenic beauty but also for its annual festivals. The most anticipated event is the Harvest Festival, celebrated with great enthusiasm. Locals prepare months in advance, cultivating crops and crafting goods for the occasion. The festival features a parade,\n",
      "294\n",
      "\n",
      "various competitions, and a night market that lights up the town with vibrant colors and joyous energy.\n",
      "103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    print(text)\n",
    "    print(len(text))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aba6ba6",
   "metadata": {},
   "source": [
    "Splitting with larger chunk size (total characters) makes less paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30ba4a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators= [\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_text(doc)\n",
    "print(len(texts)) # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9721ff33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Green Valley, a small town nestled in the heart of the mountains. With its picturesque landscapes and vibrant community life, Green Valley has been a hidden gem for years. The main street is lined with an array of shops and cafes, each offering a unique taste of local flavor and culture.\n",
      "299\n",
      "\n",
      "On a typical afternoon, the town square comes alive with the bustling sounds of locals and visitors mingling. Children play near the fountain, artists display their crafts, and an old man tells stories of days gone by. The aroma of freshly baked bread wafts from the bakery, drawing a steady stream of customers.\n",
      "312\n",
      "\n",
      "Green Valley is not only known for its scenic beauty but also for its annual festivals. The most anticipated event is the Harvest Festival, celebrated with great enthusiasm. Locals prepare months in advance, cultivating crops and crafting goods for the occasion. The festival features a parade, various competitions, and a night market that lights up the town with vibrant colors and joyous energy.\n",
      "398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    print(text)\n",
    "    print(len(text))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f32363",
   "metadata": {},
   "source": [
    "`chunk_overlap` helps to mitigate loss of information when context is divided between chunks especially for really small chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63ebcb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators= [\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=100,\n",
    ")\n",
    "\n",
    "texts = text_splitter.split_text(doc)\n",
    "print(len(texts)) # 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b75e8732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Green Valley, a small town nestled in the heart of the mountains. With its picturesque landscapes and vibrant community life, Green Valley has been a hidden gem for years. The main street is lined with an array of shops and cafes, each offering a unique taste of local flavor and culture.\n",
      "299\n",
      "\n",
      "On a typical afternoon, the town square comes alive with the bustling sounds of locals and visitors mingling. Children play near the fountain, artists display their crafts, and an old man tells stories of days gone by. The aroma of freshly baked bread wafts from the bakery, drawing a steady stream\n",
      "298\n",
      "\n",
      "of days gone by. The aroma of freshly baked bread wafts from the bakery, drawing a steady stream of customers.\n",
      "110\n",
      "\n",
      "Green Valley is not only known for its scenic beauty but also for its annual festivals. The most anticipated event is the Harvest Festival, celebrated with great enthusiasm. Locals prepare months in advance, cultivating crops and crafting goods for the occasion. The festival features a parade,\n",
      "294\n",
      "\n",
      "in advance, cultivating crops and crafting goods for the occasion. The festival features a parade, various competitions, and a night market that lights up the town with vibrant colors and joyous energy.\n",
      "202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in texts:\n",
    "    print(text)\n",
    "    print(len(text))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17497b9",
   "metadata": {},
   "source": [
    "You can create LangChain `Document` chunks with the `create_documents` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2f3f51e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators= [\"\\n\\n\", \"\\n\", \" \", \"\"],\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df8acfbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='Welcome to Green Valley, a small town nestled in the heart of the mountains. With its picturesque landscapes and vibrant community life, Green Valley has been a hidden gem for years. The main street is lined with an array of shops and cafes, each offering a unique taste of local flavor and culture.'), Document(metadata={}, page_content='On a typical afternoon, the town square comes alive with the bustling sounds of locals and visitors mingling. Children play near the fountain, artists display their crafts, and an old man tells stories of days gone by. The aroma of freshly baked bread wafts from the bakery, drawing a steady stream of customers.'), Document(metadata={}, page_content='Green Valley is not only known for its scenic beauty but also for its annual festivals. The most anticipated event is the Harvest Festival, celebrated with great enthusiasm. Locals prepare months in advance, cultivating crops and crafting goods for the occasion. The festival features a parade, various competitions, and a night market that lights up the town with vibrant colors and joyous energy.')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = text_splitter.create_documents([doc])\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f3f0ba",
   "metadata": {},
   "source": [
    "### CharacterTextSplitter\n",
    "\n",
    "The `CharacterTextSplitter` is a straightforward tool in LangChain for dividing text based on a specified character. It's designed to be simple yet effective, providing essential controls for customizing how text is segmented.\n",
    "\n",
    "#### Key Features and Parameters:\n",
    "- **Split Character:** By default, it uses a empty string character (\"\") to split the text, but this can be customized to any character you specify.\n",
    "- **Chunk Size:** Allows you to define the length of each chunk in terms of the number of characters. This is useful for ensuring each piece of text is of a manageable size for processing.\n",
    "- **Overlap:** You can set the amount of overlap between consecutive chunks. This helps maintain context and continuity when text is split into separate parts.\n",
    "\n",
    "This method is the simplest among text splitting tools, focusing on character-based division and providing straightforward measures for chunk length and overlap.\n",
    "\n",
    "To obtain the string content directly, use `.split_text`.\n",
    "\n",
    "To create LangChain `Document` objects (e.g., for use in downstream tasks), use `.create_documents`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6675c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='Welcome to Green Valley, a small town nestled in the heart of the mountains. With its picturesque landscapes and vibrant community life, Green Valley has been a hidden gem for years. The main street is lined with an array of shops and cafes, each offering a unique taste of local flavor and culture.'), Document(metadata={}, page_content='On a typical afternoon, the town square comes alive with the bustling sounds of locals and visitors mingling. Children play near the fountain, artists display their crafts, and an old man tells stories of days gone by. The aroma of freshly baked bread wafts from the bakery, drawing a steady stream of customers.'), Document(metadata={}, page_content='Green Valley is not only known for its scenic beauty but also for its annual festivals. The most anticipated event is the Harvest Festival, celebrated with great enthusiasm. Locals prepare months in advance, cultivating crops and crafting goods for the occasion. The festival features a parade, various competitions, and a night market that lights up the town with vibrant colors and joyous energy.')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=200,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "docs = text_splitter.create_documents([doc])\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8213b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={}, page_content='Welcome to Green Valley, a small town nestled in the heart of the mountains. With its picturesque landscapes and vibrant community life, Green Valley has been a hidden gem for years. The main street is lined with an array of shops and cafes, each offering a unique taste of local flavor and culture.'),\n",
      " Document(metadata={}, page_content='On a typical afternoon, the town square comes alive with the bustling sounds of locals and visitors mingling. Children play near the fountain, artists display their crafts, and an old man tells stories of days gone by. The aroma of freshly baked bread wafts from the bakery, drawing a steady stream of customers.'),\n",
      " Document(metadata={}, page_content='Green Valley is not only known for its scenic beauty but also for its annual festivals. The most anticipated event is the Harvest Festival, celebrated with great enthusiasm. Locals prepare months in advance, cultivating crops and crafting goods for the occasion. The festival features a parade, various competitions, and a night market that lights up the town with vibrant colors and joyous energy.')]\n"
     ]
    }
   ],
   "source": [
    "pprint(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3b1ea37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "text = text_splitter.split_text(doc)\n",
    "print(len(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d0ccc769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Green Valley, a small town nestled in the heart of the mountains. With its picturesque landscapes and vibrant community life, Green Valley has been a hidden gem for years. The main street is lined with an array of shops and cafes, each offering a unique taste of local flavor and culture.\n",
      "299\n",
      "\n",
      "On a typical afternoon, the town square comes alive with the bustling sounds of locals and visitors mingling. Children play near the fountain, artists display their crafts, and an old man tells stories of days gone by. The aroma of freshly baked bread wafts from the bakery, drawing a steady stream of customers.\n",
      "312\n",
      "\n",
      "Green Valley is not only known for its scenic beauty but also for its annual festivals. The most anticipated event is the Harvest Festival, celebrated with great enthusiasm. Locals prepare months in advance, cultivating crops and crafting goods for the occasion. The festival features a parade, various competitions, and a night market that lights up the town with vibrant colors and joyous energy.\n",
      "398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in text:\n",
    "    print(t)\n",
    "    print(len(t))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f409b2",
   "metadata": {},
   "source": [
    "### Code Splitters\n",
    "\n",
    "`RecursiveCharacterTextSplitter` includes pre-built lists of separators that are useful for splitting text in a specific programming language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "07a17245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='def hello_world():\\n    print(\"Hello, World!\")'), Document(metadata={}, page_content='hello_world()')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, Language\n",
    "\n",
    "python_code = \"\"\"\n",
    "def hello_world():\n",
    "    print(\"Hello, World!\")\n",
    "hello_world()\n",
    "\"\"\"\n",
    "\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=50, chunk_overlap=0\n",
    ")\n",
    "python_docs = python_splitter.create_documents([python_code])\n",
    "python_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb8c6b9",
   "metadata": {},
   "source": [
    "### Markdown Splitters\n",
    "\n",
    "We might want to chunk a document based on the structure. For example, a markdown file is organized by headers. Creating chunks within specific header groups is an intuitive idea. To address this challenge, we can use MarkdownHeaderTextSplitter. This will split a markdown file by a specified set of headers.\n",
    "\n",
    "For example, if we want to split this markdown:\n",
    "\n",
    "```\n",
    "markdown_document = \"\"\"\n",
    "# Team Introductions\n",
    "\n",
    "## Management Team\n",
    "\n",
    "Hi, this is Jim, the CEO.  \n",
    "Hi, this is Joe, the CFO.\n",
    "\n",
    "## Development Team\n",
    "\n",
    "Hi, this is Molly, the Lead Developer.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "We can specify the headers to split on:\n",
    "\n",
    "```\n",
    "[(\"#\", \"Header 1\"),\n",
    " (\"##\", \"Header 2\")]\n",
    "```\n",
    "\n",
    "And content is grouped or split by common headers:\n",
    "\n",
    "```\n",
    "Document(page_content='Hi, this is Jim, the CEO.\\nHi, this is Joe, the CFO.',\n",
    "metadata={'Header 1': 'Team Introductions', 'Header 2': 'Management Team'})\n",
    "\n",
    "Document(page_content='Hi, this is Molly, the Lead Developer.',\n",
    "metadata={'Header 1': 'Team Introductions', 'Header 2': 'Development Team'})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d440b7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_document = \"\"\"\n",
    "# Team Introductions\n",
    "\n",
    "## Management Team\n",
    "Hi, this is Jim, the CEO.\n",
    "Hi, this is Joe, the CFO.\n",
    "\n",
    "## Development Team\n",
    "Hi, this is Molly, the Lead Developer.\n",
    "\n",
    "### Intern Team\n",
    "Hi, This is Subhash. The new Intern\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "54ad4bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Header 1': 'Team Introductions', 'Header 2': 'Management Team'}, page_content='Hi, this is Jim, the CEO.\\nHi, this is Joe, the CFO.'), Document(metadata={'Header 1': 'Team Introductions', 'Header 2': 'Development Team'}, page_content='Hi, this is Molly, the Lead Developer.'), Document(metadata={'Header 1': 'Team Introductions', 'Header 2': 'Development Team', 'Header 3': 'Intern Team'}, page_content='Hi, This is Subhash. The new Intern')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on)\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)\n",
    "md_header_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760e9f65",
   "metadata": {},
   "source": [
    "By default, `MarkdownHeaderTextSplitter` strips headers being split on from the output chunk's content. This can be disabled by setting `strip_headers = False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5681ba1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Header 1': 'Team Introductions', 'Header 2': 'Management Team'}, page_content='# Team Introductions  \\n## Management Team\\nHi, this is Jim, the CEO.\\nHi, this is Joe, the CFO.'), Document(metadata={'Header 1': 'Team Introductions', 'Header 2': 'Development Team'}, page_content='## Development Team\\nHi, this is Molly, the Lead Developer.'), Document(metadata={'Header 1': 'Team Introductions', 'Header 2': 'Development Team', 'Header 3': 'Intern Team'}, page_content='### Intern Team\\nHi, This is Subhash. The new Intern')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on, strip_headers=False)\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)\n",
    "md_header_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e9c52e",
   "metadata": {},
   "source": [
    "### Tokenizer based Splitting\n",
    "\n",
    "Language models have a token limit. You should not exceed the token limit. When you split your text into chunks it is therefore a good idea to count the number of tokens. There are many tokenizers. When you count tokens in your text you should use the same tokenizer as used in the language model. Let's look at how we can chunk documents using different tokenizers\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650ddff2",
   "metadata": {},
   "source": [
    "#### tiktoken splitters\n",
    "\n",
    "[`tiktoken`](https://github.com/openai/tiktoken) is a fast BPE tokenizer created by OpenAI.\n",
    "\n",
    "We can use tiktoken to estimate tokens used. It will probably be more accurate for the OpenAI models. We measure the `chunk_size`here based on the number of tokens typically and not the number of characters\n",
    "\n",
    "For Open AI models, roughly 1 token = 3\\4 words.\n",
    "\n",
    "Approx: 100 tokens ~= 75 words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ca863d",
   "metadata": {},
   "source": [
    "We can load a [`TokenTextSplitter`](https://api.python.langchain.com/en/latest/base/langchain_text_splitters.base.TokenTextSplitter.html) splitter, which works with `tiktoken` directly and will ensure each split is smaller than chunk size in terms of the number of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2fe2025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"\"\"Welcome to Green Valley, a small town nestled in the heart of the mountains. With its picturesque landscapes and vibrant community life, Green Valley has been a hidden gem for years. The main street is lined with an array of shops and cafes, each offering a unique taste of local flavor and culture.\n",
    "On a typical afternoon, the town square comes alive with the bustling sounds of locals and visitors mingling. Children play near the fountain, artists display their crafts, and an old man tells stories of days gone by. The aroma of freshly baked bread wafts from the bakery, drawing a steady stream of customers.\n",
    "Green Valley is not only known for its scenic beauty but also for its annual festivals. The most anticipated event is the Harvest Festival, celebrated with great enthusiasm. Locals prepare months in advance, cultivating crops and crafting goods for the occasion. The festival features a parade, various competitions, and a night market that lights up the town with vibrant colors and joyous energy.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5f7317a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import TokenTextSplitter\n",
    "\n",
    "text_splitter = TokenTextSplitter(model_name='gpt-4o-mini',\n",
    "                                  chunk_size=30,\n",
    "                                  chunk_overlap=10)\n",
    "\n",
    "docs = text_splitter.create_documents([doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9a55f52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c15f7d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='Welcome to Green Valley, a small town nestled in the heart of the mountains. With its picturesque landscapes and vibrant community life, Green Valley has been a'), Document(metadata={}, page_content=' and vibrant community life, Green Valley has been a hidden gem for years. The main street is lined with an array of shops and cafes, each offering'), Document(metadata={}, page_content=' with an array of shops and cafes, each offering a unique taste of local flavor and culture.\\nOn a typical afternoon, the town square comes alive with'), Document(metadata={}, page_content=' a typical afternoon, the town square comes alive with the bustling sounds of locals and visitors mingling. Children play near the fountain, artists display their crafts'), Document(metadata={}, page_content=' Children play near the fountain, artists display their crafts, and an old man tells stories of days gone by. The aroma of freshly baked bread wafts'), Document(metadata={}, page_content=' by. The aroma of freshly baked bread wafts from the bakery, drawing a steady stream of customers.\\nGreen Valley is not only known for its scenic'), Document(metadata={}, page_content='.\\nGreen Valley is not only known for its scenic beauty but also for its annual festivals. The most anticipated event is the Harvest Festival, celebrated with great'), Document(metadata={}, page_content=' anticipated event is the Harvest Festival, celebrated with great enthusiasm. Locals prepare months in advance, cultivating crops and crafting goods for the occasion. The festival'), Document(metadata={}, page_content=' crops and crafting goods for the occasion. The festival features a parade, various competitions, and a night market that lights up the town with vibrant colors and'), Document(metadata={}, page_content=' market that lights up the town with vibrant colors and joyous energy.\\n')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1b4c2e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: 27 Tokens: 30 Chunk: Welcome to Green Valley, a small town nestled in the heart of the mountains. With its picturesque landscapes and vibrant community life, Green Valley has been a\n",
      "Words: 28 Tokens: 30 Chunk:  and vibrant community life, Green Valley has been a hidden gem for years. The main street is lined with an array of shops and cafes, each offering\n",
      "Words: 27 Tokens: 30 Chunk:  with an array of shops and cafes, each offering a unique taste of local flavor and culture.\n",
      "On a typical afternoon, the town square comes alive with\n",
      "Words: 27 Tokens: 30 Chunk:  a typical afternoon, the town square comes alive with the bustling sounds of locals and visitors mingling. Children play near the fountain, artists display their crafts\n",
      "Words: 27 Tokens: 30 Chunk:  Children play near the fountain, artists display their crafts, and an old man tells stories of days gone by. The aroma of freshly baked bread wafts\n",
      "Words: 26 Tokens: 30 Chunk:  by. The aroma of freshly baked bread wafts from the bakery, drawing a steady stream of customers.\n",
      "Green Valley is not only known for its scenic\n",
      "Words: 27 Tokens: 30 Chunk: .\n",
      "Green Valley is not only known for its scenic beauty but also for its annual festivals. The most anticipated event is the Harvest Festival, celebrated with great\n",
      "Words: 26 Tokens: 30 Chunk:  anticipated event is the Harvest Festival, celebrated with great enthusiasm. Locals prepare months in advance, cultivating crops and crafting goods for the occasion. The festival\n",
      "Words: 28 Tokens: 30 Chunk:  crops and crafting goods for the occasion. The festival features a parade, various competitions, and a night market that lights up the town with vibrant colors and\n",
      "Words: 13 Tokens: 13 Chunk:  market that lights up the town with vibrant colors and joyous energy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
    "for d in docs:\n",
    "  print('Words:', len(d.page_content.split(' ')),\n",
    "        'Tokens:', len(enc.encode(d.page_content)),\n",
    "        'Chunk:', d.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "05f4b4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(model_name='gpt-4o-mini',\n",
    "                                  chunk_size=100,\n",
    "                                  chunk_overlap=30)\n",
    "\n",
    "docs = text_splitter.create_documents([doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "de3c8c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "030cba44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='Welcome to Green Valley, a small town nestled in the heart of the mountains. With its picturesque landscapes and vibrant community life, Green Valley has been a hidden gem for years. The main street is lined with an array of shops and cafes, each offering a unique taste of local flavor and culture.\\nOn a typical afternoon, the town square comes alive with the bustling sounds of locals and visitors mingling. Children play near the fountain, artists display their crafts, and an old man tells stories of days gone'), Document(metadata={}, page_content=' the bustling sounds of locals and visitors mingling. Children play near the fountain, artists display their crafts, and an old man tells stories of days gone by. The aroma of freshly baked bread wafts from the bakery, drawing a steady stream of customers.\\nGreen Valley is not only known for its scenic beauty but also for its annual festivals. The most anticipated event is the Harvest Festival, celebrated with great enthusiasm. Locals prepare months in advance, cultivating crops and crafting goods for the occasion. The festival'), Document(metadata={}, page_content=' anticipated event is the Harvest Festival, celebrated with great enthusiasm. Locals prepare months in advance, cultivating crops and crafting goods for the occasion. The festival features a parade, various competitions, and a night market that lights up the town with vibrant colors and joyous energy.\\n')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d4655ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: 88 Tokens: 100 Chunk: Welcome to Green Valley, a small town nestled in the heart of the mountains. With its picturesque landscapes and vibrant community life, Green Valley has been a hidden gem for years. The main street is lined with an array of shops and cafes, each offering a unique taste of local flavor and culture.\n",
      "On a typical afternoon, the town square comes alive with the bustling sounds of locals and visitors mingling. Children play near the fountain, artists display their crafts, and an old man tells stories of days gone\n",
      "Words: 86 Tokens: 100 Chunk:  the bustling sounds of locals and visitors mingling. Children play near the fountain, artists display their crafts, and an old man tells stories of days gone by. The aroma of freshly baked bread wafts from the bakery, drawing a steady stream of customers.\n",
      "Green Valley is not only known for its scenic beauty but also for its annual festivals. The most anticipated event is the Harvest Festival, celebrated with great enthusiasm. Locals prepare months in advance, cultivating crops and crafting goods for the occasion. The festival\n",
      "Words: 46 Tokens: 53 Chunk:  anticipated event is the Harvest Festival, celebrated with great enthusiasm. Locals prepare months in advance, cultivating crops and crafting goods for the occasion. The festival features a parade, various competitions, and a night market that lights up the town with vibrant colors and joyous energy.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enc = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
    "for d in docs:\n",
    "  print('Words:', len(d.page_content.split(' ')),\n",
    "        'Tokens:', len(enc.encode(d.page_content)),\n",
    "        'Chunk:', d.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38ed908",
   "metadata": {},
   "source": [
    "To implement a hard constraint on the chunk size, we can use `RecursiveCharacterTextSplitter.from_tiktoken_encoder`, where each split will be recursively split if it has a larger size and it makes the chunks more meaningful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4a3e9327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=30,\n",
    ")\n",
    "\n",
    "docs = text_splitter.create_documents([doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5dd6ae22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dc443221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='Welcome to Green Valley, a small town nestled in the heart of the mountains. With its picturesque landscapes and vibrant community life, Green Valley has been a hidden gem for years. The main street is lined with an array of shops and cafes, each offering a unique taste of local flavor and culture.'), Document(metadata={}, page_content='On a typical afternoon, the town square comes alive with the bustling sounds of locals and visitors mingling. Children play near the fountain, artists display their crafts, and an old man tells stories of days gone by. The aroma of freshly baked bread wafts from the bakery, drawing a steady stream of customers.'), Document(metadata={}, page_content='Green Valley is not only known for its scenic beauty but also for its annual festivals. The most anticipated event is the Harvest Festival, celebrated with great enthusiasm. Locals prepare months in advance, cultivating crops and crafting goods for the occasion. The festival features a parade, various competitions, and a night market that lights up the town with vibrant colors and joyous energy.')]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ad69f862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: 53 Tokens: 59 Chunk: Welcome to Green Valley, a small town nestled in the heart of the mountains. With its picturesque landscapes and vibrant community life, Green Valley has been a hidden gem for years. The main street is lined with an array of shops and cafes, each offering a unique taste of local flavor and culture.\n",
      "Words: 53 Tokens: 62 Chunk: On a typical afternoon, the town square comes alive with the bustling sounds of locals and visitors mingling. Children play near the fountain, artists display their crafts, and an old man tells stories of days gone by. The aroma of freshly baked bread wafts from the bakery, drawing a steady stream of customers.\n",
      "Words: 63 Tokens: 72 Chunk: Green Valley is not only known for its scenic beauty but also for its annual festivals. The most anticipated event is the Harvest Festival, celebrated with great enthusiasm. Locals prepare months in advance, cultivating crops and crafting goods for the occasion. The festival features a parade, various competitions, and a night market that lights up the town with vibrant colors and joyous energy.\n"
     ]
    }
   ],
   "source": [
    "enc = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
    "for d in docs:\n",
    "  print('Words:', len(d.page_content.split(' ')),\n",
    "        'Tokens:', len(enc.encode(d.page_content)),\n",
    "        'Chunk:', d.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ac7113",
   "metadata": {},
   "source": [
    "#### spaCy\n",
    "\n",
    "[spaCy](https://spacy.io/) is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython.\n",
    "\n",
    "LangChain implements splitters based on the [spaCy tokenizer](https://spacy.io/api/tokenizer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f397d281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a551161d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sourav.banerjee/Documents/My Codebases/GenerativAI_Demystified/venv/lib/python3.11/site-packages/spacy/pipeline/lemmatizer.py:188: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import SpacyTextSplitter\n",
    "\n",
    "text_splitter = SpacyTextSplitter(chunk_size=500,\n",
    "                                  chunk_overlap=50)\n",
    "\n",
    "docs = text_splitter.create_documents([doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e17a9b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c0402b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='Welcome to Green Valley, a small town nestled in the heart of the mountains.\\n\\nWith its picturesque landscapes and vibrant community life, Green Valley has been a hidden gem for years.\\n\\nThe main street is lined with an array of shops and cafes, each offering a unique taste of local flavor and culture.\\n\\n\\nOn a typical afternoon, the town square comes alive with the bustling sounds of locals and visitors mingling.'), Document(metadata={}, page_content='Children play near the fountain, artists display their crafts, and an old man tells stories of days gone by.\\n\\nThe aroma of freshly baked bread wafts from the bakery, drawing a steady stream of customers.\\n\\n\\nGreen Valley is not only known for its scenic beauty but also for its annual festivals.\\n\\nThe most anticipated event is the Harvest Festival, celebrated with great enthusiasm.\\n\\nLocals prepare months in advance, cultivating crops and crafting goods for the occasion.'), Document(metadata={}, page_content='The festival features a parade, various competitions, and a night market that lights up the town with vibrant colors and joyous energy.')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8a5f8e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: 68 Characters: 413 Chunk: Welcome to Green Valley, a small town nestled in the heart of the mountains.\n",
      "\n",
      "With its picturesque landscapes and vibrant community life, Green Valley has been a hidden gem for years.\n",
      "\n",
      "The main street is lined with an array of shops and cafes, each offering a unique taste of local flavor and culture.\n",
      "\n",
      "\n",
      "On a typical afternoon, the town square comes alive with the bustling sounds of locals and visitors mingling.\n",
      "Words: 72 Characters: 470 Chunk: Children play near the fountain, artists display their crafts, and an old man tells stories of days gone by.\n",
      "\n",
      "The aroma of freshly baked bread wafts from the bakery, drawing a steady stream of customers.\n",
      "\n",
      "\n",
      "Green Valley is not only known for its scenic beauty but also for its annual festivals.\n",
      "\n",
      "The most anticipated event is the Harvest Festival, celebrated with great enthusiasm.\n",
      "\n",
      "Locals prepare months in advance, cultivating crops and crafting goods for the occasion.\n",
      "Words: 22 Characters: 135 Chunk: The festival features a parade, various competitions, and a night market that lights up the town with vibrant colors and joyous energy.\n"
     ]
    }
   ],
   "source": [
    "for d in docs:\n",
    "  print('Words:', len(d.page_content.split(' ')),\n",
    "        'Characters:', len(d.page_content),\n",
    "        'Chunk:', d.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425b2093",
   "metadata": {},
   "source": [
    "#### SentenceTransformers\n",
    "\n",
    "The [`SentenceTransformersTokenTextSplitter`](https://api.python.langchain.com/en/latest/sentence_transformers/langchain_text_splitters.sentence_transformers.SentenceTransformersTokenTextSplitter.html) is a specialized text splitter for use with the `sentence-transformer` language models.\n",
    "\n",
    "The default behaviour is to split the text into chunks that fit the token window of the sentence transformer model that you would like to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7fb45ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c8d412a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfb2e1a381c84a69bda0e7fccb0a2ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0dfb15af20f44ea8d29d9ede65d9a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d497ae1d4d84c349066734b412bd060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6616816c0d64b9b9cf966deb5752628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd186ffcead43418b01af7c0b020cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1167efc3dc7347af874d82da02082106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f57a4a7be4c644fd80270766ab73f5f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a69866be0c46c7b8cfdac27ed34f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82cc674e58e742d19e6a2715bd698ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "751de24b089e43f581c71d32cf2961de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "942f5e8f735b492b9cbc01571846d80e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_text_splitters import SentenceTransformersTokenTextSplitter\n",
    "\n",
    "splitter = SentenceTransformersTokenTextSplitter(model_name=\"sentence-transformers/all-mpnet-base-v2\",\n",
    "                                                 tokens_per_chunk=100,\n",
    "                                                 chunk_overlap=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6d67bb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = splitter.create_documents([doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ada7c43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0f11bb0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='welcome to green valley, a small town nestled in the heart of the mountains. with its picturesque landscapes and vibrant community life, green valley has been a hidden gem for years. the main street is lined with an array of shops and cafes, each offering a unique taste of local flavor and culture. on a typical afternoon, the town square comes alive with the bustling sounds of locals and visitors mingling. children play near the fountain, artists display their crafts, and an old man tells stories of days'), Document(metadata={}, page_content='the bustling sounds of locals and visitors mingling. children play near the fountain, artists display their crafts, and an old man tells stories of days gone by. the aroma of freshly baked bread wafts from the bakery, drawing a steady stream of customers. green valley is not only known for its scenic beauty but also for its annual festivals. the most anticipated event is the harvest festival, celebrated with great enthusiasm. locals prepare months in advance, cultivating crops and crafting goods for the occasion'), Document(metadata={}, page_content='the most anticipated event is the harvest festival, celebrated with great enthusiasm. locals prepare months in advance, cultivating crops and crafting goods for the occasion. the festival features a parade, various competitions, and a night market that lights up the town with vibrant colors and joyous energy.')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fb3c62a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words: 88 Characters: 509 Chunk: welcome to green valley, a small town nestled in the heart of the mountains. with its picturesque landscapes and vibrant community life, green valley has been a hidden gem for years. the main street is lined with an array of shops and cafes, each offering a unique taste of local flavor and culture. on a typical afternoon, the town square comes alive with the bustling sounds of locals and visitors mingling. children play near the fountain, artists display their crafts, and an old man tells stories of days\n",
      "Words: 84 Characters: 517 Chunk: the bustling sounds of locals and visitors mingling. children play near the fountain, artists display their crafts, and an old man tells stories of days gone by. the aroma of freshly baked bread wafts from the bakery, drawing a steady stream of customers. green valley is not only known for its scenic beauty but also for its annual festivals. the most anticipated event is the harvest festival, celebrated with great enthusiasm. locals prepare months in advance, cultivating crops and crafting goods for the occasion\n",
      "Words: 47 Characters: 310 Chunk: the most anticipated event is the harvest festival, celebrated with great enthusiasm. locals prepare months in advance, cultivating crops and crafting goods for the occasion. the festival features a parade, various competitions, and a night market that lights up the town with vibrant colors and joyous energy.\n"
     ]
    }
   ],
   "source": [
    "for d in docs:\n",
    "  print('Words:', len(d.page_content.split(' ')),\n",
    "        'Characters:', len(d.page_content),\n",
    "        'Chunk:', d.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b892ee",
   "metadata": {},
   "source": [
    "### Section-based Splitting in Unstructured.io\n",
    "\n",
    "Chunking functions in `unstructured` use metadata and document elements detected with partition functions to split a document into smaller parts for uses cases such as Retrieval Augmented Generation (RAG).\n",
    "\n",
    "`unstructured` uses specific knowledge about each document format to partition the document into semantic units (document elements), we only need to resort to text-splitting when a single element exceeds the desired maximum chunk size. Except in that case, all chunks contain one or more whole elements, preserving the coherence of semantic units established during partitioning.\n",
    "\n",
    "- Chunking is performed on document elements. It is a separate step performed after partitioning, on the elements produced by partitioning. (Although it can be combined with partitioning in a single step.)\n",
    "\n",
    "- Chunking combines consecutive elements to form chunks as large as possible without exceeding the maximum chunk size.\n",
    "\n",
    "- A single element that by itself exceeds the maximum chunk size is divided into two or more chunks using text-splitting.\n",
    "\n",
    "- Chunking produces a sequence of `CompositeElement`, `Table`, or `TableChunk` elements. Each “chunk” is an instance of one of these three types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d46c87e",
   "metadata": {},
   "source": [
    "Chunking Options:\n",
    "\n",
    "The following options are available to tune chunking behaviors. These are keyword arguments that can be used in a partitioning or chunking function call. All these options have defaults and need only be specified when a non-default setting is required. Specific chunking strategies (such as “by-title”) may have additional options.\n",
    "\n",
    "- `max_characters`: (default=500) - the hard maximum size for a chunk. No chunk will exceed this number of characters. A single element that by itself exceeds this size will be divided into two or more chunks using text-splitting.\n",
    "\n",
    "- `new_after_n_chars`: (default=max_characters) - the “soft” maximum size for a chunk. A chunk that already exceeds this number of characters will not be extended, even if the next _element_ would fit without exceeding the specified hard maximum. This can be used in conjunction with `max_characters` to set a “preferred” size, like “I prefer chunks of around 1000 characters, but I’d rather have a chunk of 1500 (max_characters) than resort to text-splitting”. This would be specified with `(..., max_characters=1500, new_after_n_chars=1000)`.\n",
    "\n",
    "- `overlap`: (default=0) - only when using text-splitting to break up an oversized chunk, include this number of characters from the end of the prior chunk as a prefix on the next. This can mitigate the effect of splitting the semantic unit represented by the oversized element at an arbitrary position based on text length.\n",
    "\n",
    "- `combine_text_under_n_chars argument`: This defaults to the same value as `max_characters` such that sequential small section chunks are combined to maximally fill the chunking window to produce a logically larger chunk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2dc12e",
   "metadata": {},
   "source": [
    "There are currently two chunking strategies, `basic` and `by_title`.\n",
    "\n",
    "The `basic` strategy combines sequential elements to maximally fill each chunk while respecting both the specified max_characters (hard-max) and new_after_n_chars (soft-max) option values.\n",
    "\n",
    "The `by_title` chunking strategy preserves section boundaries and optionally page boundaries as well. “Preserving” here means that a single chunk will never contain text that occurred in two different sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "69718bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt_tab: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1006)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0515ca4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading averaged_perceptron_tagger_eng: <urlopen\n",
      "[nltk_data]     error [SSL: CERTIFICATE_VERIFY_FAILED] certificate\n",
      "[nltk_data]     verify failed: unable to get local issuer certificate\n",
      "[nltk_data]     (_ssl.c:1006)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dfd77509",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
    "\n",
    "# takes 3-4 mins on Colab\n",
    "loader = UnstructuredPDFLoader('../../docs/layoutparser_paper.pdf',\n",
    "                               strategy='hi_res',\n",
    "                               extract_images_in_pdf=False,\n",
    "                               infer_table_structure=True,\n",
    "                               chunking_strategy=\"by_title\",\n",
    "                               max_characters=4000,\n",
    "                               new_after_n_chars=3800,\n",
    "                               combine_text_under_n_chars=2000,\n",
    "                               mode='elements')\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1afd052f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7f1d961d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CompositeElement', 'CompositeElement', 'CompositeElement', 'CompositeElement', 'CompositeElement', 'CompositeElement', 'CompositeElement', 'CompositeElement', 'CompositeElement', 'CompositeElement', 'CompositeElement', 'CompositeElement', 'CompositeElement', 'CompositeElement', 'CompositeElement', 'CompositeElement']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[doc.metadata['category'] for doc in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7d67c30c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '../../docs/layoutparser_paper.pdf', 'filetype': 'application/pdf', 'languages': ['eng'], 'last_modified': '2025-05-30T10:16:46', 'page_number': 1, 'orig_elements': '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', 'file_directory': '../../docs', 'filename': 'layoutparser_paper.pdf', 'category': 'CompositeElement', 'element_id': 'e92d93955d4e5194e452e84f607f1c86'}, page_content='1 2 0 2 n u J 1 2 ] V C . s\\n\\nc\\n\\n[\\n\\n2\\n\\n2103.15348v2 arXiv\\n\\nv\\n\\n8\\n\\n4\\n\\n3\\n\\n5\\n\\n1\\n\\n.\\n\\n3\\n\\n0\\n\\n1\\n\\n2\\n\\n:\\n\\nv\\n\\ni\\n\\nX\\n\\nr\\n\\na\\n\\nLayoutParser: A Uniﬁed Toolkit for Deep Learning Based Document Image Analysis\\n\\nZejiang Shen! (4), Ruochen Zhang”, Melissa Dell?, Benjamin Charles Germain Lee*, Jacob Carlson’, and Weining Li®\\n\\n1 Allen Institute for AI shannons@allenai.org 2 Brown University ruochen zhang@brown.edu 3 Harvard University {melissadell,jacob carlson}@fas.harvard.edu 4 University of Washington bcgl@cs.washington.edu 5 University of Waterloo w422li@uwaterloo.ca\\n\\nAbstract. Recent advances in document image analysis (DIA) have been primarily driven by the application of neural networks. Ideally, research outcomes could be easily deployed in production and extended for further investigation. However, various factors like loosely organized codebases and sophisticated model conﬁgurations complicate the easy reuse of im- portant innovations by a wide audience. Though there have been on-going eﬀorts to improve reusability and simplify deep learning (DL) model development in disciplines like natural language processing and computer vision, none of them are optimized for challenges in the domain of DIA. This represents a major gap in the existing toolkit, as DIA is central to academic research across a wide range of disciplines in the social sciences and humanities. This paper introduces LayoutParser, an open-source library for streamlining the usage of DL in DIA research and applica- tions. The core LayoutParser library comes with a set of simple and intuitive interfaces for applying and customizing DL models for layout de- tection, character recognition, and many other document processing tasks. To promote extensibility, LayoutParser also incorporates a community platform for sharing both pre-trained models and full document digiti- zation pipelines. We demonstrate that LayoutParser is helpful for both lightweight and large-scale digitization pipelines in real-word use cases. The library is publicly available at https://layout-parser.github.io.\\n\\nKeywords: Document Image Analysis · Deep Learning · Layout Analysis · Character Recognition · Open Source library · Toolkit.')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d1ec8ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 0 2 n u J 1 2 ] V C . s\n",
      "\n",
      "c\n",
      "\n",
      "[\n",
      "\n",
      "2\n",
      "\n",
      "2103.15348v2 arXiv\n",
      "\n",
      "v\n",
      "\n",
      "8\n",
      "\n",
      "4\n",
      "\n",
      "3\n",
      "\n",
      "5\n",
      "\n",
      "1\n",
      "\n",
      ".\n",
      "\n",
      "3\n",
      "\n",
      "0\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      ":\n",
      "\n",
      "v\n",
      "\n",
      "i\n",
      "\n",
      "X\n",
      "\n",
      "r\n",
      "\n",
      "a\n",
      "\n",
      "LayoutParser: A Uniﬁed Toolkit for Deep Learning Based Document Image Analysis\n",
      "\n",
      "Zejiang Shen! (4), Ruochen Zhang”, Melissa Dell?, Benjamin Charles Germain Lee*, Jacob Carlson’, and Weining Li®\n",
      "\n",
      "1 Allen Institute for AI shannons@allenai.org 2 Brown University ruochen zhang@brown.edu 3 Harvard University {melissadell,jacob carlson}@fas.harvard.edu 4 University of Washington bcgl@cs.washington.edu 5 University of Waterloo w422li@uwaterloo.ca\n",
      "\n",
      "Abstract. Recent advances in document image analysis (DIA) have been primarily driven by the application of neural networks. Ideally, research outcomes could be easily deployed in production and extended for further investigation. However, various factors like loosely organized codebases and sophisticated model conﬁgurations complicate the easy reuse of im- portant innovations by a wide audience. Though there have been on-going eﬀorts to improve reusability and simplify deep learning (DL) model development in disciplines like natural language processing and computer vision, none of them are optimized for challenges in the domain of DIA. This represents a major gap in the existing toolkit, as DIA is central to academic research across a wide range of disciplines in the social sciences and humanities. This paper introduces LayoutParser, an open-source library for streamlining the usage of DL in DIA research and applica- tions. The core LayoutParser library comes with a set of simple and intuitive interfaces for applying and customizing DL models for layout de- tection, character recognition, and many other document processing tasks. To promote extensibility, LayoutParser also incorporates a community platform for sharing both pre-trained models and full document digiti- zation pipelines. We demonstrate that LayoutParser is helpful for both lightweight and large-scale digitization pipelines in real-word use cases. The library is publicly available at https://layout-parser.github.io.\n",
      "\n",
      "Keywords: Document Image Analysis · Deep Learning · Layout Analysis · Character Recognition · Open Source library · Toolkit.\n"
     ]
    }
   ],
   "source": [
    "print(data[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "becf352a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': '../../docs/layoutparser_paper.pdf', 'filetype': 'application/pdf', 'languages': ['eng'], 'last_modified': '2025-05-30T10:16:46', 'page_number': 1, 'orig_elements': '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', 'file_directory': '../../docs', 'filename': 'layoutparser_paper.pdf', 'category': 'CompositeElement', 'element_id': 'd20214c808c037f1e143967102db98c5'}, page_content='1 Introduction\\n\\nDeep Learning(DL)-based approaches are the state-of-the-art for a wide range of document image analysis (DIA) tasks including document image classiﬁcation [11,\\n\\n2 Z. Shen et al.\\n\\n37], layout detection [38, 22], table detection [26], and scene text detection [4]. A generalized learning-based framework dramatically reduces the need for the manual speciﬁcation of complicated rules, which is the status quo with traditional methods. DL has the potential to transform DIA pipelines and beneﬁt a broad spectrum of large-scale document digitization projects.\\n\\nHowever, there are several practical diﬃculties for taking advantages of re- cent advances in DL-based methods: 1) DL models are notoriously convoluted for reuse and extension. Existing models are developed using distinct frame- works like TensorFlow [1] or PyTorch [24], and the high-level parameters can be obfuscated by implementation details [8]. It can be a time-consuming and frustrating experience to debug, reproduce, and adapt existing models for DIA, and many researchers who would beneﬁt the most from using these methods lack the technical background to implement them from scratch. 2) Document images contain diverse and disparate patterns across domains, and customized training is often required to achieve a desirable detection accuracy. Currently there is no full-ﬂedged infrastructure for easily curating the target document image datasets and ﬁne-tuning or re-training the models. 3) DIA usually requires a sequence of models and other processing to obtain the ﬁnal outputs. Often research teams use DL models and then perform further document analyses in separate processes, and these pipelines are not documented in any central location (and often not documented at all). This makes it diﬃcult for research teams to learn about how full pipelines are implemented and leads them to invest signiﬁcant resources in reinventing the DIA wheel.\\n\\nLayoutParser provides a uniﬁed toolkit to support DL-based document image analysis and processing. To address the aforementioned challenges, LayoutParser is built with the following components:\\n\\n1. An oﬀ-the-shelf toolkit for applying DL models for layout detection, character recognition, and other DIA tasks (Section 3)\\n\\n2. A rich repository of pre-trained neural network models (Model Zoo) that underlies the oﬀ-the-shelf usage\\n\\n3. Comprehensive tools for eﬃcient document image data annotation and model tuning to support diﬀerent levels of customization\\n\\n4. A DL model hub and community platform for the easy sharing, distribu- tion, and discussion of DIA models and pipelines, to promote reusability, reproducibility, and extensibility (Section 4)\\n\\nThe library implements simple and intuitive Python APIs without sacriﬁcing generalizability and versatility, and can be easily installed via pip. Its convenient functions for handling document image data can be seamlessly integrated with existing DIA pipelines. With detailed documentations and carefully curated tutorials, we hope this tool will beneﬁt a variety of end-users, and will lead to advances in applications in both industry and academic research.\\n\\nLayoutParser is well aligned with recent eﬀorts for improving DL model reusability in other disciplines like natural language processing [8, 34] and com- puter vision [35], but with a focus on unique challenges in DIA. We show LayoutParser can be applied in sophisticated and large-scale digitization projects\\n\\nLayoutParser: A Uniﬁed Toolkit for DL-Based DIA\\n\\nthat require precision, eﬃciency, and robustness, as well as simple and light- weight document processing tasks focusing on eﬃcacy and ﬂexibility (Section 5). LayoutParser is being actively maintained, and support for more deep learning models and novel methods in text-based layout analysis methods [37, 34] is planned.')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "362b515e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Introduction\n",
      "\n",
      "Deep Learning(DL)-based approaches are the state-of-the-art for a wide range of document image analysis (DIA) tasks including document image classiﬁcation [11,\n",
      "\n",
      "2 Z. Shen et al.\n",
      "\n",
      "37], layout detection [38, 22], table detection [26], and scene text detection [4]. A generalized learning-based framework dramatically reduces the need for the manual speciﬁcation of complicated rules, which is the status quo with traditional methods. DL has the potential to transform DIA pipelines and beneﬁt a broad spectrum of large-scale document digitization projects.\n",
      "\n",
      "However, there are several practical diﬃculties for taking advantages of re- cent advances in DL-based methods: 1) DL models are notoriously convoluted for reuse and extension. Existing models are developed using distinct frame- works like TensorFlow [1] or PyTorch [24], and the high-level parameters can be obfuscated by implementation details [8]. It can be a time-consuming and frustrating experience to debug, reproduce, and adapt existing models for DIA, and many researchers who would beneﬁt the most from using these methods lack the technical background to implement them from scratch. 2) Document images contain diverse and disparate patterns across domains, and customized training is often required to achieve a desirable detection accuracy. Currently there is no full-ﬂedged infrastructure for easily curating the target document image datasets and ﬁne-tuning or re-training the models. 3) DIA usually requires a sequence of models and other processing to obtain the ﬁnal outputs. Often research teams use DL models and then perform further document analyses in separate processes, and these pipelines are not documented in any central location (and often not documented at all). This makes it diﬃcult for research teams to learn about how full pipelines are implemented and leads them to invest signiﬁcant resources in reinventing the DIA wheel.\n",
      "\n",
      "LayoutParser provides a uniﬁed toolkit to support DL-based document image analysis and processing. To address the aforementioned challenges, LayoutParser is built with the following components:\n",
      "\n",
      "1. An oﬀ-the-shelf toolkit for applying DL models for layout detection, character recognition, and other DIA tasks (Section 3)\n",
      "\n",
      "2. A rich repository of pre-trained neural network models (Model Zoo) that underlies the oﬀ-the-shelf usage\n",
      "\n",
      "3. Comprehensive tools for eﬃcient document image data annotation and model tuning to support diﬀerent levels of customization\n",
      "\n",
      "4. A DL model hub and community platform for the easy sharing, distribu- tion, and discussion of DIA models and pipelines, to promote reusability, reproducibility, and extensibility (Section 4)\n",
      "\n",
      "The library implements simple and intuitive Python APIs without sacriﬁcing generalizability and versatility, and can be easily installed via pip. Its convenient functions for handling document image data can be seamlessly integrated with existing DIA pipelines. With detailed documentations and carefully curated tutorials, we hope this tool will beneﬁt a variety of end-users, and will lead to advances in applications in both industry and academic research.\n",
      "\n",
      "LayoutParser is well aligned with recent eﬀorts for improving DL model reusability in other disciplines like natural language processing [8, 34] and com- puter vision [35], but with a focus on unique challenges in DIA. We show LayoutParser can be applied in sophisticated and large-scale digitization projects\n",
      "\n",
      "LayoutParser: A Uniﬁed Toolkit for DL-Based DIA\n",
      "\n",
      "that require precision, eﬃciency, and robustness, as well as simple and light- weight document processing tasks focusing on eﬃcacy and ﬂexibility (Section 5). LayoutParser is being actively maintained, and support for more deep learning models and novel methods in text-based layout analysis methods [37, 34] is planned.\n"
     ]
    }
   ],
   "source": [
    "print(data[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1577387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
