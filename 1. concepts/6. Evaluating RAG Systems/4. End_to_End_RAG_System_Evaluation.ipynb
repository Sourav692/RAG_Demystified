{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "994b85fa-efad-45cf-beb5-726d0e83788f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Reference Link:** [RAG Systems Essentials (Analytics Vidhya)](https://courses.analyticsvidhya.com/courses/take/rag-systems-essentials/lessons/60148017-hands-on-deep-dive-into-rag-evaluation-metrics-generator-metrics-i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a82023d2-509e-4932-967b-d6dece6c1bd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "jbw4wHV4zlKj"
   },
   "source": [
    "# Build a Simple RAG System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "178011b0-c6d8-46e9-95b9-bfedfca519e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "4vtFl39Ofu_8"
   },
   "source": [
    "## Install OpenAI, and LangChain dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c2bc5193-950b-4547-88f6-d1f35d2eeb7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37138,
     "status": "ok",
     "timestamp": 1734095199040,
     "user": {
      "displayName": "Dipanjan ‚ÄúDJ‚Äù Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "LVX6450Lfu_9",
    "outputId": "e27aa4b8-b2b3-453e-9b0e-50c3cfa6373e"
   },
   "outputs": [],
   "source": [
    "!pip install -qq langchain\n",
    "!pip install -qq langchain-openai\n",
    "!pip install -qq langchain-community\n",
    "!pip install -qq dill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ecfbe722-f618-4779-8b90-0973032c1f14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "bwUBYHjPfu_-"
   },
   "source": [
    "## Install Chroma Vector DB and LangChain wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd33ff89-0059-465b-984c-dc8af96427d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 40219,
     "status": "ok",
     "timestamp": 1734095239256,
     "user": {
      "displayName": "Dipanjan ‚ÄúDJ‚Äù Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "p30SmCgTfu__",
    "outputId": "25bb3e59-cc15-406d-bdc3-57f61b581c75"
   },
   "outputs": [],
   "source": [
    "!pip install -qq langchain-chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67620d09-3366-4459-a51c-1d5498519c21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "lVJuo_Tyu4xv"
   },
   "source": [
    "## Install RAG Evaluation Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "20516607-53f1-4ba5-977a-8bb182cb0a4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 32283,
     "status": "ok",
     "timestamp": 1734095271535,
     "user": {
      "displayName": "Dipanjan ‚ÄúDJ‚Äù Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "CkBlAPKHu4Ih",
    "outputId": "e3dcabc8-7974-4c38-b7d4-4961d4fba51e"
   },
   "outputs": [],
   "source": [
    "!pip install -qq ragas\n",
    "!pip install -qq deepeval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3abf5449-33c2-4fab-b3e2-1b5c12a95faf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "EITC17hwfu__"
   },
   "source": [
    "## Enter Open AI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c44dcbf5-a183-4bf7-9294-7e395b0f1537",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3135,
     "status": "ok",
     "timestamp": 1734095563906,
     "user": {
      "displayName": "Dipanjan ‚ÄúDJ‚Äù Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "yEh2olNvfvAA",
    "outputId": "e683fcf2-04c5-47d3-b862-14f68dd2e843"
   },
   "outputs": [],
   "source": [
    "# from getpass import getpass\n",
    "\n",
    "# OPENAI_KEY = getpass('Enter Open AI API Key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ea7a0c80-e955-4629-8386-8a2d207db786",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "pm_mx0v-fvAA"
   },
   "source": [
    "## Setup Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a7086ec1-b9ac-4977-a879-988f9839dc30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "executionInfo": {
     "elapsed": 347,
     "status": "ok",
     "timestamp": 1734095566435,
     "user": {
      "displayName": "Dipanjan ‚ÄúDJ‚Äù Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "Jhfb4gMUfvAC"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# os.environ['OPENAI_API_KEY'] = OPENAI_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0725313a-c0f6-4931-9bf2-9bcdc82ce36a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "jiokYxD8fvAC"
   },
   "source": [
    "### Open AI Embedding Models\n",
    "\n",
    "LangChain enables us to access Open AI embedding models which include the newest models: a smaller and highly efficient `text-embedding-3-small` model, and a larger and more powerful `text-embedding-3-large` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc993a28-14f8-4ed9-be58-5591c092fe82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "executionInfo": {
     "elapsed": 3076,
     "status": "ok",
     "timestamp": 1734095571809,
     "user": {
      "displayName": "Dipanjan ‚ÄúDJ‚Äù Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "-On4AS0HfvAD"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# details here: https://openai.com/blog/new-embedding-models-and-api-updates\n",
    "openai_embed_model = OpenAIEmbeddings(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac3631b1-fc8b-4d5f-9d14-d94834aee36f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "afzeN_WkHIz2"
   },
   "source": [
    "## Loading and Processing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a88fccfe-1aee-4ebd-bf32-1681859a3dea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "RA_-hzHbFeSP"
   },
   "source": [
    "### Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d72106e-e88e-46de-910f-698415e1a1a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4857,
     "status": "ok",
     "timestamp": 1734095579822,
     "user": {
      "displayName": "Dipanjan ‚ÄúDJ‚Äù Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "RZFMYH-yFhWn",
    "outputId": "c3e648ba-3f02-428e-c724-6c3fae437f62"
   },
   "outputs": [],
   "source": [
    "# if you can't download using the following code\n",
    "# go to https://drive.google.com/file/d/1QkSY9W5RyaBnY8c5FLIsmpPVXoHTQ-fb/view?usp=sharing download it\n",
    "# manually upload it on colab\n",
    "# !gdown 1QkSY9W5RyaBnY8c5FLIsmpPVXoHTQ-fb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8caac880-28b4-477d-81f7-3dc6d4b71859",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "wMlxKZ_5jIdE"
   },
   "source": [
    "### Load and Process JSON Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7bf3ab84-04ee-41b4-8fd8-d090bd4020f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "executionInfo": {
     "elapsed": 613,
     "status": "ok",
     "timestamp": 1734095580434,
     "user": {
      "displayName": "Dipanjan ‚ÄúDJ‚Äù Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "RZ5y0NfzHPhg",
    "outputId": "824fd250-0b64-4bb5-a701-278c30e1162e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Machine learning is a field of artificial inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Deep learning is a subset of machine learning ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Natural Language Processing (NLP)</td>\n",
       "      <td>NLP is a branch of AI that enables computers t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Pyramids</td>\n",
       "      <td>Pyramids are ancient structures, often serving...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Photosynthesis</td>\n",
       "      <td>Photosynthesis is the process plants use to co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Biology</td>\n",
       "      <td>Biology is the study of living organisms, cove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Quantum Mechanics</td>\n",
       "      <td>Quantum mechanics is a branch of physics that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Cryptocurrency</td>\n",
       "      <td>Cryptocurrency is a digital currency that uses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Renewable Energy</td>\n",
       "      <td>Renewable energy sources, such as solar and wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>Artificial intelligence refers to machines mim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                              title  \\\n",
       "0   1                   Machine Learning   \n",
       "1   2                      Deep Learning   \n",
       "2   3  Natural Language Processing (NLP)   \n",
       "3   4                           Pyramids   \n",
       "4   5                     Photosynthesis   \n",
       "5   6                            Biology   \n",
       "6   7                  Quantum Mechanics   \n",
       "7   8                     Cryptocurrency   \n",
       "8   9                   Renewable Energy   \n",
       "9  10            Artificial Intelligence   \n",
       "\n",
       "                                             context  \n",
       "0  Machine learning is a field of artificial inte...  \n",
       "1  Deep learning is a subset of machine learning ...  \n",
       "2  NLP is a branch of AI that enables computers t...  \n",
       "3  Pyramids are ancient structures, often serving...  \n",
       "4  Photosynthesis is the process plants use to co...  \n",
       "5  Biology is the study of living organisms, cove...  \n",
       "6  Quantum mechanics is a branch of physics that ...  \n",
       "7  Cryptocurrency is a digital currency that uses...  \n",
       "8  Renewable energy sources, such as solar and wi...  \n",
       "9  Artificial intelligence refers to machines mim...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../../docs/rag_eval_docs.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7c2c0c87-78f0-4d03-a93e-0992d5c6d3ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1734095580435,
     "user": {
      "displayName": "Dipanjan ‚ÄúDJ‚Äù Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "wE4l0DG7tpTI",
    "outputId": "9daba315-9520-4339-847f-33176eff6e88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 1,\n",
       "  'title': 'Machine Learning',\n",
       "  'context': 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.'},\n",
       " {'id': 2,\n",
       "  'title': 'Deep Learning',\n",
       "  'context': 'Deep learning is a subset of machine learning utilizing neural networks with many layers. It excels in complex tasks like image and speech recognition. Convolutional and recurrent neural networks are among the common architectures used.'},\n",
       " {'id': 3,\n",
       "  'title': 'Natural Language Processing (NLP)',\n",
       "  'context': 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = df.to_dict(orient='records')\n",
    "docs[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df20a004-2750-4c1b-8fef-2431045082d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 358,
     "status": "ok",
     "timestamp": 1734095584182,
     "user": {
      "displayName": "Dipanjan ‚ÄúDJ‚Äù Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "yICyAF85h2DO",
    "outputId": "4b4237c5-1d47-40a9-bfe6-a000a08b1f09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'Machine Learning', 'id': 1}, page_content='Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.'),\n",
       " Document(metadata={'title': 'Deep Learning', 'id': 2}, page_content='Deep learning is a subset of machine learning utilizing neural networks with many layers. It excels in complex tasks like image and speech recognition. Convolutional and recurrent neural networks are among the common architectures used.'),\n",
       " Document(metadata={'title': 'Natural Language Processing (NLP)', 'id': 3}, page_content='NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.docstore.document import Document\n",
    "processed_docs = []\n",
    "\n",
    "for doc in docs:\n",
    "    metadata = {\n",
    "        \"title\": doc['title'],\n",
    "        \"id\": doc['id'],\n",
    "    }\n",
    "    data = doc['context']\n",
    "    processed_docs.append(Document(page_content=data, metadata=metadata))\n",
    "processed_docs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2d07084-9558-4385-8db7-a6b15d34832a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Daqn6Hglw9Nk"
   },
   "source": [
    "## Index Document Chunks and Embeddings in Vector DB\n",
    "\n",
    "Here we initialize a connection to a Chroma vector DB client, and also we want to save to disk, so we simply initialize the Chroma client and pass the directory where we want the data to be saved to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "57b83f4e-46a9-47f4-bcf2-14518954a571",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "EYjyZdCyw9Nl"
   },
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "# create vector DB of docs and embeddings - takes < 30s on Colab\n",
    "chroma_db = Chroma.from_documents(documents=processed_docs,\n",
    "                                  collection_name='my_db',\n",
    "                                  embedding=openai_embed_model,\n",
    "                                  # need to set the distance function to cosine else it uses euclidean by default\n",
    "                                  # check https://docs.trychroma.com/guides#changing-the-distance-function\n",
    "                                  collection_metadata={\"hnsw:space\": \"cosine\"},\n",
    "                                  persist_directory=\"./my_db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2f1c9372-9e08-4abf-a11a-547eff480883",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "B-0qbbpjw9Nl"
   },
   "source": [
    "### Load Vector DB from disk\n",
    "\n",
    "This is just to show once you have a vector database on disk you can just load and create a connection to it anytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0614e443-a215-41d9-af7e-7902aa97fb0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "PI3ITuGZw9Nl"
   },
   "outputs": [],
   "source": [
    "# load from disk\n",
    "chroma_db = Chroma(persist_directory=\"./my_db\",\n",
    "                   collection_name='my_db',\n",
    "                   embedding_function=openai_embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "692c6606-8ccd-4def-8020-6b88f3018e2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Udsb8xyVw9Nl",
    "outputId": "f5f8a656-343d-43b9-9728-78e71a637caa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_chroma.vectorstores.Chroma at 0x16a53fc50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma_db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7951b14-3800-41ed-9210-3dcf4652eb20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "njfZOOVZxj1a"
   },
   "source": [
    "### Semantic Similarity based Retrieval\n",
    "\n",
    "We use simple cosine similarity here and retrieve the top 3 similar documents based on the user input query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9eb910cc-0a91-4b5a-8927-861fe4baa881",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "tV1l6HYdxj1b"
   },
   "outputs": [],
   "source": [
    "similarity_retriever = chroma_db.as_retriever(search_type=\"similarity_score_threshold\",\n",
    "                                              search_kwargs={\"k\": 3, \"score_threshold\": 0.3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "948f4440-49cd-4421-becc-613a22918e86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "nUIJG_bDxj1c"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def display_docs(docs):\n",
    "    for doc in docs:\n",
    "        print('Metadata:', doc.metadata)\n",
    "        print('Content Brief:')\n",
    "        display(Markdown(doc.page_content))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6b60499-e649-43f7-8e72-a224ed317b22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "PIh4xGv2xj1c",
    "outputId": "a88ace2e-782f-40f8-9bd6-994334b0aba5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: {'id': 10, 'title': 'Artificial Intelligence'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': 3, 'title': 'Natural Language Processing (NLP)'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metadata: {'id': 1, 'title': 'Machine Learning'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"what is AI?\"\n",
    "top_docs = similarity_retriever.invoke(query)\n",
    "display_docs(top_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90e3c008-4172-4cdd-b304-74320504252d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "id": "S_PXFMcJxuyO",
    "outputId": "f9548a6a-9203-4440-fb39-eb07ef0ba8b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: {'id': 5, 'title': 'Photosynthesis'}\n",
      "Content Brief:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Photosynthesis is the process plants use to convert sunlight into energy. This process produces glucose and releases oxygen as a byproduct. It is crucial for sustaining life on Earth by providing food and oxygen."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"how do plants survive?\"\n",
    "top_docs = similarity_retriever.invoke(query)\n",
    "display_docs(top_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db3f89d8-3ea4-4e13-9339-3c3eb83d31e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "gQFWv7YUyVII"
   },
   "source": [
    "## Build the RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8d980c63-1304-45e0-bf89-4cc7e84ce2f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "PHOrfGXKyVIJ"
   },
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "rag_prompt = \"\"\"You are an assistant who is an expert in question-answering tasks.\n",
    "                Answer the following question using only the following pieces of retrieved context.\n",
    "                If the answer is not in the context, do not make up answers, just say that you don't know.\n",
    "                Keep the answer to the point based on the information from the context.\n",
    "\n",
    "                Question:\n",
    "                {question}\n",
    "\n",
    "                Context:\n",
    "                {context}\n",
    "\n",
    "                Answer:\n",
    "            \"\"\"\n",
    "\n",
    "rag_prompt_template = ChatPromptTemplate.from_template(rag_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30bde1dd-ba6d-4518-9b20-0eb0acae2e34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "KmWeCB4yyVIJ"
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "src_rag_response_chain = (\n",
    "    {\n",
    "        \"context\": (itemgetter('context')\n",
    "                        |\n",
    "                    RunnableLambda(format_docs)),\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    }\n",
    "        |\n",
    "    rag_prompt_template\n",
    "        |\n",
    "    chatgpt\n",
    "        |\n",
    "    StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_w_sources = (\n",
    "    {\n",
    "        \"context\": similarity_retriever,\n",
    "        \"question\": RunnablePassthrough()\n",
    "    }\n",
    "        |\n",
    "    RunnablePassthrough.assign(response=src_rag_response_chain)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1a0818f-f6fb-4436-b197-999e0430f6b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xvj_eGIWyVIJ",
    "outputId": "419e7f20-aa91-4ea4-c693-b671fa5405fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(metadata={'id': 10, 'title': 'Artificial Intelligence'}, page_content=\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\"),\n",
       "  Document(metadata={'id': 3, 'title': 'Natural Language Processing (NLP)'}, page_content='NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.'),\n",
       "  Document(metadata={'id': 1, 'title': 'Machine Learning'}, page_content='Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.')],\n",
       " 'question': 'What is AI?',\n",
       " 'response': 'AI refers to machines mimicking human intelligence, including problem-solving and learning, with applications like virtual assistants, robotics, and autonomous vehicles.'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is AI?\"\n",
    "result = rag_chain_w_sources.invoke(query)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33c53182-1d55-4eba-a4c0-b0760de9bede",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pXtezDlZzadt",
    "outputId": "6b78d343-83a3-4134-b878-8bbe318be2d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(metadata={'id': 5, 'title': 'Photosynthesis'}, page_content='Photosynthesis is the process plants use to convert sunlight into energy. This process produces glucose and releases oxygen as a byproduct. It is crucial for sustaining life on Earth by providing food and oxygen.')],\n",
       " 'question': 'How do plants survive?',\n",
       " 'response': 'Plants survive by using photosynthesis to convert sunlight into energy, producing glucose and releasing oxygen as a byproduct.'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How do plants survive?\"\n",
    "result = rag_chain_w_sources.invoke(query)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3b9853bf-9f2f-4b56-a30f-3378bc50e1cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "NXxRQxSQiM_E"
   },
   "source": [
    "# Create End-to-End RAG Evaluation Workflow\n",
    "\n",
    "![](https://i.imgur.com/GUIkpjy.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ad46ddc-6dea-4f12-b78c-b5eca401d20c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Q-Gdpk1Fu1aC"
   },
   "source": [
    "## Create a Synthetic RAG Golden Reference Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68eda467-e0aa-463c-be71-b03b043a742c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 409,
     "status": "ok",
     "timestamp": 1734095590045,
     "user": {
      "displayName": "Dipanjan ‚ÄúDJ‚Äù Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "XrLB2r0CpNnm",
    "outputId": "e40c3d2b-89f9-4182-9872-b27ede79ca12"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.',\n",
       " 'Deep learning is a subset of machine learning utilizing neural networks with many layers. It excels in complex tasks like image and speech recognition. Convolutional and recurrent neural networks are among the common architectures used.',\n",
       " 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_contexts = [doc.page_content for doc in processed_docs]\n",
    "doc_contexts[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2be6267-1a9f-4ec4-8109-a664c92e2a6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2545,
     "status": "ok",
     "timestamp": 1734095596780,
     "user": {
      "displayName": "Dipanjan ‚ÄúDJ‚Äù Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "Y2NT6Uw2y_Sx",
    "outputId": "1561f551-3125-431b-b4c1-a61d7e22f22a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sourav.banerjee/Documents/My Codebases/GenerativAI_Demystified/venv/lib/python3.11/site-packages/deepeval/__init__.py:49: UserWarning: You are using deepeval version 1.4.7, however version 3.2.6 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from deepeval.synthesizer import Synthesizer\n",
    "from deepeval.synthesizer import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c69a4e01-4919-418d-a53b-e7fb847b790a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "t0w1TixH4zAH",
    "outputId": "781c5c9b-1eae-4f51-8332-9eaf7a7a7c93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "‚ú® Generating up to 10 goldens using DeepEval (using gpt-4o, use case=QA, method=default): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:13<00:00,  1.36s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Generation finished üéâ! You can also run <span style=\"color: #008000; text-decoration-color: #008000\">'deepeval login'</span> to generate and save goldens directly on Confident AI.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Generation finished üéâ! You can also run \u001b[32m'deepeval login'\u001b[0m to generate and save goldens directly on Confident AI.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "synthesizer = Synthesizer(model='gpt-4o',\n",
    "                          embedder=OpenAIEmbeddings())\n",
    "\n",
    "eval_data = synthesizer.generate_goldens(\n",
    "    # Provide a list of context for synthetic data generation\n",
    "    contexts=[[doc] for doc in doc_contexts],\n",
    "    include_expected_output=True,\n",
    "    max_goldens_per_context=1,\n",
    "    num_evolutions=1,\n",
    "    scenario=\"Retrieval Augmented Generation\",\n",
    "    task=\"Question Answering\",\n",
    "    evolutions={\n",
    "        types.Evolution.REASONING: 0.1,     # Evolves the input to require multi-step logical thinking.\n",
    "        types.Evolution.MULTICONTEXT: 0.9,  # Ensures that all relevant information from the context is utilized.\n",
    "        types.Evolution.CONCRETIZING: 0.0,  # Makes abstract ideas more concrete and detailed.\n",
    "        types.Evolution.CONSTRAINED: 0.0,   # Introduces a condition or restriction, testing the model's ability to operate within specific limits.\n",
    "        types.Evolution.COMPARATIVE: 0.0,   # Requires a response that involves a comparison between options or contexts.\n",
    "        types.Evolution.HYPOTHETICAL: 0.0,  # Forces the model to consider and respond to a hypothetical scenario.\n",
    "        types.Evolution.IN_BREADTH: 0.0,    # Broadens the input to touch on related or adjacent topics.\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0d6ff07d-98c9-442b-9f03-a771b1014725",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bqh6c5CT69XM",
    "outputId": "bab3e553-189c-4001-cfab-86ff1db6bc32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input='In what ways do solar and wind energy investments contribute to reducing emissions and supporting climate change mitigation?' actual_output=None expected_output='Solar and wind energy investments contribute to reducing emissions by providing sustainable alternatives to fossil fuels, which decrease greenhouse gas emissions. By harnessing naturally replenished resources, these investments support climate change mitigation efforts and are actively promoted by governments to combat environmental impacts.' context=['Renewable energy sources, such as solar and wind, provide sustainable alternatives to fossil fuels. These resources are replenished naturally and reduce greenhouse gas emissions. Governments are investing in renewables to combat climate change.'] retrieval_context=None additional_metadata={'evolutions': ['Multi-context'], 'synthetic_input_quality': 1.0, 'context_quality': None} comments=None tools_called=None expected_tools=None source_file=None\n"
     ]
    }
   ],
   "source": [
    "print(eval_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(eval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: In what ways do solar and wind energy investments contribute to reducing emissions and supporting climate change mitigation?\n",
      "actual_output: None\n",
      "expected_output: Solar and wind energy investments contribute to reducing emissions by providing sustainable alternatives to fossil fuels, which decrease greenhouse gas emissions. By harnessing naturally replenished resources, these investments support climate change mitigation efforts and are actively promoted by governments to combat environmental impacts.\n",
      "context: ['Renewable energy sources, such as solar and wind, provide sustainable alternatives to fossil fuels. These resources are replenished naturally and reduce greenhouse gas emissions. Governments are investing in renewables to combat climate change.']\n",
      "retrieval_context: None\n",
      "additional_metadata: {'evolutions': ['Multi-context'], 'synthetic_input_quality': 1.0, 'context_quality': None}\n",
      "comments: None\n",
      "tools_called: None\n",
      "expected_tools: None\n",
      "source_file: None\n"
     ]
    }
   ],
   "source": [
    "for elem in eval_data[0]:\n",
    "    print(f\"{elem[0]}: {elem[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b87aa574-42e5-4a8f-809e-1213012b6bc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "-BOZXwFDiXKH"
   },
   "source": [
    "## Save the Synthetic RAG Golden Reference Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c330b02f-bd52-4975-bb80-4be7398f75b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "rVns4_28KO-z"
   },
   "outputs": [],
   "source": [
    "import dill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "09f45b14-601b-4b05-b904-d2f443dbda93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "YvDzxHxYKCjm"
   },
   "outputs": [],
   "source": [
    "with open('golden_ref_data.bin', 'wb') as f:\n",
    "    dill.dump(eval_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "824e9ff0-b623-4f19-bc46-8fe4772e7c10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "fl-g5-Q8ibIj"
   },
   "source": [
    "## Create RAG Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4fa54c8-d41b-42ad-82c9-31220c28706c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "y_oRbB8m1MI6"
   },
   "outputs": [],
   "source": [
    "from deepeval.dataset import EvaluationDataset\n",
    "\n",
    "eval_dataset = EvaluationDataset()\n",
    "\n",
    "# load golden dataset\n",
    "with open('golden_ref_data.bin', 'rb') as f:\n",
    "    golden_docs = dill.load(f)\n",
    "\n",
    "eval_dataset.goldens = golden_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deepeval.dataset.dataset.EvaluationDataset"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: In what ways do solar and wind energy investments contribute to reducing emissions and supporting climate change mitigation?\n",
      "actual_output: None\n",
      "expected_output: Solar and wind energy investments contribute to reducing emissions by providing sustainable alternatives to fossil fuels, which decrease greenhouse gas emissions. By harnessing naturally replenished resources, these investments support climate change mitigation efforts and are actively promoted by governments to combat environmental impacts.\n",
      "context: ['Renewable energy sources, such as solar and wind, provide sustainable alternatives to fossil fuels. These resources are replenished naturally and reduce greenhouse gas emissions. Governments are investing in renewables to combat climate change.']\n",
      "retrieval_context: None\n",
      "additional_metadata: {'evolutions': ['Multi-context'], 'synthetic_input_quality': 1.0, 'context_quality': None}\n",
      "comments: None\n",
      "tools_called: None\n",
      "expected_tools: None\n",
      "source_file: None\n"
     ]
    }
   ],
   "source": [
    "for elem in eval_dataset.goldens[0]:\n",
    "    print(f\"{elem[0]}: {elem[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88730c11-1213-4964-af1a-6b752fe9e24f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "QEP5l8DMWzwb",
    "outputId": "d6b63cdb-7480-4ab4-cb14-4c2e7b057992"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In what ways do solar and wind energy investments contribute to reducing emissions and supporting climate change mitigation?'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset.goldens[0].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c40593a3-a7ea-4f33-9f04-21f8b2f1f041",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WnHzga5EWsL_",
    "outputId": "206eadd4-5d76-4f61-9958-6fe7351cca29"
   },
   "outputs": [],
   "source": [
    "response_obj = rag_chain_w_sources.invoke(eval_dataset.goldens[0].input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(metadata={'id': 9, 'title': 'Renewable Energy'}, page_content='Renewable energy sources, such as solar and wind, provide sustainable alternatives to fossil fuels. These resources are replenished naturally and reduce greenhouse gas emissions. Governments are investing in renewables to combat climate change.')],\n",
       " 'question': 'In what ways do solar and wind energy investments contribute to reducing emissions and supporting climate change mitigation?',\n",
       " 'response': 'Solar and wind energy investments contribute to reducing emissions by providing sustainable alternatives to fossil fuels, which helps to lower greenhouse gas emissions.'}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Renewable energy sources, such as solar and wind, provide sustainable alternatives to fossil fuels. These resources are replenished naturally and reduce greenhouse gas emissions. Governments are investing in renewables to combat climate change.']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[doc.page_content for doc in response_obj['context']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7d365961-2032-43bb-a197-33ad9905cb69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "gmQkLxAt3_pe"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.dataset import Golden\n",
    "from tqdm import tqdm\n",
    "\n",
    "def convert_goldens_to_test_cases(goldens: List[Golden]) -> List[LLMTestCase]:\n",
    "    test_cases = []\n",
    "    for golden in tqdm(goldens):\n",
    "        response_obj = rag_chain_w_sources.invoke(golden.input)\n",
    "        test_case = LLMTestCase(\n",
    "            input=golden.input,\n",
    "            actual_output=response_obj['response'],\n",
    "            expected_output=golden.expected_output,\n",
    "            context=golden.context,\n",
    "            retrieval_context=[doc.page_content for doc in response_obj['context']]\n",
    "        )\n",
    "        test_cases.append(test_case)\n",
    "    return test_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cd7fa154-0587-4d00-b924-150f3010c108",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LUT7IrIbZgtp",
    "outputId": "746b4d65-6a9e-4e5e-c8da-036c5d7de5a9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:18<00:00,  1.82s/it]\n"
     ]
    }
   ],
   "source": [
    "eval_dataset.test_cases = convert_goldens_to_test_cases(eval_dataset.goldens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5c36d8ee-ef14-49f5-a794-b764bcd1c349",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8AGc_Rnpcjj0",
    "outputId": "e02abf0f-cc49-4d03-de71-ea4a5d4e3d66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLMTestCase(input='In what ways do solar and wind energy investments contribute to reducing emissions and supporting climate change mitigation?', actual_output='Solar and wind energy investments contribute to reducing emissions by providing sustainable alternatives to fossil fuels, which helps to lower greenhouse gas emissions.', expected_output='Solar and wind energy investments contribute to reducing emissions by providing sustainable alternatives to fossil fuels, which decrease greenhouse gas emissions. By harnessing naturally replenished resources, these investments support climate change mitigation efforts and are actively promoted by governments to combat environmental impacts.', context=['Renewable energy sources, such as solar and wind, provide sustainable alternatives to fossil fuels. These resources are replenished naturally and reduce greenhouse gas emissions. Governments are investing in renewables to combat climate change.'], retrieval_context=['Renewable energy sources, such as solar and wind, provide sustainable alternatives to fossil fuels. These resources are replenished naturally and reduce greenhouse gas emissions. Governments are investing in renewables to combat climate change.'], additional_metadata=None, comments=None, tools_called=None, expected_tools=None, reasoning=None, name=None)\n"
     ]
    }
   ],
   "source": [
    "print(eval_dataset.test_cases[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: In what ways do solar and wind energy investments contribute to reducing emissions and supporting climate change mitigation?\n",
      "Actual Output: Solar and wind energy investments contribute to reducing emissions by providing sustainable alternatives to fossil fuels, which helps to lower greenhouse gas emissions.\n",
      "Expected Output: Solar and wind energy investments contribute to reducing emissions by providing sustainable alternatives to fossil fuels, which decrease greenhouse gas emissions. By harnessing naturally replenished resources, these investments support climate change mitigation efforts and are actively promoted by governments to combat environmental impacts.\n",
      "Context: ['Renewable energy sources, such as solar and wind, provide sustainable alternatives to fossil fuels. These resources are replenished naturally and reduce greenhouse gas emissions. Governments are investing in renewables to combat climate change.']\n",
      "Retrieval Context: ['Renewable energy sources, such as solar and wind, provide sustainable alternatives to fossil fuels. These resources are replenished naturally and reduce greenhouse gas emissions. Governments are investing in renewables to combat climate change.']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input: In what ways do AI applications like virtual assistants and robotics simulate human intelligence in everyday scenarios?\n",
      "Actual Output: AI applications like virtual assistants and robotics simulate human intelligence by mimicking problem-solving and learning capabilities. They utilize techniques from natural language processing (NLP) to understand and generate human language, and machine learning to analyze data and make predictions.\n",
      "Expected Output: AI applications like virtual assistants and robotics simulate human intelligence by performing tasks such as understanding and responding to spoken language, learning user preferences, recognizing objects, and making decisions. Virtual assistants can manage schedules, answer questions, and control smart home devices, while robotics can perform complex tasks like navigating environments and assembling products. These applications utilize machine learning and deep learning to improve their capabilities over time.\n",
      "Context: [\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\"]\n",
      "Retrieval Context: [\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\", 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.', 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input: How do multi-layered neural networks contribute to improvements in complex tasks like image and speech recognition?\n",
      "Actual Output: Multi-layered neural networks contribute to improvements in complex tasks like image and speech recognition by utilizing deep learning, which excels in these areas through architectures such as convolutional and recurrent neural networks.\n",
      "Expected Output: Multi-layered neural networks, such as convolutional and recurrent neural networks, enhance complex tasks like image and speech recognition by leveraging multiple layers to learn hierarchical representations of data. This allows the networks to automatically extract and process intricate features, improving accuracy and performance in these tasks.\n",
      "Context: ['Deep learning is a subset of machine learning utilizing neural networks with many layers. It excels in complex tasks like image and speech recognition. Convolutional and recurrent neural networks are among the common architectures used.']\n",
      "Retrieval Context: ['Deep learning is a subset of machine learning utilizing neural networks with many layers. It excels in complex tasks like image and speech recognition. Convolutional and recurrent neural networks are among the common architectures used.', 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input: What role do cryptographic methods and decentralization play in ensuring secure peer-to-peer transfers in Bitcoin?\n",
      "Actual Output: Cryptographic methods ensure secure transactions in Bitcoin, while its decentralized nature allows peer-to-peer transfers without traditional banks.\n",
      "Expected Output: Cryptographic methods in Bitcoin ensure secure peer-to-peer transfers by encrypting transaction data, safeguarding it against tampering and fraud. Decentralization eliminates the need for traditional banks, as transactions are verified by a network of nodes, reducing reliance on a central authority and enhancing security through distributed consensus.\n",
      "Context: ['Cryptocurrency is a digital currency that uses cryptography for secure transactions. Bitcoin, the first cryptocurrency, was launched in 2009. Its decentralized nature allows peer-to-peer transfers without traditional banks.']\n",
      "Retrieval Context: ['Cryptocurrency is a digital currency that uses cryptography for secure transactions. Bitcoin, the first cryptocurrency, was launched in 2009. Its decentralized nature allows peer-to-peer transfers without traditional banks.']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input: How have advancements in cellular and DNA research influenced our current understanding of biology?\n",
      "Actual Output: Advancements in cellular and DNA research have contributed to modern biology by enhancing our understanding of how organisms function and interact with each other and their environment.\n",
      "Expected Output: Advancements in cellular and DNA research have significantly deepened our understanding of biology by revealing the fundamental mechanisms of life. They have elucidated how genetic information is stored, expressed, and passed on, thereby explaining how organisms function and evolve. These advancements have also enhanced our knowledge of ecological interactions and physiological processes, offering insights into the complexity and interconnectedness of life.\n",
      "Context: ['Biology is the study of living organisms, covering areas such as genetics, ecology, and physiology. It aims to understand how organisms function and interact with each other and their environment. Modern biology has advanced through the study of cells and DNA.']\n",
      "Retrieval Context: ['Biology is the study of living organisms, covering areas such as genetics, ecology, and physiology. It aims to understand how organisms function and interact with each other and their environment. Modern biology has advanced through the study of cells and DNA.']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input: How do plants convert sunlight into energy and produce glucose and oxygen in the process?\n",
      "Actual Output: Plants convert sunlight into energy through the process of photosynthesis, which produces glucose and releases oxygen as a byproduct.\n",
      "Expected Output: Plants convert sunlight into energy through photosynthesis. During this process, they use sunlight to convert carbon dioxide and water into glucose, which serves as energy, and oxygen is released as a byproduct. This process is essential for providing food and oxygen, sustaining life on Earth.\n",
      "Context: ['Photosynthesis is the process plants use to convert sunlight into energy. This process produces glucose and releases oxygen as a byproduct. It is crucial for sustaining life on Earth by providing food and oxygen.']\n",
      "Retrieval Context: ['Photosynthesis is the process plants use to convert sunlight into energy. This process produces glucose and releases oxygen as a byproduct. It is crucial for sustaining life on Earth by providing food and oxygen.']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input: In what ways do the construction techniques and the function of the pyramids as pharaohs' tombs contribute to their status as ancient wonders?\n",
      "Actual Output: The context does not provide specific details on how the construction techniques and the function of the pyramids as pharaohs' tombs contribute to their status as ancient wonders. Therefore, I don't know.\n",
      "Expected Output: The construction techniques of the pyramids, particularly the Great Pyramid of Giza, contribute to their status as ancient wonders due to the remarkable engineering skills and labor required to build such massive structures with precision, using limited technology. Additionally, their function as tombs for pharaohs highlights the cultural and religious significance of these monuments in ancient Egyptian society, further elevating their historical and architectural importance.\n",
      "Context: ['Pyramids are ancient structures, often serving as tombs for pharaohs in Egypt. The Great Pyramid of Giza is one of the Seven Wonders of the Ancient World. Their construction remains a subject of fascination and speculation.']\n",
      "Retrieval Context: ['Pyramids are ancient structures, often serving as tombs for pharaohs in Egypt. The Great Pyramid of Giza is one of the Seven Wonders of the Ancient World. Their construction remains a subject of fascination and speculation.']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input: In what ways do wave-particle duality and uncertainty principle challenge the principles of classical physics within the framework of quantum mechanics?\n",
      "Actual Output: Wave-particle duality and the uncertainty principle challenge classical physics by introducing concepts that do not align with classical notions of particles having definite positions and velocities. In quantum mechanics, particles exhibit both wave-like and particle-like properties, and the uncertainty principle states that certain pairs of properties, like position and momentum, cannot be simultaneously known with arbitrary precision.\n",
      "Expected Output: Wave-particle duality challenges classical physics by demonstrating that particles like electrons exhibit both wave-like and particle-like properties, contradicting the classical view of particles having a definite state. The uncertainty principle, introduced by Heisenberg, further challenges classical physics by stating that certain pairs of properties, such as position and momentum, cannot be simultaneously known with arbitrary precision. These concepts defy the deterministic nature of classical physics, where particles are expected to have definite positions and velocities.\n",
      "Context: ['Quantum mechanics is a branch of physics that studies the behavior of particles at atomic and subatomic levels. It challenges classical physics with concepts like wave-particle duality and uncertainty. Key figures include Einstein, Schr√∂dinger, and Heisenberg.']\n",
      "Retrieval Context: ['Quantum mechanics is a branch of physics that studies the behavior of particles at atomic and subatomic levels. It challenges classical physics with concepts like wave-particle duality and uncertainty. Key figures include Einstein, Schr√∂dinger, and Heisenberg.']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input: How does NLP enhance language understanding and improve applications such as chatbots and translation in AI?\n",
      "Actual Output: NLP enhances language understanding by enabling computers to understand, interpret, and generate human language through techniques like tokenization, stemming, and sentiment analysis. This improvement benefits applications such as chatbots and language translation services.\n",
      "Expected Output: NLP enhances language understanding by using techniques like tokenization and stemming to break down and interpret text. It improves applications such as chatbots by enabling more natural and meaningful interactions, and in translation services by allowing accurate language conversion.\n",
      "Context: ['NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.']\n",
      "Retrieval Context: ['NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.', \"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\", 'Deep learning is a subset of machine learning utilizing neural networks with many layers. It excels in complex tasks like image and speech recognition. Convolutional and recurrent neural networks are among the common architectures used.']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input: In what ways do AI systems utilize data analysis to classify information and predict trends?\n",
      "Actual Output: AI systems utilize data analysis by employing algorithms to analyze past data, which allows them to identify patterns for making predictions or classifying information.\n",
      "Expected Output: AI systems utilize data analysis by employing algorithms that learn patterns from historical data. These algorithms can classify information by identifying features and relationships within the data. Additionally, they predict trends by analyzing past behaviors and outcomes to forecast future events, commonly seen in recommendation systems and image recognition.\n",
      "Context: ['Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.']\n",
      "Retrieval Context: ['Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.', \"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\", 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.']\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for elem in eval_dataset.test_cases:\n",
    "    print(f\"Input: {elem.input}\")\n",
    "    print(f\"Actual Output: {elem.actual_output}\")\n",
    "    print(f\"Expected Output: {elem.expected_output}\")\n",
    "    print(f\"Context: {elem.context}\")\n",
    "    print(f\"Retrieval Context: {elem.retrieval_context}\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0878f3ac-e13d-4cd5-84d7-cd7ba709b3ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "_w8B75MKihxs"
   },
   "source": [
    "## Run and View RAG Evaluations on the Evaluation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef1475b4-1724-4d5c-9f08-abc9a8d3262e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "78edb9b2b80c483ab1d65a5e6ac7b00c",
      "0566c23e5037436e97b5178282b12628",
      "a6768074f3ea4cb4b6bf34fd3ec588d2",
      "4d02d332124e489194212dd05a80af68",
      "a73d64e7f0d64d3ab8e7c626193f44f9",
      "4ab47828042947ceb874f360a728d2e9",
      "88ec20625df54005a0e6623af57f0b9d",
      "a336914f145e42c0a1df04bfb0aa0f61",
      "0d8b6013a8734c3cb2848eee9e7597ff",
      "4d7f50e073df423b9e10770933466576",
      "b64d491c187c4506942bd5ecb013d313",
      "9be2346fdf034f3fae44bae5649ea544",
      "945dfa6461a14d0a99a207a600be9f99",
      "58a73767e7e34033b80fc8ff6dccd644",
      "3483a09e68ad423d8285c88b0023c0da",
      "9bf97bf583fd4b6f9b8dbe7667d56863",
      "f7d70159f003466996088b318a7ed06d",
      "f01d72a1d5514dc1a6c35f95cdb04c78",
      "4113a8c3d98d4ac6a55cb7d887fa530c",
      "89bfda1f10344e03a5f132feea2c9bfb",
      "8b64ddd749fe4d14bc15b0bf89c698ed",
      "af2ae9a883e64c6bbed599f54b6c6915",
      "153226563d454cbd92ed327d61cbcf68",
      "59275c721a1849e58c3efc0c339f8954",
      "5ca4e01efe6d44eea9d60e5b9c9080c2",
      "3aee75144e004e8dbcfe75abc6762208",
      "ba7fd441525a45efb8d4bce5a7362a03",
      "3c147e908b1b49fbb52d6820495afab7",
      "9fddccfcf6a843e69bf3b1e631aca9e1",
      "eeae6addc36447bd9c82d2b4b4fa99bb",
      "69f10456c157455d8a7ec9fd9cdf28f6",
      "2b53bc9dbfe84a83beec08350f953df4",
      "19d664186c594a5a81be22093ea94717",
      "613a3541acae40d38eb8898a78acb445",
      "0b3242c9b3ef4964aa9578af5775a396",
      "5ca5882b64ac4dafb27da9189802d36c",
      "e53c7c33e8d244c3ab1f3a29318e0bcf",
      "072bdd9321e644cc8f25c2749339e083",
      "2c9ed88787be4036a623d4a7088c40b8",
      "2b4046d510a34e38bdd095ca905abc9b",
      "88bcb61cb34e4cdaae01127aaa76fb07",
      "fae02453a4164ba39f26445cc1a01a72",
      "7f3fa03415044d79b0db289024d882de",
      "4fcb9e84ee2e4e909f34f4a8fa403ca2",
      "ff0b25a6b0364081907ec87b853ea6a4",
      "024d803bdab24516b6770b101969b8e1",
      "1e14a7aa053449f29d94620f654b8fdd",
      "67554dce2ed147daa1e1f6887b706256",
      "9eeb2fb2fa444982acf1e9b95e95703e",
      "c9dd4eebc151451085de50702f21a311",
      "6caddec7dc934425bf56010398936537",
      "90441504bc7b44898eabe5b78fb6a5ec",
      "e7e2ef49e4b44aec89fa39ed9799cf59",
      "9fee5fde75c34cd6999b57d4374dd9c7",
      "28fd1350a29149148a0083ff151ee2b1",
      "af5f81ba63744f48969b6230f0e1196d",
      "d76b5cc2bf724998afecba83dd9917c2",
      "bf94afe4446b49b78c325ed123805c29",
      "92df8d04435244659d3a4b4773d619e2",
      "db9c163fe2674abf94bf676d6ca94f0e",
      "968da5427c57445fa41933ad7aec061a",
      "183cf676e13d470c9c0db082b89256ff",
      "db86b4cba7b4402fa8563922ca6e9908",
      "14f35227c96342dba5aa8b0db9cdabf0",
      "4d46735abc034aa3817f3ef7bd70a0e6",
      "fae240f399c44cbd9bb14e2d0ce24013",
      "915a91064f44458eac9dee659df36362",
      "7a4b4375488a447b9f483798173b5560",
      "654a300e0e624582aad9ce36720cc8d3",
      "d3d5b7ec3dd64df69f6b17dd3fb1188e",
      "c9e569343f6a4cb1b100356cfd56c617",
      "48b6fa2757de4c9aa48c429234552b7a",
      "89c18cb46f564cb8b4d390cdb75e27a1",
      "ba82e24b119d4eb086248ba70f6adcba",
      "20174965e93c4d9e96a8b2567cda17cf",
      "0c7afd75619d43c4b2debae90e9adc2d",
      "bf93a40cc97f439b82bc2e51478e56d1",
      "55c66431dcad49088e1c81e2f1a59d68",
      "6b789175b58a413d8b4eeb4200854d7f",
      "66872cc0ee164caca99347f90386044b",
      "6d9cd0ea46f34a9faed020f53ada73ab",
      "6a52685481b54fcc9521f61e5d50119f",
      "60422854823d4a1cb19377f25a12ec51",
      "a3dca1dc3d3045e79587e5593e0ea74f",
      "6fb30db42d5b49418fdf8de0fad705a9",
      "a35b24a41e5748b8930fa70d6e795504",
      "ce21520c9bac4044a25157662b091a11",
      "66e0a0826a434c8db7f356c1a5aa8575",
      "02165f6fcfb74fafb5206b582f628a93",
      "3687d4444143421eae1d8c8231bf952d",
      "51a81caf430147789513fc3485416b33",
      "903e7d454cdc48979146cc88183042d7",
      "c2f096e13f164acab1a66d96659249bd",
      "a3c0b9000c3b4789b7a157459d4bd9c1",
      "c8a18774fec54c0cb290edf5ffeb7c1a",
      "079bf0f9293c43d988315ee189ff7c73",
      "3772f26e95a3478894125d474a1bd5e3",
      "42a91d50bb494be785a10dc07e64c57d",
      "091f150610b0474c8b4227706e6c3878",
      "4380c3157b2641949101c333de2860c4",
      "00ef1659ddf440ac829bc99c0dcb1baf",
      "d8b78b5823ad4efd9be2be03346d3009",
      "9c6494c628cd4f33a41869f5044e1567",
      "77814ee8e544404fa75ab09334721d43",
      "1b3a2dc7dbf94a068ac59a1c71b393f6",
      "ae849ff42adb4cfc9a82c45a28da07a8",
      "bb9a2dedfed946069909eac89cd5fb0e",
      "d9a4a518fd8642598f5f51bb5d3c3091",
      "4deb2d112aa4427488bc32582289caa0",
      "ed63af1291e140b68eb813f6525f4f88"
     ]
    },
    "id": "7M6isbZqcgny",
    "outputId": "9a8008ce-b84f-4a19-9952-7f2dd049f873"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Precision Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Precision Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Recall Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Recall Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Contextual Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mContextual Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Answer Relevancy </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">(</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">ragas</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">)</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span>\n",
       "<span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mAnswer Relevancy \u001b[0m\u001b[1;38;2;106;0;255m(\u001b[0m\u001b[38;2;106;0;255mragas\u001b[0m\u001b[1;38;2;106;0;255m)\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\n",
       "\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Faithfulness Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mFaithfulness Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Hallucination Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mHallucination Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event loop is already running. Applying nest_asyncio patch to allow async execution...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating 10 test case(s) in parallel: |          |  0% (0/10) [Time Taken: 00:00, ?test case/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61175bdcc13b44e3a7a078319554430b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd9988a532a450b91afb24a498940b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e08348ed4e845e89aa2909b21f19e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec042baa86b4551920d445004ab8fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8beb063efc042c5849256842952d188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f6d257647e1440ba2a455a12e0604a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63cf206849b54246b8780fce5ce3f8c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d76de3b69d43fb96dd082e8dab0c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5499bcc3fe3c4728b0d72ee0a685266a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9736610a923244de9dc2261d64b108e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 3 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 4 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 5 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 6 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 7 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 7 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 7 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 7 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 7 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 7 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 7 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 7 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 7 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 7 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 7 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 7 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 7 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 7 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 7 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 7 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 7 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 7 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 7 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 7 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 7 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 7 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 7 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 7 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 7 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 7 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 7 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 2 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 8 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 8 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 8 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 8 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 8 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 8 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 8 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 8 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 8 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 8 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 8 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 8 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 8 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 8 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 1 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 9 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 9 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 9 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 9 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 9 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 9 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 9 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 9 time(s)...\n",
      "ERROR:root:OpenAI rate limit exceeded. Retrying: 9 time(s)...\n",
      "Evaluating 10 test case(s) in parallel: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|100% (10/10) [Time Taken: 02:04, 12.42s/test case]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the first node in the retrieval context directly addresses the ways AI systems utilize data analysis by explaining how algorithms analyze past data to make predictions or classify information. The irrelevant nodes, ranked second and third, discuss AI in general terms and applications like virtual assistants and robotics or focus on NLP techniques, which do not directly relate to the input question. Great job on getting it spot on!, error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because every sentence in the expected output is perfectly aligned with information from the nodes in the retrieval context. Great job!, error: None)\n",
      "  - ‚ùå Contextual Relevancy (score: 0.3333333333333333, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 0.33 because while the statements mention that 'algorithms analyze past data to make predictions or classify information,' most of the context is focused on NLP and general AI applications, which do not directly address the specific ways AI uses data analysis for classification and trend prediction., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the response is perfectly relevant, directly addressing how AI systems use data analysis to classify information and predict trends without any irrelevant statements. Great job!, error: None)\n",
      "  - ‚úÖ Answer Relevancy (ragas) (score: 0.9622997599013171, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: None, error: None)\n",
      "  - ‚úÖ Faithfulness (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because there are no contradictions, indicating a perfect alignment between the actual output and the retrieval context. Great job!, error: None)\n",
      "  - ‚úÖ Hallucination (score: 0.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 0.00 because the actual output is fully aligned with the provided context, with no contradictions noted., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: In what ways do AI systems utilize data analysis to classify information and predict trends?\n",
      "  - actual output: AI systems utilize data analysis by employing algorithms to analyze past data, which allows them to identify patterns for making predictions or classifying information.\n",
      "  - expected output: AI systems utilize data analysis by employing algorithms that learn patterns from historical data. These algorithms can classify information by identifying features and relationships within the data. Additionally, they predict trends by analyzing past behaviors and outcomes to forecast future events, commonly seen in recommendation systems and image recognition.\n",
      "  - context: ['Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.']\n",
      "  - retrieval context: ['Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.', \"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\", 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the relevant node in the retrieval context is ranked first, providing a comprehensive explanation of how NLP enhances language understanding and improves applications such as chatbots and translation. Way to go!, error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because every sentence in the expected output is perfectly matched with the information from the nodes in the retrieval context. Great job!, error: None)\n",
      "  - ‚ùå Contextual Relevancy (score: 0.3333333333333333, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 0.33 because while relevant statements like 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language' and 'Applications range from chatbots to language translation services' are present, the majority of the context does not specifically address how NLP enhances language understanding or improves applications like chatbots and translation., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the response is perfectly relevant and directly addresses how NLP enhances language understanding and improves applications like chatbots and translation without any irrelevant statements. Great job!, error: None)\n",
      "  - ‚úÖ Answer Relevancy (ragas) (score: 0.9608503324052095, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: None, error: None)\n",
      "  - ‚úÖ Faithfulness (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because there are no contradictions, which means the actual output is perfectly aligned with the retrieval context. Great job!, error: None)\n",
      "  - ‚úÖ Hallucination (score: 0.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 0.00 because there are no contradictions between the actual output and the provided context, indicating full alignment with factual information., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: How does NLP enhance language understanding and improve applications such as chatbots and translation in AI?\n",
      "  - actual output: NLP enhances language understanding by enabling computers to understand, interpret, and generate human language through techniques like tokenization, stemming, and sentiment analysis. This improvement benefits applications such as chatbots and language translation services.\n",
      "  - expected output: NLP enhances language understanding by using techniques like tokenization and stemming to break down and interpret text. It improves applications such as chatbots by enabling more natural and meaningful interactions, and in translation services by allowing accurate language conversion.\n",
      "  - context: ['NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.']\n",
      "  - retrieval context: ['NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.', \"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\", 'Deep learning is a subset of machine learning utilizing neural networks with many layers. It excels in complex tasks like image and speech recognition. Convolutional and recurrent neural networks are among the common architectures used.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the retrieval context perfectly aligns with the input query, discussing how wave-particle duality and uncertainty principle challenge classical physics within quantum mechanics. Great job!, error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because all sentences in the expected output perfectly align with the information from the nodes in the retrieval context, with no discrepancies or missing connections., error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.6666666666666666, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 0.67 because while the retrieval context includes relevant statements such as 'Quantum mechanics is a branch of physics that studies the behavior of particles at atomic and subatomic levels' and 'It challenges classical physics with concepts like wave-particle duality and uncertainty', it also contains irrelevant information like 'Key figures include Einstein, Schr√∂dinger, and Heisenberg' which does not directly address the input question., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the response perfectly addresses the input question without any irrelevant statements. Great job!, error: None)\n",
      "  - ‚úÖ Answer Relevancy (ragas) (score: 0.9801583669448245, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: None, error: None)\n",
      "  - ‚úÖ Faithfulness (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because there are no contradictions, indicating perfect alignment between the actual output and the retrieval context. Great job!, error: None)\n",
      "  - ‚úÖ Hallucination (score: 0.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 0.00 because the actual output fully aligns with the context, with no contradictions present., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: In what ways do wave-particle duality and uncertainty principle challenge the principles of classical physics within the framework of quantum mechanics?\n",
      "  - actual output: Wave-particle duality and the uncertainty principle challenge classical physics by introducing concepts that do not align with classical notions of particles having definite positions and velocities. In quantum mechanics, particles exhibit both wave-like and particle-like properties, and the uncertainty principle states that certain pairs of properties, like position and momentum, cannot be simultaneously known with arbitrary precision.\n",
      "  - expected output: Wave-particle duality challenges classical physics by demonstrating that particles like electrons exhibit both wave-like and particle-like properties, contradicting the classical view of particles having a definite state. The uncertainty principle, introduced by Heisenberg, further challenges classical physics by stating that certain pairs of properties, such as position and momentum, cannot be simultaneously known with arbitrary precision. These concepts defy the deterministic nature of classical physics, where particles are expected to have definite positions and velocities.\n",
      "  - context: ['Quantum mechanics is a branch of physics that studies the behavior of particles at atomic and subatomic levels. It challenges classical physics with concepts like wave-particle duality and uncertainty. Key figures include Einstein, Schr√∂dinger, and Heisenberg.']\n",
      "  - retrieval context: ['Quantum mechanics is a branch of physics that studies the behavior of particles at atomic and subatomic levels. It challenges classical physics with concepts like wave-particle duality and uncertainty. Key figures include Einstein, Schr√∂dinger, and Heisenberg.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because all nodes in the retrieval context are relevant and directly address the input query. The context precisely highlights the pyramids' roles as pharaohs' tombs, their status as ancient wonders, and the fascination with their construction techniques, ensuring a perfect ranking of relevant information., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because all elements of the expected output align perfectly with the nodes in the retrieval context, highlighting both the engineering marvel and cultural significance of the pyramids with no discrepancies. Great job!, error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the input directly relates to the pyramids as pharaohs' tombs, their construction techniques, and their status as ancient wonders, all of which are addressed in the relevant statements provided., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 0.5, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 0.50 because while the response addresses the topic of pyramids, it lacks specific details and analysis about construction techniques and their function as tombs, which are crucial to fully answering the question., error: None)\n",
      "  - ‚ùå Answer Relevancy (ragas) (score: 0.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: None, error: None)\n",
      "  - ‚úÖ Faithfulness (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because there are no contradictions. Great job on ensuring complete alignment!, error: None)\n",
      "  - ‚úÖ Hallucination (score: 0.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 0.00 because the actual output does not contradict the context, and it aligns perfectly with the available information, indicating no hallucination., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: In what ways do the construction techniques and the function of the pyramids as pharaohs' tombs contribute to their status as ancient wonders?\n",
      "  - actual output: The context does not provide specific details on how the construction techniques and the function of the pyramids as pharaohs' tombs contribute to their status as ancient wonders. Therefore, I don't know.\n",
      "  - expected output: The construction techniques of the pyramids, particularly the Great Pyramid of Giza, contribute to their status as ancient wonders due to the remarkable engineering skills and labor required to build such massive structures with precision, using limited technology. Additionally, their function as tombs for pharaohs highlights the cultural and religious significance of these monuments in ancient Egyptian society, further elevating their historical and architectural importance.\n",
      "  - context: ['Pyramids are ancient structures, often serving as tombs for pharaohs in Egypt. The Great Pyramid of Giza is one of the Seven Wonders of the Ancient World. Their construction remains a subject of fascination and speculation.']\n",
      "  - retrieval context: ['Pyramids are ancient structures, often serving as tombs for pharaohs in Egypt. The Great Pyramid of Giza is one of the Seven Wonders of the Ancient World. Their construction remains a subject of fascination and speculation.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the node in the retrieval context perfectly aligns with the input question. 'Modern biology has advanced through the study of cells and DNA,' directly responds to the inquiry about how advancements in cellular and DNA research have influenced biology. Great job on getting it just right!, error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the expected output is perfectly supported by the nodes in the retrieval context, demonstrating a thorough alignment between the provided information and the expected content. Great job maintaining accuracy and relevance!, error: None)\n",
      "  - ‚ùå Contextual Relevancy (score: 0.3333333333333333, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 0.33 because while the statement 'Modern biology has advanced through the study of cells and DNA.' is somewhat relevant to advancements in cellular and DNA research, the other information provided is too general and does not specifically address how these advancements have influenced our understanding of biology., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the output directly addresses how advancements in cellular and DNA research have influenced our understanding of biology, with no irrelevant information., error: None)\n",
      "  - ‚úÖ Answer Relevancy (ragas) (score: 0.9739155183206378, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: None, error: None)\n",
      "  - ‚úÖ Faithfulness (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because there are no contradictions, indicating a perfectly faithful alignment between the actual output and the retrieval context. Great job!, error: None)\n",
      "  - ‚úÖ Hallucination (score: 0.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 0.00 because the actual output fully aligns with the provided context without any contradictions, indicating no hallucination present., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: How have advancements in cellular and DNA research influenced our current understanding of biology?\n",
      "  - actual output: Advancements in cellular and DNA research have contributed to modern biology by enhancing our understanding of how organisms function and interact with each other and their environment.\n",
      "  - expected output: Advancements in cellular and DNA research have significantly deepened our understanding of biology by revealing the fundamental mechanisms of life. They have elucidated how genetic information is stored, expressed, and passed on, thereby explaining how organisms function and evolve. These advancements have also enhanced our knowledge of ecological interactions and physiological processes, offering insights into the complexity and interconnectedness of life.\n",
      "  - context: ['Biology is the study of living organisms, covering areas such as genetics, ecology, and physiology. It aims to understand how organisms function and interact with each other and their environment. Modern biology has advanced through the study of cells and DNA.']\n",
      "  - retrieval context: ['Biology is the study of living organisms, covering areas such as genetics, ecology, and physiology. It aims to understand how organisms function and interact with each other and their environment. Modern biology has advanced through the study of cells and DNA.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the relevant node effectively highlights the key aspects of using cryptography for secure transactions and emphasizes Bitcoin's decentralized nature. Fantastic job on capturing the essence of the input!, error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the expected output perfectly aligns with the information from the nodes in the retrieval context, demonstrating a complete and accurate recall. Great job!, error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the retrieval context perfectly matches the input, highlighting the key roles of cryptography and decentralization in Bitcoin's secure peer-to-peer transfers. Great job!, error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the response perfectly addresses the role of cryptographic methods and decentralization in Bitcoin without any irrelevant statements. Great job!, error: None)\n",
      "  - ‚úÖ Answer Relevancy (ragas) (score: 0.9425592932435508, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: None, error: None)\n",
      "  - ‚úÖ Faithfulness (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because there are no contradictions. Great job on maintaining complete alignment with the retrieval context!, error: None)\n",
      "  - ‚úÖ Hallucination (score: 0.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 0.00 because there are no contradictions between the actual output and the context, and the factual alignments confirm that the output is accurate and consistent with the provided information., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: What role do cryptographic methods and decentralization play in ensuring secure peer-to-peer transfers in Bitcoin?\n",
      "  - actual output: Cryptographic methods ensure secure transactions in Bitcoin, while its decentralized nature allows peer-to-peer transfers without traditional banks.\n",
      "  - expected output: Cryptographic methods in Bitcoin ensure secure peer-to-peer transfers by encrypting transaction data, safeguarding it against tampering and fraud. Decentralization eliminates the need for traditional banks, as transactions are verified by a network of nodes, reducing reliance on a central authority and enhancing security through distributed consensus.\n",
      "  - context: ['Cryptocurrency is a digital currency that uses cryptography for secure transactions. Bitcoin, the first cryptocurrency, was launched in 2009. Its decentralized nature allows peer-to-peer transfers without traditional banks.']\n",
      "  - retrieval context: ['Cryptocurrency is a digital currency that uses cryptography for secure transactions. Bitcoin, the first cryptocurrency, was launched in 2009. Its decentralized nature allows peer-to-peer transfers without traditional banks.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the relevant node in the retrieval context, ranked first, perfectly addresses the input question by discussing how 'Deep learning is a subset of machine learning utilizing neural networks with many layers' and excels in 'complex tasks like image and speech recognition.' Great job ranking the relevant information at the top!, error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because every sentence in the expected output is perfectly aligned with the information from the nodes in the retrieval context, showcasing a comprehensive understanding and representation of the topic. Great job!, error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.5, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 0.50 because while the retrieval context mentions 'deep learning' and its role in 'complex tasks like image and speech recognition', it lacks specific details about how multi-layered neural networks contribute to these improvements, and includes irrelevant information about NLP techniques., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the response perfectly addresses how multi-layered neural networks enhance complex tasks like image and speech recognition, with no irrelevant information included. Keep up the great work!, error: None)\n",
      "  - ‚úÖ Answer Relevancy (ragas) (score: 0.9999999999999996, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: None, error: None)\n",
      "  - ‚úÖ Faithfulness (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because there are no contradictions. Excellent alignment between the actual output and the retrieval context!, error: None)\n",
      "  - ‚úÖ Hallucination (score: 0.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 0.00 because the actual output fully aligns with the provided context, accurately describing the application and architectures of deep learning without any contradictions., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: How do multi-layered neural networks contribute to improvements in complex tasks like image and speech recognition?\n",
      "  - actual output: Multi-layered neural networks contribute to improvements in complex tasks like image and speech recognition by utilizing deep learning, which excels in these areas through architectures such as convolutional and recurrent neural networks.\n",
      "  - expected output: Multi-layered neural networks, such as convolutional and recurrent neural networks, enhance complex tasks like image and speech recognition by leveraging multiple layers to learn hierarchical representations of data. This allows the networks to automatically extract and process intricate features, improving accuracy and performance in these tasks.\n",
      "  - context: ['Deep learning is a subset of machine learning utilizing neural networks with many layers. It excels in complex tasks like image and speech recognition. Convolutional and recurrent neural networks are among the common architectures used.']\n",
      "  - retrieval context: ['Deep learning is a subset of machine learning utilizing neural networks with many layers. It excels in complex tasks like image and speech recognition. Convolutional and recurrent neural networks are among the common architectures used.', 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 0.8333333333333333, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 0.83 because the first node in the retrieval context is relevant as it mentions 'AI includes applications like virtual assistants, robotics...', which directly relates to the input question. The second node is less relevant because it mentions 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language,' and does not specifically address the simulation of human intelligence by virtual assistants and robotics. However, the third node is relevant as it discusses 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data,' which supports how AI applications improve their capabilities., error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the expected output is fully supported by the nodes in the retrieval context, with all relevant information aligning perfectly. Great job!, error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.5555555555555556, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 0.56 because while the relevant statements mention AI applications like virtual assistants and robotics, they do not specifically address how these applications simulate human intelligence in everyday scenarios. The input focuses on simulation of human intelligence, but the context mainly provides general information about AI and its branches like NLP., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the response is perfectly relevant with no irrelevant statements, fully addressing how AI applications like virtual assistants and robotics simulate human intelligence in everyday scenarios. Great job!, error: None)\n",
      "  - ‚úÖ Answer Relevancy (ragas) (score: 0.9803045957508069, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: None, error: None)\n",
      "  - ‚úÖ Faithfulness (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because there are no contradictions, indicating perfect alignment between the actual output and the retrieval context. Keep up the great work!, error: None)\n",
      "  - ‚úÖ Hallucination (score: 0.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 0.00 because the actual output aligns completely with the provided context without any contradictions, indicating no hallucination present., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: In what ways do AI applications like virtual assistants and robotics simulate human intelligence in everyday scenarios?\n",
      "  - actual output: AI applications like virtual assistants and robotics simulate human intelligence by mimicking problem-solving and learning capabilities. They utilize techniques from natural language processing (NLP) to understand and generate human language, and machine learning to analyze data and make predictions.\n",
      "  - expected output: AI applications like virtual assistants and robotics simulate human intelligence by performing tasks such as understanding and responding to spoken language, learning user preferences, recognizing objects, and making decisions. Virtual assistants can manage schedules, answer questions, and control smart home devices, while robotics can perform complex tasks like navigating environments and assembling products. These applications utilize machine learning and deep learning to improve their capabilities over time.\n",
      "  - context: [\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\"]\n",
      "  - retrieval context: [\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\", 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.', 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the node in the retrieval context directly addresses the input question by stating that 'Renewable energy sources, such as solar and wind, provide sustainable alternatives to fossil fuels' and 'reduce greenhouse gas emissions.' It also highlights that 'Governments are investing in renewables to combat climate change,' perfectly aligning with the expected output regarding climate change mitigation. Great job at retrieving the most relevant information!, error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because every sentence in the expected output is perfectly supported by the 1st node in the retrieval context, aligning precisely with the information provided. Great job!, error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the retrieval context perfectly aligns with the input, highlighting how solar and wind energy reduce emissions and support climate change mitigation. Keep up the great work in exploring sustainable alternatives!, error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the response is perfectly relevant, with no irrelevant statements, and directly addresses how solar and wind energy investments contribute to reducing emissions and supporting climate change mitigation. Great job!, error: None)\n",
      "  - ‚úÖ Answer Relevancy (ragas) (score: 0.970122634281378, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: None, error: None)\n",
      "  - ‚úÖ Faithfulness (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because there are no contradictions, indicating perfect alignment between the actual output and the retrieval context. Great job maintaining consistency!, error: None)\n",
      "  - ‚úÖ Hallucination (score: 0.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 0.00 because there are no contradictions between the actual output and the context, indicating complete factual alignment., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: In what ways do solar and wind energy investments contribute to reducing emissions and supporting climate change mitigation?\n",
      "  - actual output: Solar and wind energy investments contribute to reducing emissions by providing sustainable alternatives to fossil fuels, which helps to lower greenhouse gas emissions.\n",
      "  - expected output: Solar and wind energy investments contribute to reducing emissions by providing sustainable alternatives to fossil fuels, which decrease greenhouse gas emissions. By harnessing naturally replenished resources, these investments support climate change mitigation efforts and are actively promoted by governments to combat environmental impacts.\n",
      "  - context: ['Renewable energy sources, such as solar and wind, provide sustainable alternatives to fossil fuels. These resources are replenished naturally and reduce greenhouse gas emissions. Governments are investing in renewables to combat climate change.']\n",
      "  - retrieval context: ['Renewable energy sources, such as solar and wind, provide sustainable alternatives to fossil fuels. These resources are replenished naturally and reduce greenhouse gas emissions. Governments are investing in renewables to combat climate change.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚úÖ Contextual Precision (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the first node in the retrieval context directly and accurately addresses the question about how plants convert sunlight into energy, mentioning both the production of glucose and the release of oxygen. Fantastic job!, error: None)\n",
      "  - ‚úÖ Contextual Recall (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because every sentence in the expected output is perfectly supported by the information in the nodes in retrieval context. Great job!, error: None)\n",
      "  - ‚úÖ Contextual Relevancy (score: 0.5, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 0.50 because while the relevant statement accurately describes photosynthesis as the process where plants convert sunlight into energy, producing glucose and oxygen, the irrelevancy note highlights that the importance of photosynthesis for sustaining life is not directly related to the specific process details asked in the input., error: None)\n",
      "  - ‚úÖ Answer Relevancy (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because the output is perfectly relevant and directly addresses the question about how plants convert sunlight into energy, without any irrelevant information. Great job!, error: None)\n",
      "  - ‚úÖ Answer Relevancy (ragas) (score: 0.948771831411649, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: None, error: None)\n",
      "  - ‚úÖ Faithfulness (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 1.00 because there are no contradictions, indicating perfect alignment between the actual output and the retrieval context. Great job!, error: None)\n",
      "  - ‚úÖ Hallucination (score: 0.0, threshold: 0.5, strict: False, evaluation model: gpt-4o, reason: The score is 0.00 because the actual output aligns perfectly with the provided context without any contradictions., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: How do plants convert sunlight into energy and produce glucose and oxygen in the process?\n",
      "  - actual output: Plants convert sunlight into energy through the process of photosynthesis, which produces glucose and releases oxygen as a byproduct.\n",
      "  - expected output: Plants convert sunlight into energy through photosynthesis. During this process, they use sunlight to convert carbon dioxide and water into glucose, which serves as energy, and oxygen is released as a byproduct. This process is essential for providing food and oxygen, sustaining life on Earth.\n",
      "  - context: ['Photosynthesis is the process plants use to convert sunlight into energy. This process produces glucose and releases oxygen as a byproduct. It is crucial for sustaining life on Earth by providing food and oxygen.']\n",
      "  - retrieval context: ['Photosynthesis is the process plants use to convert sunlight into energy. This process produces glucose and releases oxygen as a byproduct. It is crucial for sustaining life on Earth by providing food and oxygen.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Contextual Precision: 100.00% pass rate\n",
      "Contextual Recall: 100.00% pass rate\n",
      "Contextual Relevancy: 70.00% pass rate\n",
      "Answer Relevancy: 100.00% pass rate\n",
      "Answer Relevancy (ragas): 90.00% pass rate\n",
      "Faithfulness: 100.00% pass rate\n",
      "Hallucination: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Tests finished üéâ! Run <span style=\"color: #008000; text-decoration-color: #008000\">'deepeval login'</span> to save and analyze evaluation results on Confident AI. \n",
       "‚ÄºÔ∏è  Friendly reminder üòá: You can also run evaluations with ALL of deepeval's metrics directly on Confident AI \n",
       "instead.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Tests finished üéâ! Run \u001b[32m'deepeval login'\u001b[0m to save and analyze evaluation results on Confident AI. \n",
       "‚ÄºÔ∏è  Friendly reminder üòá: You can also run evaluations with ALL of deepeval's metrics directly on Confident AI \n",
       "instead.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from deepeval import evaluate\n",
    "from deepeval.metrics import ContextualPrecisionMetric, ContextualRecallMetric, ContextualRelevancyMetric\n",
    "from deepeval.metrics import AnswerRelevancyMetric, FaithfulnessMetric, HallucinationMetric\n",
    "from deepeval.metrics.ragas import RAGASAnswerRelevancyMetric\n",
    "\n",
    "contextual_precision = ContextualPrecisionMetric(threshold=0.5, include_reason=True, model=\"gpt-4o\")\n",
    "contextual_recall = ContextualRecallMetric(threshold=0.5, include_reason=True, model=\"gpt-4o\")\n",
    "contextual_relevancy = ContextualRelevancyMetric(threshold=0.5, include_reason=True, model=\"gpt-4o\")\n",
    "answer_relevancy = AnswerRelevancyMetric(threshold=0.5, include_reason=True, model=\"gpt-4o\")\n",
    "faithfulness = FaithfulnessMetric(threshold=0.5, include_reason=True, model=\"gpt-4o\")\n",
    "hallucination = HallucinationMetric(threshold=0.5, include_reason=True, model=\"gpt-4o\")\n",
    "ragas_answer_relevancy = RAGASAnswerRelevancyMetric(threshold=0.5, embeddings=OpenAIEmbeddings(), model=\"gpt-4o\")\n",
    "\n",
    "eval_results = evaluate(test_cases=eval_dataset.test_cases,\n",
    "                        metrics=[contextual_precision, contextual_recall, contextual_relevancy,\n",
    "                                 answer_relevancy, ragas_answer_relevancy, faithfulness, hallucination])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8dfeb523-7455-4e87-a5fb-50d3d110111f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24TsKs6JgbL7",
    "outputId": "1bccb937-a048-42a1-c599-6c4df3acf87f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestResult(success=True, metrics_data=[MetricData(name='Contextual Precision', threshold=0.5, success=True, score=1.0, reason=\"The score is 1.00 because the node in the retrieval context perfectly aligns with the input by explaining that 'renewable energy sources, such as solar and wind, provide sustainable alternatives to fossil fuels' and 'reduce greenhouse gas emissions,' which directly addresses how solar and wind investments contribute to reducing emissions and supporting climate change mitigation. Great job on ranking the relevant information at the top!\", strict_mode=False, evaluation_model='gpt-4o', error=None, evaluation_cost=0.0040025, verbose_logs='Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The context states that \\'renewable energy sources, such as solar and wind, provide sustainable alternatives to fossil fuels\\' and \\'reduce greenhouse gas emissions,\\' which directly addresses how solar and wind investments contribute to reducing emissions and supporting climate change mitigation.\"\\n    }\\n]'), MetricData(name='Contextual Recall', threshold=0.5, success=True, score=1.0, reason='The score is 1.00 because every sentence in the expected output is perfectly aligned with information from the node in the retrieval context, highlighting a comprehensive and accurate connection between the content and context. Great job!', strict_mode=False, evaluation_model='gpt-4o', error=None, evaluation_cost=0.00429, verbose_logs='Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The 1st node mentions \\'solar and wind\\' as \\'sustainable alternatives to fossil fuels\\' and \\'reduce greenhouse gas emissions\\', aligning with the sentence.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The 1st node states \\'resources are replenished naturally\\' and \\'reduce greenhouse gas emissions\\', supporting the sentence about naturally replenished resources and climate change mitigation.\"\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The 1st node includes \\'Governments are investing in renewables to combat climate change\\', directly linking to the promotion by governments mentioned in the sentence.\"\\n    }\\n]'), MetricData(name='Contextual Relevancy', threshold=0.5, success=True, score=1.0, reason='The score is 1.00 because the retrieval context perfectly supports the input with relevant statements, highlighting that solar and wind energy reduce emissions and are key to combating climate change. Great job capturing the essence of the question!', strict_mode=False, evaluation_model='gpt-4o', error=None, evaluation_cost=0.0032825000000000003, verbose_logs='Verdicts:\\n[\\n    {\\n        \"verdicts\": [\\n            {\\n                \"statement\": \"Renewable energy sources, such as solar and wind, provide sustainable alternatives to fossil fuels.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"These resources are replenished naturally and reduce greenhouse gas emissions.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            },\\n            {\\n                \"statement\": \"Governments are investing in renewables to combat climate change.\",\\n                \"verdict\": \"yes\",\\n                \"reason\": null\\n            }\\n        ]\\n    }\\n]'), MetricData(name='Answer Relevancy', threshold=0.5, success=True, score=1.0, reason='The score is 1.00 because the response is perfectly relevant, directly addressing how solar and wind energy investments contribute to reducing emissions and supporting climate change mitigation. Great job!', strict_mode=False, evaluation_model='gpt-4o', error=None, evaluation_cost=0.00329, verbose_logs='Statements:\\n[\\n    \"Solar and wind energy investments contribute to reducing emissions by providing sustainable alternatives to fossil fuels.\",\\n    \"Solar and wind energy investments help to lower greenhouse gas emissions.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    },\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'), MetricData(name='Answer Relevancy (ragas)', threshold=0.5, success=True, score=0.970122634281378, reason=None, strict_mode=False, evaluation_model='gpt-4o', error=None, evaluation_cost=None, verbose_logs=None), MetricData(name='Faithfulness', threshold=0.5, success=True, score=1.0, reason='The score is 1.00 because there are no contradictions. Everything aligns perfectly with the retrieval context. Great job!', strict_mode=False, evaluation_model='gpt-4o', error=None, evaluation_cost=0.004975, verbose_logs='Truths (limit=None):\\n[\\n    \"Renewable energy sources include solar and wind.\",\\n    \"Renewable energy sources provide sustainable alternatives to fossil fuels.\",\\n    \"Renewable energy sources are replenished naturally.\",\\n    \"Renewable energy sources reduce greenhouse gas emissions.\",\\n    \"Governments are investing in renewables to combat climate change.\"\\n] \\n \\nClaims:\\n[\\n    \"Solar and wind energy investments contribute to reducing emissions by providing sustainable alternatives to fossil fuels, which helps to lower greenhouse gas emissions.\"\\n] \\n \\nVerdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": null\\n    }\\n]'), MetricData(name='Hallucination', threshold=0.5, success=True, score=0.0, reason='The score is 0.00 because the actual output completely aligns with the provided context, with no contradictions present.', strict_mode=False, evaluation_model='gpt-4o', error=None, evaluation_cost=0.0025900000000000003, verbose_logs='Verdicts:\\n[\\n    {\\n        \"verdict\": \"yes\",\\n        \"reason\": \"The actual output agrees with the provided context which states that solar and wind energy investments contribute to reducing emissions by providing sustainable alternatives to fossil fuels and help to lower greenhouse gas emissions.\"\\n    }\\n]')], conversational=False, multimodal=False, input='In what ways do solar and wind energy investments contribute to reducing emissions and supporting climate change mitigation?', actual_output='Solar and wind energy investments contribute to reducing emissions by providing sustainable alternatives to fossil fuels, which helps to lower greenhouse gas emissions.', expected_output='Solar and wind energy investments contribute to reducing emissions by providing sustainable alternatives to fossil fuels, which decrease greenhouse gas emissions. By harnessing naturally replenished resources, these investments support climate change mitigation efforts and are actively promoted by governments to combat environmental impacts.', context=['Renewable energy sources, such as solar and wind, provide sustainable alternatives to fossil fuels. These resources are replenished naturally and reduce greenhouse gas emissions. Governments are investing in renewables to combat climate change.'], retrieval_context=['Renewable energy sources, such as solar and wind, provide sustainable alternatives to fossil fuels. These resources are replenished naturally and reduce greenhouse gas emissions. Governments are investing in renewables to combat climate change.'])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results.test_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: In what ways do AI systems utilize data analysis to classify information and predict trends?\n",
      "Expected Output: AI systems utilize data analysis by employing algorithms that learn patterns from historical data. These algorithms can classify information by identifying features and relationships within the data. Additionally, they predict trends by analyzing past behaviors and outcomes to forecast future events, commonly seen in recommendation systems and image recognition.\n",
      "Actual Output: AI systems utilize data analysis by employing algorithms to analyze past data, which allows them to identify patterns for making predictions or classifying information.\n",
      "Context: ['Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.']\n",
      "Retrieval Context: ['Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.', \"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\", 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.']\n",
      "Success: False\n",
      "Contextual Precision: 1.0\n",
      "Contextual Precision_Success: True\n",
      "Contextual Precision_Reason: The score is 1.00 because the first node in the retrieval context directly addresses the ways AI systems utilize data analysis by explaining how algorithms analyze past data to make predictions or classify information. The irrelevant nodes, ranked second and third, discuss AI in general terms and applications like virtual assistants and robotics or focus on NLP techniques, which do not directly relate to the input question. Great job on getting it spot on!\n",
      "Contextual Recall: 1.0\n",
      "Contextual Recall_Success: True\n",
      "Contextual Recall_Reason: The score is 1.00 because every sentence in the expected output is perfectly aligned with information from the nodes in the retrieval context. Great job!\n",
      "Contextual Relevancy: 0.3333333333333333\n",
      "Contextual Relevancy_Success: False\n",
      "Contextual Relevancy_Reason: The score is 0.33 because while the statements mention that 'algorithms analyze past data to make predictions or classify information,' most of the context is focused on NLP and general AI applications, which do not directly address the specific ways AI uses data analysis for classification and trend prediction.\n",
      "Answer Relevancy: 1.0\n",
      "Answer Relevancy_Success: True\n",
      "Answer Relevancy_Reason: The score is 1.00 because the response is perfectly relevant, directly addressing how AI systems use data analysis to classify information and predict trends without any irrelevant statements. Great job!\n",
      "Answer Relevancy (ragas): 0.9622997599013171\n",
      "Answer Relevancy (ragas)_Success: True\n",
      "Answer Relevancy (ragas)_Reason: None\n",
      "Faithfulness: 1.0\n",
      "Faithfulness_Success: True\n",
      "Faithfulness_Reason: The score is 1.00 because there are no contradictions, indicating a perfect alignment between the actual output and the retrieval context. Great job!\n",
      "Hallucination: 0.0\n",
      "Hallucination_Success: True\n",
      "Hallucination_Reason: The score is 0.00 because the actual output is fully aligned with the provided context, with no contradictions noted.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input: How does NLP enhance language understanding and improve applications such as chatbots and translation in AI?\n",
      "Expected Output: NLP enhances language understanding by using techniques like tokenization and stemming to break down and interpret text. It improves applications such as chatbots by enabling more natural and meaningful interactions, and in translation services by allowing accurate language conversion.\n",
      "Actual Output: NLP enhances language understanding by enabling computers to understand, interpret, and generate human language through techniques like tokenization, stemming, and sentiment analysis. This improvement benefits applications such as chatbots and language translation services.\n",
      "Context: ['NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.']\n",
      "Retrieval Context: ['NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.', \"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\", 'Deep learning is a subset of machine learning utilizing neural networks with many layers. It excels in complex tasks like image and speech recognition. Convolutional and recurrent neural networks are among the common architectures used.']\n",
      "Success: False\n",
      "Contextual Precision: 1.0\n",
      "Contextual Precision_Success: True\n",
      "Contextual Precision_Reason: The score is 1.00 because the relevant node in the retrieval context is ranked first, providing a comprehensive explanation of how NLP enhances language understanding and improves applications such as chatbots and translation. Way to go!\n",
      "Contextual Recall: 1.0\n",
      "Contextual Recall_Success: True\n",
      "Contextual Recall_Reason: The score is 1.00 because every sentence in the expected output is perfectly matched with the information from the nodes in the retrieval context. Great job!\n",
      "Contextual Relevancy: 0.3333333333333333\n",
      "Contextual Relevancy_Success: False\n",
      "Contextual Relevancy_Reason: The score is 0.33 because while relevant statements like 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language' and 'Applications range from chatbots to language translation services' are present, the majority of the context does not specifically address how NLP enhances language understanding or improves applications like chatbots and translation.\n",
      "Answer Relevancy: 1.0\n",
      "Answer Relevancy_Success: True\n",
      "Answer Relevancy_Reason: The score is 1.00 because the response is perfectly relevant and directly addresses how NLP enhances language understanding and improves applications like chatbots and translation without any irrelevant statements. Great job!\n",
      "Answer Relevancy (ragas): 0.9608503324052095\n",
      "Answer Relevancy (ragas)_Success: True\n",
      "Answer Relevancy (ragas)_Reason: None\n",
      "Faithfulness: 1.0\n",
      "Faithfulness_Success: True\n",
      "Faithfulness_Reason: The score is 1.00 because there are no contradictions, which means the actual output is perfectly aligned with the retrieval context. Great job!\n",
      "Hallucination: 0.0\n",
      "Hallucination_Success: True\n",
      "Hallucination_Reason: The score is 0.00 because there are no contradictions between the actual output and the provided context, indicating full alignment with factual information.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input: In what ways do wave-particle duality and uncertainty principle challenge the principles of classical physics within the framework of quantum mechanics?\n",
      "Expected Output: Wave-particle duality challenges classical physics by demonstrating that particles like electrons exhibit both wave-like and particle-like properties, contradicting the classical view of particles having a definite state. The uncertainty principle, introduced by Heisenberg, further challenges classical physics by stating that certain pairs of properties, such as position and momentum, cannot be simultaneously known with arbitrary precision. These concepts defy the deterministic nature of classical physics, where particles are expected to have definite positions and velocities.\n",
      "Actual Output: Wave-particle duality and the uncertainty principle challenge classical physics by introducing concepts that do not align with classical notions of particles having definite positions and velocities. In quantum mechanics, particles exhibit both wave-like and particle-like properties, and the uncertainty principle states that certain pairs of properties, like position and momentum, cannot be simultaneously known with arbitrary precision.\n",
      "Context: ['Quantum mechanics is a branch of physics that studies the behavior of particles at atomic and subatomic levels. It challenges classical physics with concepts like wave-particle duality and uncertainty. Key figures include Einstein, Schr√∂dinger, and Heisenberg.']\n",
      "Retrieval Context: ['Quantum mechanics is a branch of physics that studies the behavior of particles at atomic and subatomic levels. It challenges classical physics with concepts like wave-particle duality and uncertainty. Key figures include Einstein, Schr√∂dinger, and Heisenberg.']\n",
      "Success: True\n",
      "Contextual Precision: 1.0\n",
      "Contextual Precision_Success: True\n",
      "Contextual Precision_Reason: The score is 1.00 because the retrieval context perfectly aligns with the input query, discussing how wave-particle duality and uncertainty principle challenge classical physics within quantum mechanics. Great job!\n",
      "Contextual Recall: 1.0\n",
      "Contextual Recall_Success: True\n",
      "Contextual Recall_Reason: The score is 1.00 because all sentences in the expected output perfectly align with the information from the nodes in the retrieval context, with no discrepancies or missing connections.\n",
      "Contextual Relevancy: 0.6666666666666666\n",
      "Contextual Relevancy_Success: True\n",
      "Contextual Relevancy_Reason: The score is 0.67 because while the retrieval context includes relevant statements such as 'Quantum mechanics is a branch of physics that studies the behavior of particles at atomic and subatomic levels' and 'It challenges classical physics with concepts like wave-particle duality and uncertainty', it also contains irrelevant information like 'Key figures include Einstein, Schr√∂dinger, and Heisenberg' which does not directly address the input question.\n",
      "Answer Relevancy: 1.0\n",
      "Answer Relevancy_Success: True\n",
      "Answer Relevancy_Reason: The score is 1.00 because the response perfectly addresses the input question without any irrelevant statements. Great job!\n",
      "Answer Relevancy (ragas): 0.9801583669448245\n",
      "Answer Relevancy (ragas)_Success: True\n",
      "Answer Relevancy (ragas)_Reason: None\n",
      "Faithfulness: 1.0\n",
      "Faithfulness_Success: True\n",
      "Faithfulness_Reason: The score is 1.00 because there are no contradictions, indicating perfect alignment between the actual output and the retrieval context. Great job!\n",
      "Hallucination: 0.0\n",
      "Hallucination_Success: True\n",
      "Hallucination_Reason: The score is 0.00 because the actual output fully aligns with the context, with no contradictions present.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input: In what ways do the construction techniques and the function of the pyramids as pharaohs' tombs contribute to their status as ancient wonders?\n",
      "Expected Output: The construction techniques of the pyramids, particularly the Great Pyramid of Giza, contribute to their status as ancient wonders due to the remarkable engineering skills and labor required to build such massive structures with precision, using limited technology. Additionally, their function as tombs for pharaohs highlights the cultural and religious significance of these monuments in ancient Egyptian society, further elevating their historical and architectural importance.\n",
      "Actual Output: The context does not provide specific details on how the construction techniques and the function of the pyramids as pharaohs' tombs contribute to their status as ancient wonders. Therefore, I don't know.\n",
      "Context: ['Pyramids are ancient structures, often serving as tombs for pharaohs in Egypt. The Great Pyramid of Giza is one of the Seven Wonders of the Ancient World. Their construction remains a subject of fascination and speculation.']\n",
      "Retrieval Context: ['Pyramids are ancient structures, often serving as tombs for pharaohs in Egypt. The Great Pyramid of Giza is one of the Seven Wonders of the Ancient World. Their construction remains a subject of fascination and speculation.']\n",
      "Success: False\n",
      "Contextual Precision: 1.0\n",
      "Contextual Precision_Success: True\n",
      "Contextual Precision_Reason: The score is 1.00 because all nodes in the retrieval context are relevant and directly address the input query. The context precisely highlights the pyramids' roles as pharaohs' tombs, their status as ancient wonders, and the fascination with their construction techniques, ensuring a perfect ranking of relevant information.\n",
      "Contextual Recall: 1.0\n",
      "Contextual Recall_Success: True\n",
      "Contextual Recall_Reason: The score is 1.00 because all elements of the expected output align perfectly with the nodes in the retrieval context, highlighting both the engineering marvel and cultural significance of the pyramids with no discrepancies. Great job!\n",
      "Contextual Relevancy: 1.0\n",
      "Contextual Relevancy_Success: True\n",
      "Contextual Relevancy_Reason: The score is 1.00 because the input directly relates to the pyramids as pharaohs' tombs, their construction techniques, and their status as ancient wonders, all of which are addressed in the relevant statements provided.\n",
      "Answer Relevancy: 0.5\n",
      "Answer Relevancy_Success: True\n",
      "Answer Relevancy_Reason: The score is 0.50 because while the response addresses the topic of pyramids, it lacks specific details and analysis about construction techniques and their function as tombs, which are crucial to fully answering the question.\n",
      "Answer Relevancy (ragas): 0.0\n",
      "Answer Relevancy (ragas)_Success: False\n",
      "Answer Relevancy (ragas)_Reason: None\n",
      "Faithfulness: 1.0\n",
      "Faithfulness_Success: True\n",
      "Faithfulness_Reason: The score is 1.00 because there are no contradictions. Great job on ensuring complete alignment!\n",
      "Hallucination: 0.0\n",
      "Hallucination_Success: True\n",
      "Hallucination_Reason: The score is 0.00 because the actual output does not contradict the context, and it aligns perfectly with the available information, indicating no hallucination.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input: How have advancements in cellular and DNA research influenced our current understanding of biology?\n",
      "Expected Output: Advancements in cellular and DNA research have significantly deepened our understanding of biology by revealing the fundamental mechanisms of life. They have elucidated how genetic information is stored, expressed, and passed on, thereby explaining how organisms function and evolve. These advancements have also enhanced our knowledge of ecological interactions and physiological processes, offering insights into the complexity and interconnectedness of life.\n",
      "Actual Output: Advancements in cellular and DNA research have contributed to modern biology by enhancing our understanding of how organisms function and interact with each other and their environment.\n",
      "Context: ['Biology is the study of living organisms, covering areas such as genetics, ecology, and physiology. It aims to understand how organisms function and interact with each other and their environment. Modern biology has advanced through the study of cells and DNA.']\n",
      "Retrieval Context: ['Biology is the study of living organisms, covering areas such as genetics, ecology, and physiology. It aims to understand how organisms function and interact with each other and their environment. Modern biology has advanced through the study of cells and DNA.']\n",
      "Success: False\n",
      "Contextual Precision: 1.0\n",
      "Contextual Precision_Success: True\n",
      "Contextual Precision_Reason: The score is 1.00 because the node in the retrieval context perfectly aligns with the input question. 'Modern biology has advanced through the study of cells and DNA,' directly responds to the inquiry about how advancements in cellular and DNA research have influenced biology. Great job on getting it just right!\n",
      "Contextual Recall: 1.0\n",
      "Contextual Recall_Success: True\n",
      "Contextual Recall_Reason: The score is 1.00 because the expected output is perfectly supported by the nodes in the retrieval context, demonstrating a thorough alignment between the provided information and the expected content. Great job maintaining accuracy and relevance!\n",
      "Contextual Relevancy: 0.3333333333333333\n",
      "Contextual Relevancy_Success: False\n",
      "Contextual Relevancy_Reason: The score is 0.33 because while the statement 'Modern biology has advanced through the study of cells and DNA.' is somewhat relevant to advancements in cellular and DNA research, the other information provided is too general and does not specifically address how these advancements have influenced our understanding of biology.\n",
      "Answer Relevancy: 1.0\n",
      "Answer Relevancy_Success: True\n",
      "Answer Relevancy_Reason: The score is 1.00 because the output directly addresses how advancements in cellular and DNA research have influenced our understanding of biology, with no irrelevant information.\n",
      "Answer Relevancy (ragas): 0.9739155183206378\n",
      "Answer Relevancy (ragas)_Success: True\n",
      "Answer Relevancy (ragas)_Reason: None\n",
      "Faithfulness: 1.0\n",
      "Faithfulness_Success: True\n",
      "Faithfulness_Reason: The score is 1.00 because there are no contradictions, indicating a perfectly faithful alignment between the actual output and the retrieval context. Great job!\n",
      "Hallucination: 0.0\n",
      "Hallucination_Success: True\n",
      "Hallucination_Reason: The score is 0.00 because the actual output fully aligns with the provided context without any contradictions, indicating no hallucination present.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input: What role do cryptographic methods and decentralization play in ensuring secure peer-to-peer transfers in Bitcoin?\n",
      "Expected Output: Cryptographic methods in Bitcoin ensure secure peer-to-peer transfers by encrypting transaction data, safeguarding it against tampering and fraud. Decentralization eliminates the need for traditional banks, as transactions are verified by a network of nodes, reducing reliance on a central authority and enhancing security through distributed consensus.\n",
      "Actual Output: Cryptographic methods ensure secure transactions in Bitcoin, while its decentralized nature allows peer-to-peer transfers without traditional banks.\n",
      "Context: ['Cryptocurrency is a digital currency that uses cryptography for secure transactions. Bitcoin, the first cryptocurrency, was launched in 2009. Its decentralized nature allows peer-to-peer transfers without traditional banks.']\n",
      "Retrieval Context: ['Cryptocurrency is a digital currency that uses cryptography for secure transactions. Bitcoin, the first cryptocurrency, was launched in 2009. Its decentralized nature allows peer-to-peer transfers without traditional banks.']\n",
      "Success: True\n",
      "Contextual Precision: 1.0\n",
      "Contextual Precision_Success: True\n",
      "Contextual Precision_Reason: The score is 1.00 because the relevant node effectively highlights the key aspects of using cryptography for secure transactions and emphasizes Bitcoin's decentralized nature. Fantastic job on capturing the essence of the input!\n",
      "Contextual Recall: 1.0\n",
      "Contextual Recall_Success: True\n",
      "Contextual Recall_Reason: The score is 1.00 because the expected output perfectly aligns with the information from the nodes in the retrieval context, demonstrating a complete and accurate recall. Great job!\n",
      "Contextual Relevancy: 1.0\n",
      "Contextual Relevancy_Success: True\n",
      "Contextual Relevancy_Reason: The score is 1.00 because the retrieval context perfectly matches the input, highlighting the key roles of cryptography and decentralization in Bitcoin's secure peer-to-peer transfers. Great job!\n",
      "Answer Relevancy: 1.0\n",
      "Answer Relevancy_Success: True\n",
      "Answer Relevancy_Reason: The score is 1.00 because the response perfectly addresses the role of cryptographic methods and decentralization in Bitcoin without any irrelevant statements. Great job!\n",
      "Answer Relevancy (ragas): 0.9425592932435508\n",
      "Answer Relevancy (ragas)_Success: True\n",
      "Answer Relevancy (ragas)_Reason: None\n",
      "Faithfulness: 1.0\n",
      "Faithfulness_Success: True\n",
      "Faithfulness_Reason: The score is 1.00 because there are no contradictions. Great job on maintaining complete alignment with the retrieval context!\n",
      "Hallucination: 0.0\n",
      "Hallucination_Success: True\n",
      "Hallucination_Reason: The score is 0.00 because there are no contradictions between the actual output and the context, and the factual alignments confirm that the output is accurate and consistent with the provided information.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input: How do multi-layered neural networks contribute to improvements in complex tasks like image and speech recognition?\n",
      "Expected Output: Multi-layered neural networks, such as convolutional and recurrent neural networks, enhance complex tasks like image and speech recognition by leveraging multiple layers to learn hierarchical representations of data. This allows the networks to automatically extract and process intricate features, improving accuracy and performance in these tasks.\n",
      "Actual Output: Multi-layered neural networks contribute to improvements in complex tasks like image and speech recognition by utilizing deep learning, which excels in these areas through architectures such as convolutional and recurrent neural networks.\n",
      "Context: ['Deep learning is a subset of machine learning utilizing neural networks with many layers. It excels in complex tasks like image and speech recognition. Convolutional and recurrent neural networks are among the common architectures used.']\n",
      "Retrieval Context: ['Deep learning is a subset of machine learning utilizing neural networks with many layers. It excels in complex tasks like image and speech recognition. Convolutional and recurrent neural networks are among the common architectures used.', 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.']\n",
      "Success: True\n",
      "Contextual Precision: 1.0\n",
      "Contextual Precision_Success: True\n",
      "Contextual Precision_Reason: The score is 1.00 because the relevant node in the retrieval context, ranked first, perfectly addresses the input question by discussing how 'Deep learning is a subset of machine learning utilizing neural networks with many layers' and excels in 'complex tasks like image and speech recognition.' Great job ranking the relevant information at the top!\n",
      "Contextual Recall: 1.0\n",
      "Contextual Recall_Success: True\n",
      "Contextual Recall_Reason: The score is 1.00 because every sentence in the expected output is perfectly aligned with the information from the nodes in the retrieval context, showcasing a comprehensive understanding and representation of the topic. Great job!\n",
      "Contextual Relevancy: 0.5\n",
      "Contextual Relevancy_Success: True\n",
      "Contextual Relevancy_Reason: The score is 0.50 because while the retrieval context mentions 'deep learning' and its role in 'complex tasks like image and speech recognition', it lacks specific details about how multi-layered neural networks contribute to these improvements, and includes irrelevant information about NLP techniques.\n",
      "Answer Relevancy: 1.0\n",
      "Answer Relevancy_Success: True\n",
      "Answer Relevancy_Reason: The score is 1.00 because the response perfectly addresses how multi-layered neural networks enhance complex tasks like image and speech recognition, with no irrelevant information included. Keep up the great work!\n",
      "Answer Relevancy (ragas): 0.9999999999999996\n",
      "Answer Relevancy (ragas)_Success: True\n",
      "Answer Relevancy (ragas)_Reason: None\n",
      "Faithfulness: 1.0\n",
      "Faithfulness_Success: True\n",
      "Faithfulness_Reason: The score is 1.00 because there are no contradictions. Excellent alignment between the actual output and the retrieval context!\n",
      "Hallucination: 0.0\n",
      "Hallucination_Success: True\n",
      "Hallucination_Reason: The score is 0.00 because the actual output fully aligns with the provided context, accurately describing the application and architectures of deep learning without any contradictions.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input: In what ways do AI applications like virtual assistants and robotics simulate human intelligence in everyday scenarios?\n",
      "Expected Output: AI applications like virtual assistants and robotics simulate human intelligence by performing tasks such as understanding and responding to spoken language, learning user preferences, recognizing objects, and making decisions. Virtual assistants can manage schedules, answer questions, and control smart home devices, while robotics can perform complex tasks like navigating environments and assembling products. These applications utilize machine learning and deep learning to improve their capabilities over time.\n",
      "Actual Output: AI applications like virtual assistants and robotics simulate human intelligence by mimicking problem-solving and learning capabilities. They utilize techniques from natural language processing (NLP) to understand and generate human language, and machine learning to analyze data and make predictions.\n",
      "Context: [\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\"]\n",
      "Retrieval Context: [\"Artificial intelligence refers to machines mimicking human intelligence, like problem-solving and learning. AI includes applications like virtual assistants, robotics, and autonomous vehicles. It's evolving rapidly with advancements in machine learning and deep learning.\", 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language. Techniques include tokenization, stemming, and sentiment analysis. Applications range from chatbots to language translation services.', 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data. Algorithms analyze past data to make predictions or classify information. Popular applications include recommendation systems and image recognition.']\n",
      "Success: True\n",
      "Contextual Precision: 0.8333333333333333\n",
      "Contextual Precision_Success: True\n",
      "Contextual Precision_Reason: The score is 0.83 because the first node in the retrieval context is relevant as it mentions 'AI includes applications like virtual assistants, robotics...', which directly relates to the input question. The second node is less relevant because it mentions 'NLP is a branch of AI that enables computers to understand, interpret, and generate human language,' and does not specifically address the simulation of human intelligence by virtual assistants and robotics. However, the third node is relevant as it discusses 'Machine learning is a field of artificial intelligence focused on enabling systems to learn patterns from data,' which supports how AI applications improve their capabilities.\n",
      "Contextual Recall: 1.0\n",
      "Contextual Recall_Success: True\n",
      "Contextual Recall_Reason: The score is 1.00 because the expected output is fully supported by the nodes in the retrieval context, with all relevant information aligning perfectly. Great job!\n",
      "Contextual Relevancy: 0.5555555555555556\n",
      "Contextual Relevancy_Success: True\n",
      "Contextual Relevancy_Reason: The score is 0.56 because while the relevant statements mention AI applications like virtual assistants and robotics, they do not specifically address how these applications simulate human intelligence in everyday scenarios. The input focuses on simulation of human intelligence, but the context mainly provides general information about AI and its branches like NLP.\n",
      "Answer Relevancy: 1.0\n",
      "Answer Relevancy_Success: True\n",
      "Answer Relevancy_Reason: The score is 1.00 because the response is perfectly relevant with no irrelevant statements, fully addressing how AI applications like virtual assistants and robotics simulate human intelligence in everyday scenarios. Great job!\n",
      "Answer Relevancy (ragas): 0.9803045957508069\n",
      "Answer Relevancy (ragas)_Success: True\n",
      "Answer Relevancy (ragas)_Reason: None\n",
      "Faithfulness: 1.0\n",
      "Faithfulness_Success: True\n",
      "Faithfulness_Reason: The score is 1.00 because there are no contradictions, indicating perfect alignment between the actual output and the retrieval context. Keep up the great work!\n",
      "Hallucination: 0.0\n",
      "Hallucination_Success: True\n",
      "Hallucination_Reason: The score is 0.00 because the actual output aligns completely with the provided context without any contradictions, indicating no hallucination present.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input: In what ways do solar and wind energy investments contribute to reducing emissions and supporting climate change mitigation?\n",
      "Expected Output: Solar and wind energy investments contribute to reducing emissions by providing sustainable alternatives to fossil fuels, which decrease greenhouse gas emissions. By harnessing naturally replenished resources, these investments support climate change mitigation efforts and are actively promoted by governments to combat environmental impacts.\n",
      "Actual Output: Solar and wind energy investments contribute to reducing emissions by providing sustainable alternatives to fossil fuels, which helps to lower greenhouse gas emissions.\n",
      "Context: ['Renewable energy sources, such as solar and wind, provide sustainable alternatives to fossil fuels. These resources are replenished naturally and reduce greenhouse gas emissions. Governments are investing in renewables to combat climate change.']\n",
      "Retrieval Context: ['Renewable energy sources, such as solar and wind, provide sustainable alternatives to fossil fuels. These resources are replenished naturally and reduce greenhouse gas emissions. Governments are investing in renewables to combat climate change.']\n",
      "Success: True\n",
      "Contextual Precision: 1.0\n",
      "Contextual Precision_Success: True\n",
      "Contextual Precision_Reason: The score is 1.00 because the node in the retrieval context directly addresses the input question by stating that 'Renewable energy sources, such as solar and wind, provide sustainable alternatives to fossil fuels' and 'reduce greenhouse gas emissions.' It also highlights that 'Governments are investing in renewables to combat climate change,' perfectly aligning with the expected output regarding climate change mitigation. Great job at retrieving the most relevant information!\n",
      "Contextual Recall: 1.0\n",
      "Contextual Recall_Success: True\n",
      "Contextual Recall_Reason: The score is 1.00 because every sentence in the expected output is perfectly supported by the 1st node in the retrieval context, aligning precisely with the information provided. Great job!\n",
      "Contextual Relevancy: 1.0\n",
      "Contextual Relevancy_Success: True\n",
      "Contextual Relevancy_Reason: The score is 1.00 because the retrieval context perfectly aligns with the input, highlighting how solar and wind energy reduce emissions and support climate change mitigation. Keep up the great work in exploring sustainable alternatives!\n",
      "Answer Relevancy: 1.0\n",
      "Answer Relevancy_Success: True\n",
      "Answer Relevancy_Reason: The score is 1.00 because the response is perfectly relevant, with no irrelevant statements, and directly addresses how solar and wind energy investments contribute to reducing emissions and supporting climate change mitigation. Great job!\n",
      "Answer Relevancy (ragas): 0.970122634281378\n",
      "Answer Relevancy (ragas)_Success: True\n",
      "Answer Relevancy (ragas)_Reason: None\n",
      "Faithfulness: 1.0\n",
      "Faithfulness_Success: True\n",
      "Faithfulness_Reason: The score is 1.00 because there are no contradictions, indicating perfect alignment between the actual output and the retrieval context. Great job maintaining consistency!\n",
      "Hallucination: 0.0\n",
      "Hallucination_Success: True\n",
      "Hallucination_Reason: The score is 0.00 because there are no contradictions between the actual output and the context, indicating complete factual alignment.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input: How do plants convert sunlight into energy and produce glucose and oxygen in the process?\n",
      "Expected Output: Plants convert sunlight into energy through photosynthesis. During this process, they use sunlight to convert carbon dioxide and water into glucose, which serves as energy, and oxygen is released as a byproduct. This process is essential for providing food and oxygen, sustaining life on Earth.\n",
      "Actual Output: Plants convert sunlight into energy through the process of photosynthesis, which produces glucose and releases oxygen as a byproduct.\n",
      "Context: ['Photosynthesis is the process plants use to convert sunlight into energy. This process produces glucose and releases oxygen as a byproduct. It is crucial for sustaining life on Earth by providing food and oxygen.']\n",
      "Retrieval Context: ['Photosynthesis is the process plants use to convert sunlight into energy. This process produces glucose and releases oxygen as a byproduct. It is crucial for sustaining life on Earth by providing food and oxygen.']\n",
      "Success: True\n",
      "Contextual Precision: 1.0\n",
      "Contextual Precision_Success: True\n",
      "Contextual Precision_Reason: The score is 1.00 because the first node in the retrieval context directly and accurately addresses the question about how plants convert sunlight into energy, mentioning both the production of glucose and the release of oxygen. Fantastic job!\n",
      "Contextual Recall: 1.0\n",
      "Contextual Recall_Success: True\n",
      "Contextual Recall_Reason: The score is 1.00 because every sentence in the expected output is perfectly supported by the information in the nodes in retrieval context. Great job!\n",
      "Contextual Relevancy: 0.5\n",
      "Contextual Relevancy_Success: True\n",
      "Contextual Relevancy_Reason: The score is 0.50 because while the relevant statement accurately describes photosynthesis as the process where plants convert sunlight into energy, producing glucose and oxygen, the irrelevancy note highlights that the importance of photosynthesis for sustaining life is not directly related to the specific process details asked in the input.\n",
      "Answer Relevancy: 1.0\n",
      "Answer Relevancy_Success: True\n",
      "Answer Relevancy_Reason: The score is 1.00 because the output is perfectly relevant and directly addresses the question about how plants convert sunlight into energy, without any irrelevant information. Great job!\n",
      "Answer Relevancy (ragas): 0.948771831411649\n",
      "Answer Relevancy (ragas)_Success: True\n",
      "Answer Relevancy (ragas)_Reason: None\n",
      "Faithfulness: 1.0\n",
      "Faithfulness_Success: True\n",
      "Faithfulness_Reason: The score is 1.00 because there are no contradictions, indicating perfect alignment between the actual output and the retrieval context. Great job!\n",
      "Hallucination: 0.0\n",
      "Hallucination_Success: True\n",
      "Hallucination_Reason: The score is 0.00 because the actual output aligns perfectly with the provided context without any contradictions.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for result in eval_results.test_results:\n",
    "    print(f\"Input: {result.input}\")\n",
    "    print(f\"Expected Output: {result.expected_output}\")\n",
    "    print(f\"Actual Output: {result.actual_output}\")\n",
    "    print(f\"Context: {result.context}\")\n",
    "    print(f\"Retrieval Context: {result.retrieval_context}\")\n",
    "    print(f\"Success: {result.success}\")\n",
    "    metrics = result.metrics_data\n",
    "    for metric in metrics:\n",
    "        print(f\"{metric.name}: {metric.score}\")\n",
    "        print(f\"{metric.name}_Success: {metric.success}\")\n",
    "        print(f\"{metric.name}_Reason: {metric.reason}\")\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b205f62c-39ec-4dae-9f30-d730aad09359",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "wykn6lUXeRoe"
   },
   "outputs": [],
   "source": [
    "eval_metrics = []\n",
    "for result in eval_results.test_results:\n",
    "    eval_dict = {}\n",
    "    eval_dict['Input'] = result.input\n",
    "    eval_dict['Expected Output'] = result.expected_output\n",
    "    eval_dict['Actual Output'] = result.actual_output\n",
    "    eval_dict['Context'] = result.context\n",
    "    eval_dict['Retrieval Context'] = result.retrieval_context\n",
    "    eval_dict['Success'] = result.success\n",
    "    metrics = result.metrics_data\n",
    "    for metric in metrics:\n",
    "        eval_dict[metric.name+'_Score'] = metric.score\n",
    "    for metric in metrics:\n",
    "        eval_dict[metric.name+'_Success'] = metric.success\n",
    "    for metric in metrics:\n",
    "        eval_dict[metric.name+'_Reason'] = metric.reason\n",
    "    eval_metrics.append(eval_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "94de1364-dada-4d6f-bbdf-3db2aa821933",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9J4KlVzIfXCP",
    "outputId": "8d80c436-9951-458e-a54b-637ce96061b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Input': 'In what ways do solar and wind energy investments contribute to reducing emissions and supporting climate change mitigation?',\n",
       " 'Expected Output': 'Solar and wind energy investments contribute to reducing emissions by providing sustainable alternatives to fossil fuels, which decrease greenhouse gas emissions. By harnessing naturally replenished resources, these investments support climate change mitigation efforts and are actively promoted by governments to combat environmental impacts.',\n",
       " 'Actual Output': 'Solar and wind energy investments contribute to reducing emissions by providing sustainable alternatives to fossil fuels, which helps to lower greenhouse gas emissions.',\n",
       " 'Context': ['Renewable energy sources, such as solar and wind, provide sustainable alternatives to fossil fuels. These resources are replenished naturally and reduce greenhouse gas emissions. Governments are investing in renewables to combat climate change.'],\n",
       " 'Retrieval Context': ['Renewable energy sources, such as solar and wind, provide sustainable alternatives to fossil fuels. These resources are replenished naturally and reduce greenhouse gas emissions. Governments are investing in renewables to combat climate change.'],\n",
       " 'Success': True,\n",
       " 'Contextual Precision_Score': 1.0,\n",
       " 'Contextual Recall_Score': 1.0,\n",
       " 'Contextual Relevancy_Score': 1.0,\n",
       " 'Answer Relevancy_Score': 1.0,\n",
       " 'Answer Relevancy (ragas)_Score': 0.970122634281378,\n",
       " 'Faithfulness_Score': 1.0,\n",
       " 'Hallucination_Score': 0.0,\n",
       " 'Contextual Precision_Success': True,\n",
       " 'Contextual Recall_Success': True,\n",
       " 'Contextual Relevancy_Success': True,\n",
       " 'Answer Relevancy_Success': True,\n",
       " 'Answer Relevancy (ragas)_Success': True,\n",
       " 'Faithfulness_Success': True,\n",
       " 'Hallucination_Success': True,\n",
       " 'Contextual Precision_Reason': \"The score is 1.00 because the node in the retrieval context perfectly aligns with the input by explaining that 'renewable energy sources, such as solar and wind, provide sustainable alternatives to fossil fuels' and 'reduce greenhouse gas emissions,' which directly addresses how solar and wind investments contribute to reducing emissions and supporting climate change mitigation. Great job on ranking the relevant information at the top!\",\n",
       " 'Contextual Recall_Reason': 'The score is 1.00 because every sentence in the expected output is perfectly aligned with information from the node in the retrieval context, highlighting a comprehensive and accurate connection between the content and context. Great job!',\n",
       " 'Contextual Relevancy_Reason': 'The score is 1.00 because the retrieval context perfectly supports the input with relevant statements, highlighting that solar and wind energy reduce emissions and are key to combating climate change. Great job capturing the essence of the question!',\n",
       " 'Answer Relevancy_Reason': 'The score is 1.00 because the response is perfectly relevant, directly addressing how solar and wind energy investments contribute to reducing emissions and supporting climate change mitigation. Great job!',\n",
       " 'Answer Relevancy (ragas)_Reason': None,\n",
       " 'Faithfulness_Reason': 'The score is 1.00 because there are no contradictions. Everything aligns perfectly with the retrieval context. Great job!',\n",
       " 'Hallucination_Reason': 'The score is 0.00 because the actual output completely aligns with the provided context, with no contradictions present.'}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_metrics[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6b593e54-5eee-4a66-af70-b114094c3de3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0chd5WCigMwo",
    "outputId": "ac57379c-49b3-48ce-b3d3-322f9761cb8c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Input</th>\n",
       "      <td>In what ways do solar and wind energy investme...</td>\n",
       "      <td>How do multi-layered neural networks contribut...</td>\n",
       "      <td>In what ways do the construction techniques an...</td>\n",
       "      <td>What role do cryptographic methods and decentr...</td>\n",
       "      <td>In what ways do AI systems utilize data analys...</td>\n",
       "      <td>In what ways do wave-particle duality and unce...</td>\n",
       "      <td>In what ways do AI applications like virtual a...</td>\n",
       "      <td>How have advancements in cellular and DNA rese...</td>\n",
       "      <td>How do plants convert sunlight into energy and...</td>\n",
       "      <td>How does NLP enhance language understanding an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Expected Output</th>\n",
       "      <td>Solar and wind energy investments contribute t...</td>\n",
       "      <td>Multi-layered neural networks, such as convolu...</td>\n",
       "      <td>The construction techniques of the pyramids, p...</td>\n",
       "      <td>Cryptographic methods in Bitcoin ensure secure...</td>\n",
       "      <td>AI systems utilize data analysis by employing ...</td>\n",
       "      <td>Wave-particle duality challenges classical phy...</td>\n",
       "      <td>AI applications like virtual assistants and ro...</td>\n",
       "      <td>Advancements in cellular and DNA research have...</td>\n",
       "      <td>Plants convert sunlight into energy through ph...</td>\n",
       "      <td>NLP enhances language understanding by using t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Output</th>\n",
       "      <td>Solar and wind energy investments contribute t...</td>\n",
       "      <td>Multi-layered neural networks contribute to im...</td>\n",
       "      <td>The context does not provide specific details ...</td>\n",
       "      <td>Cryptographic methods ensure secure transactio...</td>\n",
       "      <td>AI systems utilize data analysis by employing ...</td>\n",
       "      <td>Wave-particle duality and the uncertainty prin...</td>\n",
       "      <td>AI applications like virtual assistants and ro...</td>\n",
       "      <td>Advancements in cellular and DNA research have...</td>\n",
       "      <td>Plants convert sunlight into energy through th...</td>\n",
       "      <td>NLP enhances language understanding by enablin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Context</th>\n",
       "      <td>[Renewable energy sources, such as solar and w...</td>\n",
       "      <td>[Deep learning is a subset of machine learning...</td>\n",
       "      <td>[Pyramids are ancient structures, often servin...</td>\n",
       "      <td>[Cryptocurrency is a digital currency that use...</td>\n",
       "      <td>[Machine learning is a field of artificial int...</td>\n",
       "      <td>[Quantum mechanics is a branch of physics that...</td>\n",
       "      <td>[Artificial intelligence refers to machines mi...</td>\n",
       "      <td>[Biology is the study of living organisms, cov...</td>\n",
       "      <td>[Photosynthesis is the process plants use to c...</td>\n",
       "      <td>[NLP is a branch of AI that enables computers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retrieval Context</th>\n",
       "      <td>[Renewable energy sources, such as solar and w...</td>\n",
       "      <td>[Deep learning is a subset of machine learning...</td>\n",
       "      <td>[Pyramids are ancient structures, often servin...</td>\n",
       "      <td>[Cryptocurrency is a digital currency that use...</td>\n",
       "      <td>[Machine learning is a field of artificial int...</td>\n",
       "      <td>[Quantum mechanics is a branch of physics that...</td>\n",
       "      <td>[Artificial intelligence refers to machines mi...</td>\n",
       "      <td>[Biology is the study of living organisms, cov...</td>\n",
       "      <td>[Photosynthesis is the process plants use to c...</td>\n",
       "      <td>[NLP is a branch of AI that enables computers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Success</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contextual Precision_Score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contextual Recall_Score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contextual Relevancy_Score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Answer Relevancy_Score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Answer Relevancy (ragas)_Score</th>\n",
       "      <td>0.970123</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.942471</td>\n",
       "      <td>0.962305</td>\n",
       "      <td>0.980184</td>\n",
       "      <td>0.98029</td>\n",
       "      <td>0.990291</td>\n",
       "      <td>0.948705</td>\n",
       "      <td>0.960904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Faithfulness_Score</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hallucination_Score</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contextual Precision_Success</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contextual Recall_Success</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contextual Relevancy_Success</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Answer Relevancy_Success</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Answer Relevancy (ragas)_Success</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Faithfulness_Success</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hallucination_Success</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contextual Precision_Reason</th>\n",
       "      <td>The score is 1.00 because the node in the retr...</td>\n",
       "      <td>The score is 1.00 because the relevant node in...</td>\n",
       "      <td>The score is 1.00 because all relevant nodes i...</td>\n",
       "      <td>The score is 1.00 because the first node in th...</td>\n",
       "      <td>The score is 1.00 because the relevant node, w...</td>\n",
       "      <td>The score is 1.00 because the node in retrieva...</td>\n",
       "      <td>The score is 1.00 because all nodes in the ret...</td>\n",
       "      <td>The score is 1.00 because the node in the retr...</td>\n",
       "      <td>The score is 1.00 because the first node in th...</td>\n",
       "      <td>The score is 1.00 because all the relevant nod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contextual Recall_Reason</th>\n",
       "      <td>The score is 1.00 because every sentence in th...</td>\n",
       "      <td>The score is 0.50 because while the first sent...</td>\n",
       "      <td>The score is 1.00 because all sentences in the...</td>\n",
       "      <td>The score is 1.00 because all sentences in the...</td>\n",
       "      <td>The score is 1.00 because every sentence in th...</td>\n",
       "      <td>The score is 1.00 because all sentences in the...</td>\n",
       "      <td>The score is 1.00 because every sentence in th...</td>\n",
       "      <td>The score is 0.67 because the retrieval contex...</td>\n",
       "      <td>The score is 0.75 because while the nodes in r...</td>\n",
       "      <td>The score is 1.00 because every sentence in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contextual Relevancy_Reason</th>\n",
       "      <td>The score is 1.00 because the retrieval contex...</td>\n",
       "      <td>The score is 0.50 because while the retrieval ...</td>\n",
       "      <td>The score is 1.00 because the context perfectl...</td>\n",
       "      <td>The score is 1.00 because the context precisel...</td>\n",
       "      <td>The score is 0.56 because while the relevant s...</td>\n",
       "      <td>The score is 0.67 because while the retrieval ...</td>\n",
       "      <td>The score is 0.56 because while some statement...</td>\n",
       "      <td>The score is 1.00 because the retrieval contex...</td>\n",
       "      <td>The score is 0.67 because while the relevant s...</td>\n",
       "      <td>The score is 0.33 because while the retrieval ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Answer Relevancy_Reason</th>\n",
       "      <td>The score is 1.00 because the response is perf...</td>\n",
       "      <td>The score is 1.00 because the response is full...</td>\n",
       "      <td>The score is 0.50 because while the output par...</td>\n",
       "      <td>The score is 1.00 because the response perfect...</td>\n",
       "      <td>The score is 1.00 because the response was per...</td>\n",
       "      <td>The score is 1.00 because the response perfect...</td>\n",
       "      <td>The score is 1.00 because the response is perf...</td>\n",
       "      <td>The score is 1.00 because the output is perfec...</td>\n",
       "      <td>The score is 1.00 because the answer perfectly...</td>\n",
       "      <td>The score is 1.00 because the response is perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Answer Relevancy (ragas)_Reason</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Faithfulness_Reason</th>\n",
       "      <td>The score is 1.00 because there are no contrad...</td>\n",
       "      <td>The score is 1.00 because there are no contrad...</td>\n",
       "      <td>The score is 1.00 because there are no contrad...</td>\n",
       "      <td>The score is 1.00 because there are no contrad...</td>\n",
       "      <td>The score is 1.00 because there are no contrad...</td>\n",
       "      <td>The score is 1.00 because there are no contrad...</td>\n",
       "      <td>The score is 1.00 because there are no contrad...</td>\n",
       "      <td>The score is 1.00 because there are no contrad...</td>\n",
       "      <td>The score is 1.00 because there are no contrad...</td>\n",
       "      <td>The score is 1.00 because there are no contrad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hallucination_Reason</th>\n",
       "      <td>The score is 0.00 because the actual output co...</td>\n",
       "      <td>The score is 0.00 because the actual output pe...</td>\n",
       "      <td>The score is 0.00 because the actual output do...</td>\n",
       "      <td>The score is 0.00 because the actual output al...</td>\n",
       "      <td>The score is 0.00 because the actual output fu...</td>\n",
       "      <td>The score is 0.00 because there are no contrad...</td>\n",
       "      <td>The score is 0.00 because the actual output al...</td>\n",
       "      <td>The score is 0.00 because the actual output fu...</td>\n",
       "      <td>The score is 0.00 because there are no contrad...</td>\n",
       "      <td>The score is 0.00 because the actual output fu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                  0  \\\n",
       "Input                             In what ways do solar and wind energy investme...   \n",
       "Expected Output                   Solar and wind energy investments contribute t...   \n",
       "Actual Output                     Solar and wind energy investments contribute t...   \n",
       "Context                           [Renewable energy sources, such as solar and w...   \n",
       "Retrieval Context                 [Renewable energy sources, such as solar and w...   \n",
       "Success                                                                        True   \n",
       "Contextual Precision_Score                                                      1.0   \n",
       "Contextual Recall_Score                                                         1.0   \n",
       "Contextual Relevancy_Score                                                      1.0   \n",
       "Answer Relevancy_Score                                                          1.0   \n",
       "Answer Relevancy (ragas)_Score                                             0.970123   \n",
       "Faithfulness_Score                                                              1.0   \n",
       "Hallucination_Score                                                             0.0   \n",
       "Contextual Precision_Success                                                   True   \n",
       "Contextual Recall_Success                                                      True   \n",
       "Contextual Relevancy_Success                                                   True   \n",
       "Answer Relevancy_Success                                                       True   \n",
       "Answer Relevancy (ragas)_Success                                               True   \n",
       "Faithfulness_Success                                                           True   \n",
       "Hallucination_Success                                                          True   \n",
       "Contextual Precision_Reason       The score is 1.00 because the node in the retr...   \n",
       "Contextual Recall_Reason          The score is 1.00 because every sentence in th...   \n",
       "Contextual Relevancy_Reason       The score is 1.00 because the retrieval contex...   \n",
       "Answer Relevancy_Reason           The score is 1.00 because the response is perf...   \n",
       "Answer Relevancy (ragas)_Reason                                                None   \n",
       "Faithfulness_Reason               The score is 1.00 because there are no contrad...   \n",
       "Hallucination_Reason              The score is 0.00 because the actual output co...   \n",
       "\n",
       "                                                                                  1  \\\n",
       "Input                             How do multi-layered neural networks contribut...   \n",
       "Expected Output                   Multi-layered neural networks, such as convolu...   \n",
       "Actual Output                     Multi-layered neural networks contribute to im...   \n",
       "Context                           [Deep learning is a subset of machine learning...   \n",
       "Retrieval Context                 [Deep learning is a subset of machine learning...   \n",
       "Success                                                                        True   \n",
       "Contextual Precision_Score                                                      1.0   \n",
       "Contextual Recall_Score                                                         0.5   \n",
       "Contextual Relevancy_Score                                                      0.5   \n",
       "Answer Relevancy_Score                                                          1.0   \n",
       "Answer Relevancy (ragas)_Score                                             0.999999   \n",
       "Faithfulness_Score                                                              1.0   \n",
       "Hallucination_Score                                                             0.0   \n",
       "Contextual Precision_Success                                                   True   \n",
       "Contextual Recall_Success                                                      True   \n",
       "Contextual Relevancy_Success                                                   True   \n",
       "Answer Relevancy_Success                                                       True   \n",
       "Answer Relevancy (ragas)_Success                                               True   \n",
       "Faithfulness_Success                                                           True   \n",
       "Hallucination_Success                                                          True   \n",
       "Contextual Precision_Reason       The score is 1.00 because the relevant node in...   \n",
       "Contextual Recall_Reason          The score is 0.50 because while the first sent...   \n",
       "Contextual Relevancy_Reason       The score is 0.50 because while the retrieval ...   \n",
       "Answer Relevancy_Reason           The score is 1.00 because the response is full...   \n",
       "Answer Relevancy (ragas)_Reason                                                None   \n",
       "Faithfulness_Reason               The score is 1.00 because there are no contrad...   \n",
       "Hallucination_Reason              The score is 0.00 because the actual output pe...   \n",
       "\n",
       "                                                                                  2  \\\n",
       "Input                             In what ways do the construction techniques an...   \n",
       "Expected Output                   The construction techniques of the pyramids, p...   \n",
       "Actual Output                     The context does not provide specific details ...   \n",
       "Context                           [Pyramids are ancient structures, often servin...   \n",
       "Retrieval Context                 [Pyramids are ancient structures, often servin...   \n",
       "Success                                                                       False   \n",
       "Contextual Precision_Score                                                      1.0   \n",
       "Contextual Recall_Score                                                         1.0   \n",
       "Contextual Relevancy_Score                                                      1.0   \n",
       "Answer Relevancy_Score                                                          0.5   \n",
       "Answer Relevancy (ragas)_Score                                                  0.0   \n",
       "Faithfulness_Score                                                              1.0   \n",
       "Hallucination_Score                                                             0.0   \n",
       "Contextual Precision_Success                                                   True   \n",
       "Contextual Recall_Success                                                      True   \n",
       "Contextual Relevancy_Success                                                   True   \n",
       "Answer Relevancy_Success                                                       True   \n",
       "Answer Relevancy (ragas)_Success                                              False   \n",
       "Faithfulness_Success                                                           True   \n",
       "Hallucination_Success                                                          True   \n",
       "Contextual Precision_Reason       The score is 1.00 because all relevant nodes i...   \n",
       "Contextual Recall_Reason          The score is 1.00 because all sentences in the...   \n",
       "Contextual Relevancy_Reason       The score is 1.00 because the context perfectl...   \n",
       "Answer Relevancy_Reason           The score is 0.50 because while the output par...   \n",
       "Answer Relevancy (ragas)_Reason                                                None   \n",
       "Faithfulness_Reason               The score is 1.00 because there are no contrad...   \n",
       "Hallucination_Reason              The score is 0.00 because the actual output do...   \n",
       "\n",
       "                                                                                  3  \\\n",
       "Input                             What role do cryptographic methods and decentr...   \n",
       "Expected Output                   Cryptographic methods in Bitcoin ensure secure...   \n",
       "Actual Output                     Cryptographic methods ensure secure transactio...   \n",
       "Context                           [Cryptocurrency is a digital currency that use...   \n",
       "Retrieval Context                 [Cryptocurrency is a digital currency that use...   \n",
       "Success                                                                        True   \n",
       "Contextual Precision_Score                                                      1.0   \n",
       "Contextual Recall_Score                                                         1.0   \n",
       "Contextual Relevancy_Score                                                      1.0   \n",
       "Answer Relevancy_Score                                                          1.0   \n",
       "Answer Relevancy (ragas)_Score                                             0.942471   \n",
       "Faithfulness_Score                                                              1.0   \n",
       "Hallucination_Score                                                             0.0   \n",
       "Contextual Precision_Success                                                   True   \n",
       "Contextual Recall_Success                                                      True   \n",
       "Contextual Relevancy_Success                                                   True   \n",
       "Answer Relevancy_Success                                                       True   \n",
       "Answer Relevancy (ragas)_Success                                               True   \n",
       "Faithfulness_Success                                                           True   \n",
       "Hallucination_Success                                                          True   \n",
       "Contextual Precision_Reason       The score is 1.00 because the first node in th...   \n",
       "Contextual Recall_Reason          The score is 1.00 because all sentences in the...   \n",
       "Contextual Relevancy_Reason       The score is 1.00 because the context precisel...   \n",
       "Answer Relevancy_Reason           The score is 1.00 because the response perfect...   \n",
       "Answer Relevancy (ragas)_Reason                                                None   \n",
       "Faithfulness_Reason               The score is 1.00 because there are no contrad...   \n",
       "Hallucination_Reason              The score is 0.00 because the actual output al...   \n",
       "\n",
       "                                                                                  4  \\\n",
       "Input                             In what ways do AI systems utilize data analys...   \n",
       "Expected Output                   AI systems utilize data analysis by employing ...   \n",
       "Actual Output                     AI systems utilize data analysis by employing ...   \n",
       "Context                           [Machine learning is a field of artificial int...   \n",
       "Retrieval Context                 [Machine learning is a field of artificial int...   \n",
       "Success                                                                        True   \n",
       "Contextual Precision_Score                                                      1.0   \n",
       "Contextual Recall_Score                                                         1.0   \n",
       "Contextual Relevancy_Score                                                 0.555556   \n",
       "Answer Relevancy_Score                                                          1.0   \n",
       "Answer Relevancy (ragas)_Score                                             0.962305   \n",
       "Faithfulness_Score                                                              1.0   \n",
       "Hallucination_Score                                                             0.0   \n",
       "Contextual Precision_Success                                                   True   \n",
       "Contextual Recall_Success                                                      True   \n",
       "Contextual Relevancy_Success                                                   True   \n",
       "Answer Relevancy_Success                                                       True   \n",
       "Answer Relevancy (ragas)_Success                                               True   \n",
       "Faithfulness_Success                                                           True   \n",
       "Hallucination_Success                                                          True   \n",
       "Contextual Precision_Reason       The score is 1.00 because the relevant node, w...   \n",
       "Contextual Recall_Reason          The score is 1.00 because every sentence in th...   \n",
       "Contextual Relevancy_Reason       The score is 0.56 because while the relevant s...   \n",
       "Answer Relevancy_Reason           The score is 1.00 because the response was per...   \n",
       "Answer Relevancy (ragas)_Reason                                                None   \n",
       "Faithfulness_Reason               The score is 1.00 because there are no contrad...   \n",
       "Hallucination_Reason              The score is 0.00 because the actual output fu...   \n",
       "\n",
       "                                                                                  5  \\\n",
       "Input                             In what ways do wave-particle duality and unce...   \n",
       "Expected Output                   Wave-particle duality challenges classical phy...   \n",
       "Actual Output                     Wave-particle duality and the uncertainty prin...   \n",
       "Context                           [Quantum mechanics is a branch of physics that...   \n",
       "Retrieval Context                 [Quantum mechanics is a branch of physics that...   \n",
       "Success                                                                        True   \n",
       "Contextual Precision_Score                                                      1.0   \n",
       "Contextual Recall_Score                                                         1.0   \n",
       "Contextual Relevancy_Score                                                 0.666667   \n",
       "Answer Relevancy_Score                                                          1.0   \n",
       "Answer Relevancy (ragas)_Score                                             0.980184   \n",
       "Faithfulness_Score                                                              1.0   \n",
       "Hallucination_Score                                                             0.0   \n",
       "Contextual Precision_Success                                                   True   \n",
       "Contextual Recall_Success                                                      True   \n",
       "Contextual Relevancy_Success                                                   True   \n",
       "Answer Relevancy_Success                                                       True   \n",
       "Answer Relevancy (ragas)_Success                                               True   \n",
       "Faithfulness_Success                                                           True   \n",
       "Hallucination_Success                                                          True   \n",
       "Contextual Precision_Reason       The score is 1.00 because the node in retrieva...   \n",
       "Contextual Recall_Reason          The score is 1.00 because all sentences in the...   \n",
       "Contextual Relevancy_Reason       The score is 0.67 because while the retrieval ...   \n",
       "Answer Relevancy_Reason           The score is 1.00 because the response perfect...   \n",
       "Answer Relevancy (ragas)_Reason                                                None   \n",
       "Faithfulness_Reason               The score is 1.00 because there are no contrad...   \n",
       "Hallucination_Reason              The score is 0.00 because there are no contrad...   \n",
       "\n",
       "                                                                                  6  \\\n",
       "Input                             In what ways do AI applications like virtual a...   \n",
       "Expected Output                   AI applications like virtual assistants and ro...   \n",
       "Actual Output                     AI applications like virtual assistants and ro...   \n",
       "Context                           [Artificial intelligence refers to machines mi...   \n",
       "Retrieval Context                 [Artificial intelligence refers to machines mi...   \n",
       "Success                                                                        True   \n",
       "Contextual Precision_Score                                                      1.0   \n",
       "Contextual Recall_Score                                                         1.0   \n",
       "Contextual Relevancy_Score                                                 0.555556   \n",
       "Answer Relevancy_Score                                                          1.0   \n",
       "Answer Relevancy (ragas)_Score                                              0.98029   \n",
       "Faithfulness_Score                                                              1.0   \n",
       "Hallucination_Score                                                             0.0   \n",
       "Contextual Precision_Success                                                   True   \n",
       "Contextual Recall_Success                                                      True   \n",
       "Contextual Relevancy_Success                                                   True   \n",
       "Answer Relevancy_Success                                                       True   \n",
       "Answer Relevancy (ragas)_Success                                               True   \n",
       "Faithfulness_Success                                                           True   \n",
       "Hallucination_Success                                                          True   \n",
       "Contextual Precision_Reason       The score is 1.00 because all nodes in the ret...   \n",
       "Contextual Recall_Reason          The score is 1.00 because every sentence in th...   \n",
       "Contextual Relevancy_Reason       The score is 0.56 because while some statement...   \n",
       "Answer Relevancy_Reason           The score is 1.00 because the response is perf...   \n",
       "Answer Relevancy (ragas)_Reason                                                None   \n",
       "Faithfulness_Reason               The score is 1.00 because there are no contrad...   \n",
       "Hallucination_Reason              The score is 0.00 because the actual output al...   \n",
       "\n",
       "                                                                                  7  \\\n",
       "Input                             How have advancements in cellular and DNA rese...   \n",
       "Expected Output                   Advancements in cellular and DNA research have...   \n",
       "Actual Output                     Advancements in cellular and DNA research have...   \n",
       "Context                           [Biology is the study of living organisms, cov...   \n",
       "Retrieval Context                 [Biology is the study of living organisms, cov...   \n",
       "Success                                                                        True   \n",
       "Contextual Precision_Score                                                      1.0   \n",
       "Contextual Recall_Score                                                    0.666667   \n",
       "Contextual Relevancy_Score                                                      1.0   \n",
       "Answer Relevancy_Score                                                          1.0   \n",
       "Answer Relevancy (ragas)_Score                                             0.990291   \n",
       "Faithfulness_Score                                                              1.0   \n",
       "Hallucination_Score                                                             0.0   \n",
       "Contextual Precision_Success                                                   True   \n",
       "Contextual Recall_Success                                                      True   \n",
       "Contextual Relevancy_Success                                                   True   \n",
       "Answer Relevancy_Success                                                       True   \n",
       "Answer Relevancy (ragas)_Success                                               True   \n",
       "Faithfulness_Success                                                           True   \n",
       "Hallucination_Success                                                          True   \n",
       "Contextual Precision_Reason       The score is 1.00 because the node in the retr...   \n",
       "Contextual Recall_Reason          The score is 0.67 because the retrieval contex...   \n",
       "Contextual Relevancy_Reason       The score is 1.00 because the retrieval contex...   \n",
       "Answer Relevancy_Reason           The score is 1.00 because the output is perfec...   \n",
       "Answer Relevancy (ragas)_Reason                                                None   \n",
       "Faithfulness_Reason               The score is 1.00 because there are no contrad...   \n",
       "Hallucination_Reason              The score is 0.00 because the actual output fu...   \n",
       "\n",
       "                                                                                  8  \\\n",
       "Input                             How do plants convert sunlight into energy and...   \n",
       "Expected Output                   Plants convert sunlight into energy through ph...   \n",
       "Actual Output                     Plants convert sunlight into energy through th...   \n",
       "Context                           [Photosynthesis is the process plants use to c...   \n",
       "Retrieval Context                 [Photosynthesis is the process plants use to c...   \n",
       "Success                                                                        True   \n",
       "Contextual Precision_Score                                                      1.0   \n",
       "Contextual Recall_Score                                                        0.75   \n",
       "Contextual Relevancy_Score                                                 0.666667   \n",
       "Answer Relevancy_Score                                                          1.0   \n",
       "Answer Relevancy (ragas)_Score                                             0.948705   \n",
       "Faithfulness_Score                                                              1.0   \n",
       "Hallucination_Score                                                             0.0   \n",
       "Contextual Precision_Success                                                   True   \n",
       "Contextual Recall_Success                                                      True   \n",
       "Contextual Relevancy_Success                                                   True   \n",
       "Answer Relevancy_Success                                                       True   \n",
       "Answer Relevancy (ragas)_Success                                               True   \n",
       "Faithfulness_Success                                                           True   \n",
       "Hallucination_Success                                                          True   \n",
       "Contextual Precision_Reason       The score is 1.00 because the first node in th...   \n",
       "Contextual Recall_Reason          The score is 0.75 because while the nodes in r...   \n",
       "Contextual Relevancy_Reason       The score is 0.67 because while the relevant s...   \n",
       "Answer Relevancy_Reason           The score is 1.00 because the answer perfectly...   \n",
       "Answer Relevancy (ragas)_Reason                                                None   \n",
       "Faithfulness_Reason               The score is 1.00 because there are no contrad...   \n",
       "Hallucination_Reason              The score is 0.00 because there are no contrad...   \n",
       "\n",
       "                                                                                  9  \n",
       "Input                             How does NLP enhance language understanding an...  \n",
       "Expected Output                   NLP enhances language understanding by using t...  \n",
       "Actual Output                     NLP enhances language understanding by enablin...  \n",
       "Context                           [NLP is a branch of AI that enables computers ...  \n",
       "Retrieval Context                 [NLP is a branch of AI that enables computers ...  \n",
       "Success                                                                       False  \n",
       "Contextual Precision_Score                                                      1.0  \n",
       "Contextual Recall_Score                                                         1.0  \n",
       "Contextual Relevancy_Score                                                 0.333333  \n",
       "Answer Relevancy_Score                                                          1.0  \n",
       "Answer Relevancy (ragas)_Score                                             0.960904  \n",
       "Faithfulness_Score                                                              1.0  \n",
       "Hallucination_Score                                                             0.0  \n",
       "Contextual Precision_Success                                                   True  \n",
       "Contextual Recall_Success                                                      True  \n",
       "Contextual Relevancy_Success                                                  False  \n",
       "Answer Relevancy_Success                                                       True  \n",
       "Answer Relevancy (ragas)_Success                                               True  \n",
       "Faithfulness_Success                                                           True  \n",
       "Hallucination_Success                                                          True  \n",
       "Contextual Precision_Reason       The score is 1.00 because all the relevant nod...  \n",
       "Contextual Recall_Reason          The score is 1.00 because every sentence in th...  \n",
       "Contextual Relevancy_Reason       The score is 0.33 because while the retrieval ...  \n",
       "Answer Relevancy_Reason           The score is 1.00 because the response is perf...  \n",
       "Answer Relevancy (ragas)_Reason                                                None  \n",
       "Faithfulness_Reason               The score is 1.00 because there are no contrad...  \n",
       "Hallucination_Reason              The score is 0.00 because the actual output fu...  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "eval_results_df = pd.DataFrame(eval_metrics)\n",
    "eval_results_df.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Expected Output</th>\n",
       "      <th>Actual Output</th>\n",
       "      <th>Context</th>\n",
       "      <th>Retrieval Context</th>\n",
       "      <th>Success</th>\n",
       "      <th>Contextual Precision_Score</th>\n",
       "      <th>Contextual Recall_Score</th>\n",
       "      <th>Contextual Relevancy_Score</th>\n",
       "      <th>Answer Relevancy_Score</th>\n",
       "      <th>...</th>\n",
       "      <th>Answer Relevancy (ragas)_Success</th>\n",
       "      <th>Faithfulness_Success</th>\n",
       "      <th>Hallucination_Success</th>\n",
       "      <th>Contextual Precision_Reason</th>\n",
       "      <th>Contextual Recall_Reason</th>\n",
       "      <th>Contextual Relevancy_Reason</th>\n",
       "      <th>Answer Relevancy_Reason</th>\n",
       "      <th>Answer Relevancy (ragas)_Reason</th>\n",
       "      <th>Faithfulness_Reason</th>\n",
       "      <th>Hallucination_Reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In what ways do solar and wind energy investme...</td>\n",
       "      <td>Solar and wind energy investments contribute t...</td>\n",
       "      <td>Solar and wind energy investments contribute t...</td>\n",
       "      <td>[Renewable energy sources, such as solar and w...</td>\n",
       "      <td>[Renewable energy sources, such as solar and w...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>The score is 1.00 because the node in the retr...</td>\n",
       "      <td>The score is 1.00 because every sentence in th...</td>\n",
       "      <td>The score is 1.00 because the retrieval contex...</td>\n",
       "      <td>The score is 1.00 because the response is perf...</td>\n",
       "      <td>None</td>\n",
       "      <td>The score is 1.00 because there are no contrad...</td>\n",
       "      <td>The score is 0.00 because the actual output co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How do multi-layered neural networks contribut...</td>\n",
       "      <td>Multi-layered neural networks, such as convolu...</td>\n",
       "      <td>Multi-layered neural networks contribute to im...</td>\n",
       "      <td>[Deep learning is a subset of machine learning...</td>\n",
       "      <td>[Deep learning is a subset of machine learning...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>The score is 1.00 because the relevant node in...</td>\n",
       "      <td>The score is 0.50 because while the first sent...</td>\n",
       "      <td>The score is 0.50 because while the retrieval ...</td>\n",
       "      <td>The score is 1.00 because the response is full...</td>\n",
       "      <td>None</td>\n",
       "      <td>The score is 1.00 because there are no contrad...</td>\n",
       "      <td>The score is 0.00 because the actual output pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In what ways do the construction techniques an...</td>\n",
       "      <td>The construction techniques of the pyramids, p...</td>\n",
       "      <td>The context does not provide specific details ...</td>\n",
       "      <td>[Pyramids are ancient structures, often servin...</td>\n",
       "      <td>[Pyramids are ancient structures, often servin...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>The score is 1.00 because all relevant nodes i...</td>\n",
       "      <td>The score is 1.00 because all sentences in the...</td>\n",
       "      <td>The score is 1.00 because the context perfectl...</td>\n",
       "      <td>The score is 0.50 because while the output par...</td>\n",
       "      <td>None</td>\n",
       "      <td>The score is 1.00 because there are no contrad...</td>\n",
       "      <td>The score is 0.00 because the actual output do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What role do cryptographic methods and decentr...</td>\n",
       "      <td>Cryptographic methods in Bitcoin ensure secure...</td>\n",
       "      <td>Cryptographic methods ensure secure transactio...</td>\n",
       "      <td>[Cryptocurrency is a digital currency that use...</td>\n",
       "      <td>[Cryptocurrency is a digital currency that use...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>The score is 1.00 because the first node in th...</td>\n",
       "      <td>The score is 1.00 because all sentences in the...</td>\n",
       "      <td>The score is 1.00 because the context precisel...</td>\n",
       "      <td>The score is 1.00 because the response perfect...</td>\n",
       "      <td>None</td>\n",
       "      <td>The score is 1.00 because there are no contrad...</td>\n",
       "      <td>The score is 0.00 because the actual output al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In what ways do AI systems utilize data analys...</td>\n",
       "      <td>AI systems utilize data analysis by employing ...</td>\n",
       "      <td>AI systems utilize data analysis by employing ...</td>\n",
       "      <td>[Machine learning is a field of artificial int...</td>\n",
       "      <td>[Machine learning is a field of artificial int...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>The score is 1.00 because the relevant node, w...</td>\n",
       "      <td>The score is 1.00 because every sentence in th...</td>\n",
       "      <td>The score is 0.56 because while the relevant s...</td>\n",
       "      <td>The score is 1.00 because the response was per...</td>\n",
       "      <td>None</td>\n",
       "      <td>The score is 1.00 because there are no contrad...</td>\n",
       "      <td>The score is 0.00 because the actual output fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>In what ways do wave-particle duality and unce...</td>\n",
       "      <td>Wave-particle duality challenges classical phy...</td>\n",
       "      <td>Wave-particle duality and the uncertainty prin...</td>\n",
       "      <td>[Quantum mechanics is a branch of physics that...</td>\n",
       "      <td>[Quantum mechanics is a branch of physics that...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>The score is 1.00 because the node in retrieva...</td>\n",
       "      <td>The score is 1.00 because all sentences in the...</td>\n",
       "      <td>The score is 0.67 because while the retrieval ...</td>\n",
       "      <td>The score is 1.00 because the response perfect...</td>\n",
       "      <td>None</td>\n",
       "      <td>The score is 1.00 because there are no contrad...</td>\n",
       "      <td>The score is 0.00 because there are no contrad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>In what ways do AI applications like virtual a...</td>\n",
       "      <td>AI applications like virtual assistants and ro...</td>\n",
       "      <td>AI applications like virtual assistants and ro...</td>\n",
       "      <td>[Artificial intelligence refers to machines mi...</td>\n",
       "      <td>[Artificial intelligence refers to machines mi...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>The score is 1.00 because all nodes in the ret...</td>\n",
       "      <td>The score is 1.00 because every sentence in th...</td>\n",
       "      <td>The score is 0.56 because while some statement...</td>\n",
       "      <td>The score is 1.00 because the response is perf...</td>\n",
       "      <td>None</td>\n",
       "      <td>The score is 1.00 because there are no contrad...</td>\n",
       "      <td>The score is 0.00 because the actual output al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How have advancements in cellular and DNA rese...</td>\n",
       "      <td>Advancements in cellular and DNA research have...</td>\n",
       "      <td>Advancements in cellular and DNA research have...</td>\n",
       "      <td>[Biology is the study of living organisms, cov...</td>\n",
       "      <td>[Biology is the study of living organisms, cov...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>The score is 1.00 because the node in the retr...</td>\n",
       "      <td>The score is 0.67 because the retrieval contex...</td>\n",
       "      <td>The score is 1.00 because the retrieval contex...</td>\n",
       "      <td>The score is 1.00 because the output is perfec...</td>\n",
       "      <td>None</td>\n",
       "      <td>The score is 1.00 because there are no contrad...</td>\n",
       "      <td>The score is 0.00 because the actual output fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How do plants convert sunlight into energy and...</td>\n",
       "      <td>Plants convert sunlight into energy through ph...</td>\n",
       "      <td>Plants convert sunlight into energy through th...</td>\n",
       "      <td>[Photosynthesis is the process plants use to c...</td>\n",
       "      <td>[Photosynthesis is the process plants use to c...</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>The score is 1.00 because the first node in th...</td>\n",
       "      <td>The score is 0.75 because while the nodes in r...</td>\n",
       "      <td>The score is 0.67 because while the relevant s...</td>\n",
       "      <td>The score is 1.00 because the answer perfectly...</td>\n",
       "      <td>None</td>\n",
       "      <td>The score is 1.00 because there are no contrad...</td>\n",
       "      <td>The score is 0.00 because there are no contrad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>How does NLP enhance language understanding an...</td>\n",
       "      <td>NLP enhances language understanding by using t...</td>\n",
       "      <td>NLP enhances language understanding by enablin...</td>\n",
       "      <td>[NLP is a branch of AI that enables computers ...</td>\n",
       "      <td>[NLP is a branch of AI that enables computers ...</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>The score is 1.00 because all the relevant nod...</td>\n",
       "      <td>The score is 1.00 because every sentence in th...</td>\n",
       "      <td>The score is 0.33 because while the retrieval ...</td>\n",
       "      <td>The score is 1.00 because the response is perf...</td>\n",
       "      <td>None</td>\n",
       "      <td>The score is 1.00 because there are no contrad...</td>\n",
       "      <td>The score is 0.00 because the actual output fu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Input  \\\n",
       "0  In what ways do solar and wind energy investme...   \n",
       "1  How do multi-layered neural networks contribut...   \n",
       "2  In what ways do the construction techniques an...   \n",
       "3  What role do cryptographic methods and decentr...   \n",
       "4  In what ways do AI systems utilize data analys...   \n",
       "5  In what ways do wave-particle duality and unce...   \n",
       "6  In what ways do AI applications like virtual a...   \n",
       "7  How have advancements in cellular and DNA rese...   \n",
       "8  How do plants convert sunlight into energy and...   \n",
       "9  How does NLP enhance language understanding an...   \n",
       "\n",
       "                                     Expected Output  \\\n",
       "0  Solar and wind energy investments contribute t...   \n",
       "1  Multi-layered neural networks, such as convolu...   \n",
       "2  The construction techniques of the pyramids, p...   \n",
       "3  Cryptographic methods in Bitcoin ensure secure...   \n",
       "4  AI systems utilize data analysis by employing ...   \n",
       "5  Wave-particle duality challenges classical phy...   \n",
       "6  AI applications like virtual assistants and ro...   \n",
       "7  Advancements in cellular and DNA research have...   \n",
       "8  Plants convert sunlight into energy through ph...   \n",
       "9  NLP enhances language understanding by using t...   \n",
       "\n",
       "                                       Actual Output  \\\n",
       "0  Solar and wind energy investments contribute t...   \n",
       "1  Multi-layered neural networks contribute to im...   \n",
       "2  The context does not provide specific details ...   \n",
       "3  Cryptographic methods ensure secure transactio...   \n",
       "4  AI systems utilize data analysis by employing ...   \n",
       "5  Wave-particle duality and the uncertainty prin...   \n",
       "6  AI applications like virtual assistants and ro...   \n",
       "7  Advancements in cellular and DNA research have...   \n",
       "8  Plants convert sunlight into energy through th...   \n",
       "9  NLP enhances language understanding by enablin...   \n",
       "\n",
       "                                             Context  \\\n",
       "0  [Renewable energy sources, such as solar and w...   \n",
       "1  [Deep learning is a subset of machine learning...   \n",
       "2  [Pyramids are ancient structures, often servin...   \n",
       "3  [Cryptocurrency is a digital currency that use...   \n",
       "4  [Machine learning is a field of artificial int...   \n",
       "5  [Quantum mechanics is a branch of physics that...   \n",
       "6  [Artificial intelligence refers to machines mi...   \n",
       "7  [Biology is the study of living organisms, cov...   \n",
       "8  [Photosynthesis is the process plants use to c...   \n",
       "9  [NLP is a branch of AI that enables computers ...   \n",
       "\n",
       "                                   Retrieval Context  Success  \\\n",
       "0  [Renewable energy sources, such as solar and w...     True   \n",
       "1  [Deep learning is a subset of machine learning...     True   \n",
       "2  [Pyramids are ancient structures, often servin...    False   \n",
       "3  [Cryptocurrency is a digital currency that use...     True   \n",
       "4  [Machine learning is a field of artificial int...     True   \n",
       "5  [Quantum mechanics is a branch of physics that...     True   \n",
       "6  [Artificial intelligence refers to machines mi...     True   \n",
       "7  [Biology is the study of living organisms, cov...     True   \n",
       "8  [Photosynthesis is the process plants use to c...     True   \n",
       "9  [NLP is a branch of AI that enables computers ...    False   \n",
       "\n",
       "   Contextual Precision_Score  Contextual Recall_Score  \\\n",
       "0                         1.0                 1.000000   \n",
       "1                         1.0                 0.500000   \n",
       "2                         1.0                 1.000000   \n",
       "3                         1.0                 1.000000   \n",
       "4                         1.0                 1.000000   \n",
       "5                         1.0                 1.000000   \n",
       "6                         1.0                 1.000000   \n",
       "7                         1.0                 0.666667   \n",
       "8                         1.0                 0.750000   \n",
       "9                         1.0                 1.000000   \n",
       "\n",
       "   Contextual Relevancy_Score  Answer Relevancy_Score  ...  \\\n",
       "0                    1.000000                     1.0  ...   \n",
       "1                    0.500000                     1.0  ...   \n",
       "2                    1.000000                     0.5  ...   \n",
       "3                    1.000000                     1.0  ...   \n",
       "4                    0.555556                     1.0  ...   \n",
       "5                    0.666667                     1.0  ...   \n",
       "6                    0.555556                     1.0  ...   \n",
       "7                    1.000000                     1.0  ...   \n",
       "8                    0.666667                     1.0  ...   \n",
       "9                    0.333333                     1.0  ...   \n",
       "\n",
       "   Answer Relevancy (ragas)_Success  Faithfulness_Success  \\\n",
       "0                              True                  True   \n",
       "1                              True                  True   \n",
       "2                             False                  True   \n",
       "3                              True                  True   \n",
       "4                              True                  True   \n",
       "5                              True                  True   \n",
       "6                              True                  True   \n",
       "7                              True                  True   \n",
       "8                              True                  True   \n",
       "9                              True                  True   \n",
       "\n",
       "   Hallucination_Success                        Contextual Precision_Reason  \\\n",
       "0                   True  The score is 1.00 because the node in the retr...   \n",
       "1                   True  The score is 1.00 because the relevant node in...   \n",
       "2                   True  The score is 1.00 because all relevant nodes i...   \n",
       "3                   True  The score is 1.00 because the first node in th...   \n",
       "4                   True  The score is 1.00 because the relevant node, w...   \n",
       "5                   True  The score is 1.00 because the node in retrieva...   \n",
       "6                   True  The score is 1.00 because all nodes in the ret...   \n",
       "7                   True  The score is 1.00 because the node in the retr...   \n",
       "8                   True  The score is 1.00 because the first node in th...   \n",
       "9                   True  The score is 1.00 because all the relevant nod...   \n",
       "\n",
       "                            Contextual Recall_Reason  \\\n",
       "0  The score is 1.00 because every sentence in th...   \n",
       "1  The score is 0.50 because while the first sent...   \n",
       "2  The score is 1.00 because all sentences in the...   \n",
       "3  The score is 1.00 because all sentences in the...   \n",
       "4  The score is 1.00 because every sentence in th...   \n",
       "5  The score is 1.00 because all sentences in the...   \n",
       "6  The score is 1.00 because every sentence in th...   \n",
       "7  The score is 0.67 because the retrieval contex...   \n",
       "8  The score is 0.75 because while the nodes in r...   \n",
       "9  The score is 1.00 because every sentence in th...   \n",
       "\n",
       "                         Contextual Relevancy_Reason  \\\n",
       "0  The score is 1.00 because the retrieval contex...   \n",
       "1  The score is 0.50 because while the retrieval ...   \n",
       "2  The score is 1.00 because the context perfectl...   \n",
       "3  The score is 1.00 because the context precisel...   \n",
       "4  The score is 0.56 because while the relevant s...   \n",
       "5  The score is 0.67 because while the retrieval ...   \n",
       "6  The score is 0.56 because while some statement...   \n",
       "7  The score is 1.00 because the retrieval contex...   \n",
       "8  The score is 0.67 because while the relevant s...   \n",
       "9  The score is 0.33 because while the retrieval ...   \n",
       "\n",
       "                             Answer Relevancy_Reason  \\\n",
       "0  The score is 1.00 because the response is perf...   \n",
       "1  The score is 1.00 because the response is full...   \n",
       "2  The score is 0.50 because while the output par...   \n",
       "3  The score is 1.00 because the response perfect...   \n",
       "4  The score is 1.00 because the response was per...   \n",
       "5  The score is 1.00 because the response perfect...   \n",
       "6  The score is 1.00 because the response is perf...   \n",
       "7  The score is 1.00 because the output is perfec...   \n",
       "8  The score is 1.00 because the answer perfectly...   \n",
       "9  The score is 1.00 because the response is perf...   \n",
       "\n",
       "   Answer Relevancy (ragas)_Reason  \\\n",
       "0                             None   \n",
       "1                             None   \n",
       "2                             None   \n",
       "3                             None   \n",
       "4                             None   \n",
       "5                             None   \n",
       "6                             None   \n",
       "7                             None   \n",
       "8                             None   \n",
       "9                             None   \n",
       "\n",
       "                                 Faithfulness_Reason  \\\n",
       "0  The score is 1.00 because there are no contrad...   \n",
       "1  The score is 1.00 because there are no contrad...   \n",
       "2  The score is 1.00 because there are no contrad...   \n",
       "3  The score is 1.00 because there are no contrad...   \n",
       "4  The score is 1.00 because there are no contrad...   \n",
       "5  The score is 1.00 because there are no contrad...   \n",
       "6  The score is 1.00 because there are no contrad...   \n",
       "7  The score is 1.00 because there are no contrad...   \n",
       "8  The score is 1.00 because there are no contrad...   \n",
       "9  The score is 1.00 because there are no contrad...   \n",
       "\n",
       "                                Hallucination_Reason  \n",
       "0  The score is 0.00 because the actual output co...  \n",
       "1  The score is 0.00 because the actual output pe...  \n",
       "2  The score is 0.00 because the actual output do...  \n",
       "3  The score is 0.00 because the actual output al...  \n",
       "4  The score is 0.00 because the actual output fu...  \n",
       "5  The score is 0.00 because there are no contrad...  \n",
       "6  The score is 0.00 because the actual output al...  \n",
       "7  The score is 0.00 because the actual output fu...  \n",
       "8  The score is 0.00 because there are no contrad...  \n",
       "9  The score is 0.00 because the actual output fu...  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c80ff06a-1207-47bb-8713-27050f782c22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 355
    },
    "id": "pROkSYPUgRse",
    "outputId": "d9834373-7009-467e-d8fe-92e801aa4886"
   },
   "outputs": [],
   "source": [
    "eval_results_df[['Contextual Precision_Score', 'Contextual Recall_Score', 'Contextual Relevancy_Score',\n",
    "                 'Answer Relevancy_Score', 'Answer Relevancy (ragas)_Score',\n",
    "                 'Faithfulness_Score', 'Hallucination_Score']].describe()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "M7_End_to_End_RAG_System_Evaluation",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00ef1659ddf440ac829bc99c0dcb1baf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b3a2dc7dbf94a068ac59a1c71b393f6",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_ae849ff42adb4cfc9a82c45a28da07a8",
      "value": "Evaluating:‚Äá100%"
     }
    },
    "02165f6fcfb74fafb5206b582f628a93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3687d4444143421eae1d8c8231bf952d",
       "IPY_MODEL_51a81caf430147789513fc3485416b33",
       "IPY_MODEL_903e7d454cdc48979146cc88183042d7"
      ],
      "layout": "IPY_MODEL_c2f096e13f164acab1a66d96659249bd"
     }
    },
    "024d803bdab24516b6770b101969b8e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9dd4eebc151451085de50702f21a311",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_6caddec7dc934425bf56010398936537",
      "value": "Evaluating:‚Äá100%"
     }
    },
    "0566c23e5037436e97b5178282b12628": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4ab47828042947ceb874f360a728d2e9",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_88ec20625df54005a0e6623af57f0b9d",
      "value": "Evaluating:‚Äá100%"
     }
    },
    "072bdd9321e644cc8f25c2749339e083": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "079bf0f9293c43d988315ee189ff7c73": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "091f150610b0474c8b4227706e6c3878": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0b3242c9b3ef4964aa9578af5775a396": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c9ed88787be4036a623d4a7088c40b8",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_2b4046d510a34e38bdd095ca905abc9b",
      "value": "Evaluating:‚Äá100%"
     }
    },
    "0c7afd75619d43c4b2debae90e9adc2d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d8b6013a8734c3cb2848eee9e7597ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "14f35227c96342dba5aa8b0db9cdabf0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "153226563d454cbd92ed327d61cbcf68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_59275c721a1849e58c3efc0c339f8954",
       "IPY_MODEL_5ca4e01efe6d44eea9d60e5b9c9080c2",
       "IPY_MODEL_3aee75144e004e8dbcfe75abc6762208"
      ],
      "layout": "IPY_MODEL_ba7fd441525a45efb8d4bce5a7362a03"
     }
    },
    "183cf676e13d470c9c0db082b89256ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "19d664186c594a5a81be22093ea94717": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1b3a2dc7dbf94a068ac59a1c71b393f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e14a7aa053449f29d94620f654b8fdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_90441504bc7b44898eabe5b78fb6a5ec",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e7e2ef49e4b44aec89fa39ed9799cf59",
      "value": 1
     }
    },
    "20174965e93c4d9e96a8b2567cda17cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "28fd1350a29149148a0083ff151ee2b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2b4046d510a34e38bdd095ca905abc9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2b53bc9dbfe84a83beec08350f953df4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c9ed88787be4036a623d4a7088c40b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3483a09e68ad423d8285c88b0023c0da": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8b64ddd749fe4d14bc15b0bf89c698ed",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_af2ae9a883e64c6bbed599f54b6c6915",
      "value": "‚Äá1/1‚Äá[00:35&lt;00:00,‚Äá35.59s/it]"
     }
    },
    "3687d4444143421eae1d8c8231bf952d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a3c0b9000c3b4789b7a157459d4bd9c1",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_c8a18774fec54c0cb290edf5ffeb7c1a",
      "value": "Evaluating:‚Äá100%"
     }
    },
    "3772f26e95a3478894125d474a1bd5e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3aee75144e004e8dbcfe75abc6762208": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b53bc9dbfe84a83beec08350f953df4",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_19d664186c594a5a81be22093ea94717",
      "value": "‚Äá1/1‚Äá[00:34&lt;00:00,‚Äá34.01s/it]"
     }
    },
    "3c147e908b1b49fbb52d6820495afab7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4113a8c3d98d4ac6a55cb7d887fa530c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "42a91d50bb494be785a10dc07e64c57d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4380c3157b2641949101c333de2860c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_00ef1659ddf440ac829bc99c0dcb1baf",
       "IPY_MODEL_d8b78b5823ad4efd9be2be03346d3009",
       "IPY_MODEL_9c6494c628cd4f33a41869f5044e1567"
      ],
      "layout": "IPY_MODEL_77814ee8e544404fa75ab09334721d43"
     }
    },
    "48b6fa2757de4c9aa48c429234552b7a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ab47828042947ceb874f360a728d2e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d02d332124e489194212dd05a80af68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d7f50e073df423b9e10770933466576",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_b64d491c187c4506942bd5ecb013d313",
      "value": "‚Äá1/1‚Äá[00:37&lt;00:00,‚Äá37.09s/it]"
     }
    },
    "4d46735abc034aa3817f3ef7bd70a0e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4d7f50e073df423b9e10770933466576": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4deb2d112aa4427488bc32582289caa0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4fcb9e84ee2e4e909f34f4a8fa403ca2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "51a81caf430147789513fc3485416b33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_079bf0f9293c43d988315ee189ff7c73",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3772f26e95a3478894125d474a1bd5e3",
      "value": 1
     }
    },
    "55c66431dcad49088e1c81e2f1a59d68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6b789175b58a413d8b4eeb4200854d7f",
       "IPY_MODEL_66872cc0ee164caca99347f90386044b",
       "IPY_MODEL_6d9cd0ea46f34a9faed020f53ada73ab"
      ],
      "layout": "IPY_MODEL_6a52685481b54fcc9521f61e5d50119f"
     }
    },
    "58a73767e7e34033b80fc8ff6dccd644": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4113a8c3d98d4ac6a55cb7d887fa530c",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_89bfda1f10344e03a5f132feea2c9bfb",
      "value": 1
     }
    },
    "59275c721a1849e58c3efc0c339f8954": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c147e908b1b49fbb52d6820495afab7",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_9fddccfcf6a843e69bf3b1e631aca9e1",
      "value": "Evaluating:‚Äá100%"
     }
    },
    "5ca4e01efe6d44eea9d60e5b9c9080c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eeae6addc36447bd9c82d2b4b4fa99bb",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_69f10456c157455d8a7ec9fd9cdf28f6",
      "value": 1
     }
    },
    "5ca5882b64ac4dafb27da9189802d36c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_88bcb61cb34e4cdaae01127aaa76fb07",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fae02453a4164ba39f26445cc1a01a72",
      "value": 1
     }
    },
    "60422854823d4a1cb19377f25a12ec51": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "613a3541acae40d38eb8898a78acb445": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0b3242c9b3ef4964aa9578af5775a396",
       "IPY_MODEL_5ca5882b64ac4dafb27da9189802d36c",
       "IPY_MODEL_e53c7c33e8d244c3ab1f3a29318e0bcf"
      ],
      "layout": "IPY_MODEL_072bdd9321e644cc8f25c2749339e083"
     }
    },
    "654a300e0e624582aad9ce36720cc8d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ba82e24b119d4eb086248ba70f6adcba",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_20174965e93c4d9e96a8b2567cda17cf",
      "value": 1
     }
    },
    "66872cc0ee164caca99347f90386044b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6fb30db42d5b49418fdf8de0fad705a9",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a35b24a41e5748b8930fa70d6e795504",
      "value": 1
     }
    },
    "66e0a0826a434c8db7f356c1a5aa8575": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "67554dce2ed147daa1e1f6887b706256": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9fee5fde75c34cd6999b57d4374dd9c7",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_28fd1350a29149148a0083ff151ee2b1",
      "value": "‚Äá1/1‚Äá[00:31&lt;00:00,‚Äá31.89s/it]"
     }
    },
    "69f10456c157455d8a7ec9fd9cdf28f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6a52685481b54fcc9521f61e5d50119f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6b789175b58a413d8b4eeb4200854d7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60422854823d4a1cb19377f25a12ec51",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_a3dca1dc3d3045e79587e5593e0ea74f",
      "value": "Evaluating:‚Äá100%"
     }
    },
    "6caddec7dc934425bf56010398936537": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6d9cd0ea46f34a9faed020f53ada73ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ce21520c9bac4044a25157662b091a11",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_66e0a0826a434c8db7f356c1a5aa8575",
      "value": "‚Äá1/1‚Äá[00:22&lt;00:00,‚Äá22.26s/it]"
     }
    },
    "6fb30db42d5b49418fdf8de0fad705a9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "77814ee8e544404fa75ab09334721d43": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78edb9b2b80c483ab1d65a5e6ac7b00c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0566c23e5037436e97b5178282b12628",
       "IPY_MODEL_a6768074f3ea4cb4b6bf34fd3ec588d2",
       "IPY_MODEL_4d02d332124e489194212dd05a80af68"
      ],
      "layout": "IPY_MODEL_a73d64e7f0d64d3ab8e7c626193f44f9"
     }
    },
    "7a4b4375488a447b9f483798173b5560": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48b6fa2757de4c9aa48c429234552b7a",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_89c18cb46f564cb8b4d390cdb75e27a1",
      "value": "Evaluating:‚Äá100%"
     }
    },
    "7f3fa03415044d79b0db289024d882de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88bcb61cb34e4cdaae01127aaa76fb07": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88ec20625df54005a0e6623af57f0b9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "89bfda1f10344e03a5f132feea2c9bfb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "89c18cb46f564cb8b4d390cdb75e27a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8b64ddd749fe4d14bc15b0bf89c698ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "903e7d454cdc48979146cc88183042d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_42a91d50bb494be785a10dc07e64c57d",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_091f150610b0474c8b4227706e6c3878",
      "value": "‚Äá1/1‚Äá[00:24&lt;00:00,‚Äá24.16s/it]"
     }
    },
    "90441504bc7b44898eabe5b78fb6a5ec": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "915a91064f44458eac9dee659df36362": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7a4b4375488a447b9f483798173b5560",
       "IPY_MODEL_654a300e0e624582aad9ce36720cc8d3",
       "IPY_MODEL_d3d5b7ec3dd64df69f6b17dd3fb1188e"
      ],
      "layout": "IPY_MODEL_c9e569343f6a4cb1b100356cfd56c617"
     }
    },
    "92df8d04435244659d3a4b4773d619e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d46735abc034aa3817f3ef7bd70a0e6",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_fae240f399c44cbd9bb14e2d0ce24013",
      "value": "‚Äá1/1‚Äá[00:28&lt;00:00,‚Äá28.64s/it]"
     }
    },
    "945dfa6461a14d0a99a207a600be9f99": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f7d70159f003466996088b318a7ed06d",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f01d72a1d5514dc1a6c35f95cdb04c78",
      "value": "Evaluating:‚Äá100%"
     }
    },
    "968da5427c57445fa41933ad7aec061a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9be2346fdf034f3fae44bae5649ea544": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_945dfa6461a14d0a99a207a600be9f99",
       "IPY_MODEL_58a73767e7e34033b80fc8ff6dccd644",
       "IPY_MODEL_3483a09e68ad423d8285c88b0023c0da"
      ],
      "layout": "IPY_MODEL_9bf97bf583fd4b6f9b8dbe7667d56863"
     }
    },
    "9bf97bf583fd4b6f9b8dbe7667d56863": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c6494c628cd4f33a41869f5044e1567": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4deb2d112aa4427488bc32582289caa0",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_ed63af1291e140b68eb813f6525f4f88",
      "value": "‚Äá1/1‚Äá[00:17&lt;00:00,‚Äá17.35s/it]"
     }
    },
    "9eeb2fb2fa444982acf1e9b95e95703e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9fddccfcf6a843e69bf3b1e631aca9e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9fee5fde75c34cd6999b57d4374dd9c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a336914f145e42c0a1df04bfb0aa0f61": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a35b24a41e5748b8930fa70d6e795504": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a3c0b9000c3b4789b7a157459d4bd9c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a3dca1dc3d3045e79587e5593e0ea74f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a6768074f3ea4cb4b6bf34fd3ec588d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a336914f145e42c0a1df04bfb0aa0f61",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0d8b6013a8734c3cb2848eee9e7597ff",
      "value": 1
     }
    },
    "a73d64e7f0d64d3ab8e7c626193f44f9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae849ff42adb4cfc9a82c45a28da07a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "af2ae9a883e64c6bbed599f54b6c6915": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "af5f81ba63744f48969b6230f0e1196d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d76b5cc2bf724998afecba83dd9917c2",
       "IPY_MODEL_bf94afe4446b49b78c325ed123805c29",
       "IPY_MODEL_92df8d04435244659d3a4b4773d619e2"
      ],
      "layout": "IPY_MODEL_db9c163fe2674abf94bf676d6ca94f0e"
     }
    },
    "b64d491c187c4506942bd5ecb013d313": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ba7fd441525a45efb8d4bce5a7362a03": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba82e24b119d4eb086248ba70f6adcba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb9a2dedfed946069909eac89cd5fb0e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf93a40cc97f439b82bc2e51478e56d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf94afe4446b49b78c325ed123805c29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_db86b4cba7b4402fa8563922ca6e9908",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_14f35227c96342dba5aa8b0db9cdabf0",
      "value": 1
     }
    },
    "c2f096e13f164acab1a66d96659249bd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8a18774fec54c0cb290edf5ffeb7c1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c9dd4eebc151451085de50702f21a311": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9e569343f6a4cb1b100356cfd56c617": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ce21520c9bac4044a25157662b091a11": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3d5b7ec3dd64df69f6b17dd3fb1188e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c7afd75619d43c4b2debae90e9adc2d",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_bf93a40cc97f439b82bc2e51478e56d1",
      "value": "‚Äá1/1‚Äá[00:28&lt;00:00,‚Äá28.27s/it]"
     }
    },
    "d76b5cc2bf724998afecba83dd9917c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_968da5427c57445fa41933ad7aec061a",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_183cf676e13d470c9c0db082b89256ff",
      "value": "Evaluating:‚Äá100%"
     }
    },
    "d8b78b5823ad4efd9be2be03346d3009": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb9a2dedfed946069909eac89cd5fb0e",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d9a4a518fd8642598f5f51bb5d3c3091",
      "value": 1
     }
    },
    "d9a4a518fd8642598f5f51bb5d3c3091": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "db86b4cba7b4402fa8563922ca6e9908": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db9c163fe2674abf94bf676d6ca94f0e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e53c7c33e8d244c3ab1f3a29318e0bcf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f3fa03415044d79b0db289024d882de",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_4fcb9e84ee2e4e909f34f4a8fa403ca2",
      "value": "‚Äá1/1‚Äá[00:32&lt;00:00,‚Äá32.50s/it]"
     }
    },
    "e7e2ef49e4b44aec89fa39ed9799cf59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ed63af1291e140b68eb813f6525f4f88": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "eeae6addc36447bd9c82d2b4b4fa99bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f01d72a1d5514dc1a6c35f95cdb04c78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f7d70159f003466996088b318a7ed06d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fae02453a4164ba39f26445cc1a01a72": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fae240f399c44cbd9bb14e2d0ce24013": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ff0b25a6b0364081907ec87b853ea6a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_024d803bdab24516b6770b101969b8e1",
       "IPY_MODEL_1e14a7aa053449f29d94620f654b8fdd",
       "IPY_MODEL_67554dce2ed147daa1e1f6887b706256"
      ],
      "layout": "IPY_MODEL_9eeb2fb2fa444982acf1e9b95e95703e"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
