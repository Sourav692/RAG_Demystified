{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a212a86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run setup.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4dfc17",
   "metadata": {},
   "source": [
    "### YouTube Transcript Loader\n",
    "You can get the transcript from any YouTube link. First, you have to install the given libraries. If you want to keep the video information like title, and description in the documents, then keep add_video_info=True Otherwise keep False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44a8850b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade -qq  youtube-transcript-api\n",
    "%pip install --upgrade -qq  pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f34eb45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytube in /Users/sourav.banerjee/Documents/My Codebases/GenerativAI_Demystified/venv/lib/python3.11/site-packages (15.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2dc872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without Video Info: [Document(metadata={'source': 'LAfrShnpVIk'}, page_content=\"when using chat GPT you most probably have encountered responses like I'm sorry but as of my last knowledge update in January 2022 Etc or even responses that are not true at all this is where rag comes into play and says let me help you by injecting more knowledge or content into your interactions with an llm and help it answer the unknown and upcoming questions we hear llms prompts and rag Everywhere by now I think most of us know what an llm and the prompt is but did you know that right now rag is just as important as both of these and Powers most applications you may use involving a chatbot I recently did a poll on the learn AI together Discord Community to find out if people had already studied created or used rag applications and most voted to understand what rag is used for rag is as important as your coursebook for success in a class so understanding what it is is highly relevant in AI an llm or a large language mode model is just an AI model trained on language to talk with humans like GPT 4 used in ch GPT a prompt is simply your interaction with it it's the question you ask it but if you are experiencing issues like hallucinations or biases using such a language model or llm then rag or retrieval augmented Generations comes into play Let's quickly clarify hallucinations first it's when the model returns random things that seems true but aren't simply because it doesn't know the answer in fact a language model is constantly hallucinating it only predicts words in a statistical way it turns out that when they are trained with the entire internet there are so many examples that they manage to accurately predict the next logical words to answer most questions despite this it hallucinates it doesn't really understand what it's talking about and just outputs one word at a time that is probable what is incredible is that most of these hallucinations are actually true and answer our questions however some of them are real hallucinations of fabricated facts or scenarios and that can cause quite a few problems if they are not sufficiently controlled while there are several reasons why llms hallucinate it is mostly because they lack relevant context either because they cannot find the relevant data or don't know which data to refer to for a particular question this is because they were trained to answer and not to say I don't know rag solves this by automatically adding more knowledge or content into your interactions with an llm put simply you have a data set which is required and you use it to help the llm answer the unknown and upcoming user questions this is the simplest form and requires a few steps to make it work but this is the gist of a rag based system you have a user question that is sent to an automatic search in the database for finding relevant information which is then used back along with the question to give back an answer to the user as you can see with frag we use context from the user question question and our knowledge base to answer it this helps with grounding our model to the knowledge we control making it safer and aligned the disadvantage is limiting our answers to our knowledge base which is finite and probably not as big as the Internet it's just like an open book exam you would have in school you already have access to most answers and simply need to know where it is in your knowledge base if you find the answer in the manual it's quite hard to fail the question and write something wrong Jerry Leu CEO of L index gave a very interesting view on how to see rag in my most recent podcast with him if you think about it rag is basically prompt engineering because you're basically figuring out a way to put context into the prompt uh it's just a programmatic way of prompt engineering it's a way of prompting so that you actually get back um some contacts he also said to subscribe to the channel to learn more about AI okay maybe that's just a hallucination actually but you should still do it honestly in rag you first need data or knowledge which can be in the form of documentation but books articles Etc and only allow the llm to search and respond if the answer to the question is inside this knowledge base you have anyways if you have access to accurate information in your school manual why would you try to come up with something different Instead This is currently the best way to control your outputs and make your model safer and aligned basically the best way to ensure you will give the right answer and get your best grade for example we recently built an AI tutor to answer AI related questions we wanted accurate responses for our students both in terms of accuracy to give the right answer and in terms of relevancy so upto-date information with rag you can simply update your database if things have changed there's no big deal if the whole pytorch Library had a big update yesterday scrape it again and update your data set in a second and voila you don't have to retrain the whole model or wait for a gp4 to finally update the noledge card update the overall process of the butt is quite straightforward we validate the question answering it is related to Ai and that our chatbot should answer it then we search in our database to find good and relevant sources and finally use chat GPT to digest those sources and give a good answer for the student if you need safe information from an AI chat but like a medical assistant a tutor a lawyer or an accent you will be using rag for sure well maybe not if you're listening in 2030 but as of now rag is by far the best and safest approach to using a chatbot where you need to give factual and accurate information to build a rag based chatbot or application like our AI tutor we start by ingesting all our data into memory this is done by splitting all the content into chunks of text so split our textual data into fixed or flexible parts for example 500 character parts and processing it to an embedding model like open AI text embedding Adda model this will produce embeddings that are just vectors of numbers repres representing your text it will facilitate your life and allow you to compare text together easily you can save those vectors in a memory then for a new question from a particular user you can repeat this process and answer this means embedding the question using the same approach and compare it with all your current embeddings in your memory here you are basically looking for the most probable answer for this question searching in your memory just like you do for an exam looking through the chapters to find a title that seems relevant to the current exam question once it finds the most similar embedding chat GPT is asked to understand the user's question and intent and only use the retrieved sources of knowledge to answer the question this is how rag reduces hallucination risks and allows you to have upto-date information since you can update your knowledge base as much as you want and chat gbt or your current language model simply picks information from it to answer plus as you see it cites all sources it found on question for you to dive in and learn more which is also a plus when you're trying to learn and understand a new topic then there are still many things to consider like how to determine when to answer a question or not if it is relevant or in your documentation understand new terms or acronyms not in chat gpt's knowledge base find the relevant information more efficiently and accurately etc those concerns are all things we've improved through using various techniques like better chunking methods rank ERS query expansion agents and more that you can learn about in our free Advanced rag course we've built together with toi and active Loop that I Linked In the description below before some of you may ask yes an alternative to rag would be to fine-tune your model on your specific task basically to further train a model on your own data to make it more specific and ingest the knowledge you have rather than always searching in it like memorizing the book before the exam instead of bringing it with you I have a video comparing fine tuning and rag to teach you when you should consider each but in short rag stays relevant with or without fine tuning as it is much cheaper to build and is better to reduce undesired hallucinations as you force the model to give answers based on documentation you control and not simply things it ingested and hopefully will regurgitate correctly as in fine tune models coming back to our open book exams is just like professors making you focus on understanding the core matter and logic and not the knowledge itself as you can always find it in manuals or on Google same here for llms and complimenting them with rag plus even though those models have much better memories than us they are not perfect and they will not retain all the information you give them thus even with a fine tune model on hyp specific data rag remains something worth leveraging before we end this video I just wanted to mention that we discussed both these Topics in depth with coding examples in our llm and rag courses if you want to put this knowledge into practice the link is in the description below and they are completely free I hope you've enjoyed this video and that it helps you understand the goals and principles of rag better if you did please share it with a friend or your network to spread the know Edge and help the channel grow thank you for [Music] watching [Music]\")]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "\n",
    "loader = YoutubeLoader.from_youtube_url(\n",
    "    \"https://www.youtube.com/watch?v=LAfrShnpVIk\",\n",
    "    add_video_info=False,\n",
    ")\n",
    "\n",
    "result = loader.load()\n",
    "print(f\"Without Video Info: {result}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71b1c64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ SSL certificate bypass configured for YouTube API access\n"
     ]
    }
   ],
   "source": [
    "# üîß SSL Certificate Fix for YouTube API Access\n",
    "# This addresses the common SSL certificate verification error when accessing YouTube\n",
    "\n",
    "import ssl\n",
    "import urllib.request\n",
    "\n",
    "def setup_ssl_bypass():\n",
    "    \"\"\"Setup SSL context to bypass certificate verification for YouTube API access.\"\"\"\n",
    "    try:\n",
    "        # Create unverified SSL context\n",
    "        _create_unverified_https_context = ssl._create_unverified_context\n",
    "    except AttributeError:\n",
    "        # Legacy Python that doesn't verify HTTPS certificates by default\n",
    "        pass\n",
    "    else:\n",
    "        # Handle target environment that doesn't support HTTPS verification\n",
    "        ssl._create_default_https_context = _create_unverified_https_context\n",
    "    \n",
    "    print(\"‚úÖ SSL certificate bypass configured for YouTube API access\")\n",
    "\n",
    "# Apply the SSL bypass\n",
    "setup_ssl_bypass()\n",
    "\n",
    "# Additional SSL configuration for pytube\n",
    "import os\n",
    "os.environ['PYTHONHTTPSVERIFY'] = '0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90ef5018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Attempt 1/3 - Loading YouTube video with info...\n",
      "‚ùå Other URL error: HTTP Error 400: Bad Request\n",
      "‚ùå Final error: HTTP Error 400: Bad Request\n",
      "üí° Try restarting the kernel or use transcript-only mode\n"
     ]
    }
   ],
   "source": [
    "# Enhanced YouTube loader with SSL error handling\n",
    "from urllib.error import URLError\n",
    "import ssl\n",
    "\n",
    "def load_youtube_with_info(url, max_retries=3):\n",
    "    \"\"\"Load YouTube video with info, handling SSL errors gracefully.\"\"\"\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"üîÑ Attempt {attempt + 1}/{max_retries} - Loading YouTube video with info...\")\n",
    "            \n",
    "            loader = YoutubeLoader.from_youtube_url(\n",
    "                url,\n",
    "                add_video_info=True,\n",
    "            )\n",
    "            result = loader.load()\n",
    "            print(\"‚úÖ Successfully loaded YouTube video with metadata!\")\n",
    "            return result\n",
    "            \n",
    "        except URLError as e:\n",
    "            if \"CERTIFICATE_VERIFY_FAILED\" in str(e):\n",
    "                print(f\"‚ö†Ô∏è  SSL Certificate error on attempt {attempt + 1}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    print(\"üîß Applying additional SSL bypass...\")\n",
    "                    # Apply more aggressive SSL bypass\n",
    "                    import ssl\n",
    "                    ssl._create_default_https_context = ssl._create_unverified_context\n",
    "                    continue\n",
    "                else:\n",
    "                    print(\"‚ùå SSL issues persist. Falling back to transcript-only mode...\")\n",
    "                    # Fallback to transcript only\n",
    "                    loader = YoutubeLoader.from_youtube_url(url, add_video_info=False)\n",
    "                    result = loader.load()\n",
    "                    print(\"‚úÖ Successfully loaded transcript (without video metadata)\")\n",
    "                    return result\n",
    "            else:\n",
    "                print(f\"‚ùå Other URL error: {e}\")\n",
    "                raise\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Unexpected error on attempt {attempt + 1}: {e}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                print(\"üîÑ Falling back to transcript-only mode...\")\n",
    "                loader = YoutubeLoader.from_youtube_url(url, add_video_info=False)\n",
    "                result = loader.load()\n",
    "                print(\"‚úÖ Successfully loaded transcript (without video metadata)\")\n",
    "                return result\n",
    "\n",
    "# Test the enhanced loader\n",
    "try:\n",
    "    result = load_youtube_with_info(\"https://www.youtube.com/watch?v=ZL-cwYRMPjI\")\n",
    "    print(f\"\\nüìä Results Summary:\")\n",
    "    print(f\"   - Number of documents: {len(result)}\")\n",
    "    print(f\"   - Document metadata: {result[0].metadata}\")\n",
    "    print(f\"   - Content preview: {result[0].page_content[:200]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Final error: {e}\")\n",
    "    print(\"üí° Try restarting the kernel or use transcript-only mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ba449f",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### üîß SSL Certificate Troubleshooting for YouTube Loader\n",
    "\n",
    "If you encounter SSL certificate verification errors when using `YoutubeLoader` with `add_video_info=True`, here's what's happening and how to fix it:\n",
    "\n",
    "#### **Problem:**\n",
    "```\n",
    "URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate>\n",
    "```\n",
    "\n",
    "#### **Root Cause:**\n",
    "- The `pytube` library (used internally by `YoutubeLoader`) needs to access YouTube's API to fetch video metadata\n",
    "- macOS and some environments have SSL certificate verification issues with Python's urllib\n",
    "- This only affects video metadata fetching, not transcript loading\n",
    "\n",
    "#### **Solutions Applied:**\n",
    "\n",
    "1. **SSL Certificate Bypass:** The cell above configures Python to bypass SSL verification for HTTPS requests\n",
    "2. **Environment Variable:** Sets `PYTHONHTTPSVERIFY=0` to disable SSL verification\n",
    "3. **Graceful Fallback:** Enhanced loader automatically falls back to transcript-only mode if SSL issues persist\n",
    "\n",
    "#### **Alternative Solutions:**\n",
    "\n",
    "If you still encounter issues, try these manual fixes:\n",
    "\n",
    "1. **Use transcript-only mode:**\n",
    "   ```python\n",
    "   loader = YoutubeLoader.from_youtube_url(url, add_video_info=False)\n",
    "   ```\n",
    "\n",
    "2. **Install certificates (macOS):**\n",
    "   ```bash\n",
    "   /Applications/Python\\ 3.11/Install\\ Certificates.command\n",
    "   ```\n",
    "\n",
    "3. **Update certificates:**\n",
    "   ```bash\n",
    "   pip install --upgrade certifi\n",
    "   ```\n",
    "\n",
    "4. **Restart kernel:** Sometimes the SSL context needs a fresh start\n",
    "\n",
    "#### **Notes:**\n",
    "- SSL bypass is **only for development/testing** environments\n",
    "- For production, prefer proper certificate configuration\n",
    "- The enhanced loader above handles these issues automatically\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b857ed51",
   "metadata": {},
   "source": [
    "If you want to format the Transcripts, you can do it through the TranscriptFormat class. Here I have created the documents where each document will contain the transcript of 10-second contexts from the video. You can customize it in your desired format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5324feb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì∫ Loading YouTube transcript in 10-second chunks...\n",
      "‚úÖ Successfully loaded 16 transcript chunks\n",
      "\n",
      "üìä Transcript Summary:\n",
      "   - Total chunks: 16\n",
      "   - Sample metadata: {'source': 'https://www.youtube.com/watch?v=TKCMw0utiak&t=0s', 'start_seconds': 0, 'start_timestamp': '00:00:00'}\n",
      "\n",
      "üî§ First few chunks:\n",
      "==================================================\n",
      "üìÑ Chunk 1:\n",
      "   Content: ‚ô™ Hail to the victors valiant ‚ô™\n",
      "   Metadata: {'source': 'https://www.youtube.com/watch?v=TKCMw0utiak&t=0s', 'start_seconds': 0, 'start_timestamp': '00:00:00'}\n",
      "------------------------------\n",
      "üìÑ Chunk 2:\n",
      "   Content: ‚ô™ Hail to the conquering heroes ‚ô™ ‚ô™ Hail, hail to Michigan ‚ô™\n",
      "   Metadata: {'source': 'https://www.youtube.com/watch?v=TKCMw0utiak&t=10s', 'start_seconds': 10, 'start_timestamp': '00:00:10'}\n",
      "------------------------------\n",
      "üìÑ Chunk 3:\n",
      "   Content: ‚ô™ The leaders and best ‚ô™\n",
      "   Metadata: {'source': 'https://www.youtube.com/watch?v=TKCMw0utiak&t=20s', 'start_seconds': 20, 'start_timestamp': '00:00:20'}\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# üìë YouTube Transcript with Custom Formatting\n",
    "from langchain_community.document_loaders.youtube import TranscriptFormat\n",
    "\n",
    "def load_youtube_transcript_chunks(url, chunk_size_seconds=10):\n",
    "    \"\"\"Load YouTube transcript in formatted chunks.\"\"\"\n",
    "    try:\n",
    "        print(f\"üì∫ Loading YouTube transcript in {chunk_size_seconds}-second chunks...\")\n",
    "        \n",
    "        loader = YoutubeLoader.from_youtube_url(\n",
    "            url,\n",
    "            add_video_info=False,  # Use False to avoid SSL issues\n",
    "            transcript_format=TranscriptFormat.CHUNKS,\n",
    "            chunk_size_seconds=chunk_size_seconds,\n",
    "        )\n",
    "        \n",
    "        documents = loader.load()\n",
    "        print(f\"‚úÖ Successfully loaded {len(documents)} transcript chunks\")\n",
    "        \n",
    "        return documents\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading transcript: {e}\")\n",
    "        return []\n",
    "\n",
    "# Load and display formatted transcript\n",
    "documents = load_youtube_transcript_chunks(\"https://www.youtube.com/watch?v=TKCMw0utiak\")\n",
    "\n",
    "if documents:\n",
    "    print(f\"\\nüìä Transcript Summary:\")\n",
    "    print(f\"   - Total chunks: {len(documents)}\")\n",
    "    print(f\"   - Sample metadata: {documents[0].metadata}\")\n",
    "    print(f\"\\nüî§ First few chunks:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Display first 3 chunks\n",
    "    for i, doc in enumerate(documents[:3]):\n",
    "        print(f\"üìÑ Chunk {i+1}:\")\n",
    "        print(f\"   Content: {doc.page_content}\")\n",
    "        print(f\"   Metadata: {doc.metadata}\")\n",
    "        print(\"-\" * 30)\n",
    "else:\n",
    "    print(\"‚ùå No transcript chunks loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "353b83b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ YouTube Loader Comprehensive Test\n",
      "==================================================\n",
      "\n",
      "1Ô∏è‚É£ Testing basic transcript loading...\n",
      "‚úÖ Basic transcript: 1 documents loaded\n",
      "   Content preview: when using chat GPT you most probably have encountered responses like I'm sorry but as of my last kn...\n",
      "\n",
      "2Ô∏è‚É£ Testing transcript with video info...\n",
      "üîÑ Attempt 1/3 - Loading YouTube video with info...\n",
      "‚ùå Other URL error: HTTP Error 400: Bad Request\n",
      "‚ùå With video info failed: HTTP Error 400: Bad Request\n",
      "\n",
      "3Ô∏è‚É£ Testing chunked transcript...\n",
      "üì∫ Loading YouTube transcript in 15-second chunks...\n",
      "‚úÖ Successfully loaded 39 transcript chunks\n",
      "‚úÖ Chunked transcript: 39 chunks loaded\n",
      "   First chunk: when using chat GPT you most probably have encount...\n",
      "\n",
      "üèÅ Test suite completed!\n",
      "üí° If any tests failed, check the troubleshooting guide above\n"
     ]
    }
   ],
   "source": [
    "# üß™ Complete YouTube Loader Test Suite\n",
    "# This cell tests all YouTube loader functionality with proper error handling\n",
    "\n",
    "def test_youtube_loader_comprehensive():\n",
    "    \"\"\"Test all YouTube loader functionality comprehensively.\"\"\"\n",
    "    \n",
    "    test_video_url = \"https://www.youtube.com/watch?v=LAfrShnpVIk\"\n",
    "    \n",
    "    print(\"üß™ YouTube Loader Comprehensive Test\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Test 1: Basic transcript loading (should always work)\n",
    "    print(\"\\n1Ô∏è‚É£ Testing basic transcript loading...\")\n",
    "    try:\n",
    "        loader = YoutubeLoader.from_youtube_url(test_video_url, add_video_info=False)\n",
    "        result = loader.load()\n",
    "        print(f\"‚úÖ Basic transcript: {len(result)} documents loaded\")\n",
    "        print(f\"   Content preview: {result[0].page_content[:100]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Basic transcript failed: {e}\")\n",
    "    \n",
    "    # Test 2: Transcript with video info (may fail due to SSL)\n",
    "    print(\"\\n2Ô∏è‚É£ Testing transcript with video info...\")\n",
    "    try:\n",
    "        result = load_youtube_with_info(test_video_url)\n",
    "        print(f\"‚úÖ With video info: {len(result)} documents loaded\")\n",
    "        print(f\"   Metadata: {result[0].metadata}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå With video info failed: {e}\")\n",
    "    \n",
    "    # Test 3: Chunked transcript\n",
    "    print(\"\\n3Ô∏è‚É£ Testing chunked transcript...\")\n",
    "    try:\n",
    "        documents = load_youtube_transcript_chunks(test_video_url, chunk_size_seconds=15)\n",
    "        if documents:\n",
    "            print(f\"‚úÖ Chunked transcript: {len(documents)} chunks loaded\")\n",
    "            print(f\"   First chunk: {documents[0].page_content[:50]}...\")\n",
    "        else:\n",
    "            print(\"‚ùå No chunks loaded\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Chunked transcript failed: {e}\")\n",
    "    \n",
    "    print(\"\\nüèÅ Test suite completed!\")\n",
    "    print(\"üí° If any tests failed, check the troubleshooting guide above\")\n",
    "\n",
    "# Run the comprehensive test\n",
    "test_youtube_loader_comprehensive()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a4fc27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
