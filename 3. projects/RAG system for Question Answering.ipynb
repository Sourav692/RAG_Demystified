{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "de864c8f-ed5f-4dc2-8a18-b3809f3cb58e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Reference Link:** [RAG Systems Essentials (Analytics Vidhya)](https://courses.analyticsvidhya.com/courses/take/rag-systems-essentials/lessons/60148017-hands-on-deep-dive-into-rag-evaluation-metrics-generator-metrics-i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8c8c2cbf-5b2b-4ff4-8d78-3a80c37fdcae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install langchain==0.3.10\n",
    "!pip install langchain-openai==0.2.12\n",
    "!pip install langchain-community==0.3.11\n",
    "!pip install langchain-huggingface==0.1.2\n",
    "!pip install jq==1.8.0\n",
    "!pip install pymupdf==1.25.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1e783c9-6b6f-4574-82aa-e4666dfa7770",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install langchain-chroma==0.1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9921df9e-d29d-4058-a48b-2c81fb3babde",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "OPENAI_KEY = getpass('Enter Open AI API Key: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb7e5933-d075-428c-a82c-4b680b468d56",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21252d26-eab7-410f-b4a2-5f5a3ca711f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# details here: https://openai.com/blog/new-embedding-models-and-api-updates\n",
    "openai_embed_model = OpenAIEmbeddings(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "56f97cc5-0857-4179-8ff1-507dfa9a95fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4cfba87c-6d53-4c60-a193-4f8e802a1a3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# create a chat prompt\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "\n",
    "def generate_chunk_context(document, chunk):\n",
    "\n",
    "    chunk_process_prompt = \"\"\"You are an AI assistant specializing in research paper analysis.\n",
    "                            Your task is to provide brief, relevant context for a chunk of text\n",
    "                            based on the following research paper.\n",
    "\n",
    "                            Here is the research paper:\n",
    "                            <paper>\n",
    "                            {paper}\n",
    "                            </paper>\n",
    "\n",
    "                            Here is the chunk we want to situate within the whole document:\n",
    "                            <chunk>\n",
    "                            {chunk}\n",
    "                            </chunk>\n",
    "\n",
    "                            Provide a concise context (3-4 sentences max) for this chunk,\n",
    "                            considering the following guidelines:\n",
    "\n",
    "                            - Give a short succinct context to situate this chunk within the overall document\n",
    "                            for the purposes of improving search retrieval of the chunk.\n",
    "                            - Answer only with the succinct context and nothing else.\n",
    "                            - Context should be mentioned like 'Focuses on ....'\n",
    "                            do not mention 'this chunk or section focuses on...'\n",
    "\n",
    "                            Context:\n",
    "                        \"\"\"\n",
    "\n",
    "    prompt_template = ChatPromptTemplate.from_template(chunk_process_prompt)\n",
    "\n",
    "    agentic_chunk_chain = (prompt_template\n",
    "                                |\n",
    "                            chatgpt\n",
    "                                |\n",
    "                            StrOutputParser())\n",
    "\n",
    "    context = agentic_chunk_chain.invoke({'paper': document, 'chunk': chunk})\n",
    "\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dea4251d-9fd1-4bfb-ba9d-2280cfdc4385",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "\n",
    "def create_contextual_chunks(file_path):\n",
    "\n",
    "    print('Loading pages:', file_path)\n",
    "    loader = PyMuPDFLoader(file_path)\n",
    "    doc_pages = loader.load()\n",
    "\n",
    "    print('Chunking pages:', file_path)\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=3500,\n",
    "                                              chunk_overlap=0)\n",
    "    doc_chunks = splitter.split_documents(doc_pages)\n",
    "\n",
    "    print('Generating contextual chunks:', file_path)\n",
    "    original_doc = '\\n'.join([doc.page_content for doc in doc_chunks])\n",
    "    contextual_chunks = []\n",
    "    for chunk in doc_chunks:\n",
    "        context = generate_chunk_context(original_doc, chunk.page_content)\n",
    "        contextual_chunks.append(Document(page_content=context+'\\n'+chunk.page_content,\n",
    "                                          metadata=chunk.metadata))\n",
    "    print('Finished processing:', file_path)\n",
    "    print()\n",
    "    return contextual_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01e5bb5a-dfc7-41df-9177-3e138ef4795c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "pdf_files = glob('./data/*.pdf')\n",
    "pdf_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f05da8f9-d50f-471f-8582-72432cdb0db0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "paper_docs = []\n",
    "for fp in pdf_files:\n",
    "    paper_docs.extend(create_contextual_chunks(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7af3273-75a8-46d7-ae88-cdd89b11a886",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "# create vector DB of docs and embeddings - takes < 30s on Colab\n",
    "chroma_db = Chroma.from_documents(documents=total_docs,\n",
    "                                  collection_name='final_project',\n",
    "                                  embedding=openai_embed_model,\n",
    "                                  # need to set the distance function to cosine else it uses euclidean by default\n",
    "                                  # check https://docs.trychroma.com/guides#changing-the-distance-function\n",
    "                                  collection_metadata={\"hnsw:space\": \"cosine\"},\n",
    "                                  persist_directory=\"./final_project\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "005d0083-3551-4c79-8f74-1a871f14e759",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# load from disk\n",
    "chroma_db = Chroma(persist_directory=\"./final_project\",\n",
    "                   collection_name='final_project',\n",
    "                   embedding_function=openai_embed_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6c76bc4-52e7-453a-882f-f8f5f4837300",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "similarity_retriever = chroma_db.as_retriever(search_type=\"similarity\",\n",
    "                                              search_kwargs={\"k\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "480731ed-a7d3-47ce-a7a1-42d2d0bf7dde",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def display_docs(docs):\n",
    "    for doc in docs:\n",
    "        print('Metadata:', doc.metadata)\n",
    "        print('Content Brief:')\n",
    "        display(Markdown(doc.page_content[:1000]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bbc66ccb-2129-4e02-a156-18538240edce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = \"what is machine learning?\"\n",
    "top_docs = similarity_retriever.invoke(query)\n",
    "display_docs(top_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8843c863-a304-4073-9670-aa5ceeb909ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatgpt = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b40d364-0505-4169-8635-f4b0397509ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "# # Set logging for the queries\n",
    "# import logging\n",
    "\n",
    "# similarity_retriever = chroma_db.as_retriever(search_type=\"similarity\",\n",
    "#                                               search_kwargs={\"k\": 5})\n",
    "\n",
    "# mq_retriever = MultiQueryRetriever.from_llm(\n",
    "#     retriever=similarity_retriever, llm=chatgpt\n",
    "# )\n",
    "\n",
    "# logging.basicConfig()\n",
    "# # so we can see what queries are generated by the LLM\n",
    "# logging.getLogger(\"langchain.retrievers.multi_query\").setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82d55f3c-c180-4dc6-914d-cb8aa3d2d3fa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = \"what is a cnn?\"\n",
    "top_docs = mq_retriever.invoke(query)\n",
    "display_docs(top_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a6217aab-558f-4855-8c7b-008b36b6c0b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = \"what is nlp?\"\n",
    "top_docs = mq_retriever.invoke(query)\n",
    "display_docs(top_docs)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "RAG system for Question Answering",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
